{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edaebc57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nthis file for data_set_part_3\\n\\n    part 1 - train: 11.22~11.27 > 11.28;\\n    part 2 - train: 11.29~12.04 > 12.05;\\n    part 3 - test: 12.13~12.18 (> 12.19);\\n    \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "this file for data_set_part_3\n",
    "\n",
    "    part 1 - train: 11.22~11.27 > 11.28;\n",
    "    part 2 - train: 11.29~12.04 > 12.05;\n",
    "    part 3 - test: 12.13~12.18 (> 12.19);\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1ba85a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### file path\n",
    "# input \n",
    "path_df_D = \"/Users/DanDan/Desktop/第一课/code/fresh_comp_offline/tianchi_fresh_comp_train_user.csv\"\n",
    "\n",
    "path_df_part_1 = \"/Users/DanDan/Desktop/第一课/code/fresh_comp_offline/df_part_1.csv\"\n",
    "path_df_part_2 = \"/Users/DanDan/Desktop/第一课/code/fresh_comp_offline/df_part_2.csv\"\n",
    "path_df_part_3 = \"/Users/DanDan/Desktop/第一课/code/fresh_comp_offline/df_part_3.csv\"\n",
    "\n",
    "path_df_part_1_tar = \"/Users/DanDan/Desktop/第一课/code/fresh_comp_offline/df_part_1_tar.csv\"\n",
    "path_df_part_2_tar = \"/Users/DanDan/Desktop/第一课/code/fresh_comp_offline/df_part_2_tar.csv\"\n",
    "\n",
    "path_df_part_1_uic_label = \"/Users/DanDan/Desktop/第一课/code/fresh_comp_offline/df_part_1_uic_label.csv\"\n",
    "path_df_part_2_uic_label = \"/Users/DanDan/Desktop/第一课/code/fresh_comp_offline/df_part_2_uic_label.csv\"\n",
    "path_df_part_3_uic       = \"/Users/DanDan/Desktop/第一课/code/fresh_comp_offline/df_part_3_uic.csv\"\n",
    "\n",
    "# output\n",
    "path_df_part_1_U   = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_1_U.csv\"  \n",
    "path_df_part_1_I   = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_1_I.csv\"\n",
    "path_df_part_1_C   = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_1_C.csv\"\n",
    "path_df_part_1_IC  = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_1_IC.csv\"\n",
    "path_df_part_1_UI  = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_1_UI.csv\"\n",
    "path_df_part_1_UC  = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_1_UC.csv\"\n",
    "\n",
    "path_df_part_2_U   = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_2_U.csv\"  \n",
    "path_df_part_2_I   = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_2_I.csv\"\n",
    "path_df_part_2_C   = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_2_C.csv\"\n",
    "path_df_part_2_IC  = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_2_IC.csv\"\n",
    "path_df_part_2_UI  = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_2_UI.csv\"\n",
    "path_df_part_2_UC  = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_2_UC.csv\"\n",
    "\n",
    "path_df_part_3_U   = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_3_U.csv\"  \n",
    "path_df_part_3_I   = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_3_I.csv\"\n",
    "path_df_part_3_C   = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_3_C.csv\"\n",
    "path_df_part_3_IC  = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_3_IC.csv\"\n",
    "path_df_part_3_UI  = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_3_UI.csv\"\n",
    "path_df_part_3_UC  = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_3_UC.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1abf78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# loading data\n",
    "path_df = open(path_df_part_3, 'r')\n",
    "try:\n",
    "    df_part_3 = pd.read_csv(path_df, index_col = False, parse_dates = [0])\n",
    "    df_part_3.columns = ['time','user_id','item_id','behavior_type','item_category']\n",
    "finally:\n",
    "    path_df.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d51784e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15494/1775199738.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_3_u_b_count_in_6 = df_part_3.drop_duplicates(['user_id','behavior_type'], 'last')[['user_id','behavior_type','cumcount']]\n"
     ]
    }
   ],
   "source": [
    "# u_b_count_in_6\n",
    "df_part_3['cumcount'] = df_part_3.groupby(['user_id', 'behavior_type']).cumcount()\n",
    "df_part_3_u_b_count_in_6 = df_part_3.drop_duplicates(['user_id','behavior_type'], 'last')[['user_id','behavior_type','cumcount']]\n",
    "df_part_3_u_b_count_in_6 = pd.get_dummies(df_part_3_u_b_count_in_6['behavior_type']).join(df_part_3_u_b_count_in_6[['user_id','cumcount']])\n",
    "df_part_3_u_b_count_in_6.rename(columns = {1:'behavior_type_1',\n",
    "                                           2:'behavior_type_2',\n",
    "                                           3:'behavior_type_3',\n",
    "                                           4:'behavior_type_4'}, inplace=True)\n",
    "df_part_3_u_b_count_in_6['u_b1_count_in_6'] = df_part_3_u_b_count_in_6['behavior_type_1'] * (df_part_3_u_b_count_in_6['cumcount']+1)\n",
    "df_part_3_u_b_count_in_6['u_b2_count_in_6'] = df_part_3_u_b_count_in_6['behavior_type_2'] * (df_part_3_u_b_count_in_6['cumcount']+1)\n",
    "df_part_3_u_b_count_in_6['u_b3_count_in_6'] = df_part_3_u_b_count_in_6['behavior_type_3'] * (df_part_3_u_b_count_in_6['cumcount']+1)\n",
    "df_part_3_u_b_count_in_6['u_b4_count_in_6'] = df_part_3_u_b_count_in_6['behavior_type_4'] * (df_part_3_u_b_count_in_6['cumcount']+1)\n",
    "df_part_3_u_b_count_in_6 = df_part_3_u_b_count_in_6.groupby('user_id').agg({'u_b1_count_in_6': np.sum,\n",
    "                                                                            'u_b2_count_in_6': np.sum,\n",
    "                                                                            'u_b3_count_in_6': np.sum,\n",
    "                                                                            'u_b4_count_in_6': np.sum})\n",
    "df_part_3_u_b_count_in_6.reset_index(inplace = True)\n",
    "df_part_3_u_b_count_in_6['u_b_count_in_6'] = df_part_3_u_b_count_in_6[['u_b1_count_in_6',\n",
    "                                                                       'u_b2_count_in_6',\n",
    "                                                                       'u_b3_count_in_6',\n",
    "                                                                       'u_b4_count_in_6']].apply(lambda x: x.sum(), axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3316991",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15494/1728761746.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_part_3_in_3['cumcount'] = df_part_3_in_3.groupby(['user_id', 'behavior_type']).cumcount()\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15494/1728761746.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_3_u_b_count_in_3 = df_part_3.drop_duplicates(['user_id','behavior_type'], 'last')[['user_id','behavior_type','cumcount']]\n"
     ]
    }
   ],
   "source": [
    "# u_b_count_in_3\n",
    "df_part_3_in_3 = df_part_3[df_part_3['time'] >= np.datetime64('2014-12-16')]\n",
    "df_part_3_in_3['cumcount'] = df_part_3_in_3.groupby(['user_id', 'behavior_type']).cumcount()\n",
    "df_part_3_u_b_count_in_3 = df_part_3.drop_duplicates(['user_id','behavior_type'], 'last')[['user_id','behavior_type','cumcount']]\n",
    "df_part_3_u_b_count_in_3 = pd.get_dummies(df_part_3_u_b_count_in_3['behavior_type']).join(df_part_3_u_b_count_in_3[['user_id','cumcount']])\n",
    "df_part_3_u_b_count_in_3.rename(columns = {1:'behavior_type_1',\n",
    "                                           2:'behavior_type_2',\n",
    "                                           3:'behavior_type_3',\n",
    "                                           4:'behavior_type_4'}, inplace=True)\n",
    "df_part_3_u_b_count_in_3['u_b1_count_in_3'] = df_part_3_u_b_count_in_3['behavior_type_1'] * (df_part_3_u_b_count_in_3['cumcount']+1)\n",
    "df_part_3_u_b_count_in_3['u_b2_count_in_3'] = df_part_3_u_b_count_in_3['behavior_type_2'] * (df_part_3_u_b_count_in_3['cumcount']+1)\n",
    "df_part_3_u_b_count_in_3['u_b3_count_in_3'] = df_part_3_u_b_count_in_3['behavior_type_3'] * (df_part_3_u_b_count_in_3['cumcount']+1)\n",
    "df_part_3_u_b_count_in_3['u_b4_count_in_3'] = df_part_3_u_b_count_in_3['behavior_type_4'] * (df_part_3_u_b_count_in_3['cumcount']+1)\n",
    "df_part_3_u_b_count_in_3 = df_part_3_u_b_count_in_3.groupby('user_id').agg({'u_b1_count_in_3': np.sum,\n",
    "                                                                            'u_b2_count_in_3': np.sum,\n",
    "                                                                            'u_b3_count_in_3': np.sum,\n",
    "                                                                            'u_b4_count_in_3': np.sum})\n",
    "df_part_3_u_b_count_in_3.reset_index(inplace = True)\n",
    "df_part_3_u_b_count_in_3['u_b_count_in_3'] = df_part_3_u_b_count_in_3[['u_b1_count_in_3',\n",
    "                                                                       'u_b2_count_in_3',\n",
    "                                                                       'u_b3_count_in_3',\n",
    "                                                                       'u_b4_count_in_3']].apply(lambda x: x.sum(), axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c85d0e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15494/2865522393.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_part_3_in_1['cumcount'] = df_part_3_in_1.groupby(['user_id', 'behavior_type']).cumcount()\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15494/2865522393.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_3_u_b_count_in_1 = df_part_3_in_1.drop_duplicates(['user_id','behavior_type'], 'last')[['user_id','behavior_type','cumcount']]\n"
     ]
    }
   ],
   "source": [
    "# u_b_count_in_1\n",
    "df_part_3_in_1 = df_part_3[df_part_3['time'] >= np.datetime64('2014-12-18')]\n",
    "df_part_3_in_1['cumcount'] = df_part_3_in_1.groupby(['user_id', 'behavior_type']).cumcount()\n",
    "df_part_3_u_b_count_in_1 = df_part_3_in_1.drop_duplicates(['user_id','behavior_type'], 'last')[['user_id','behavior_type','cumcount']]\n",
    "df_part_3_u_b_count_in_1 = pd.get_dummies(df_part_3_u_b_count_in_1['behavior_type']).join(df_part_3_u_b_count_in_1[['user_id','cumcount']])\n",
    "df_part_3_u_b_count_in_1.rename(columns = {1:'behavior_type_1',\n",
    "                                           2:'behavior_type_2',\n",
    "                                           3:'behavior_type_3',\n",
    "                                           4:'behavior_type_4'}, inplace=True)\n",
    "df_part_3_u_b_count_in_1['u_b1_count_in_1'] = df_part_3_u_b_count_in_1['behavior_type_1'] * (df_part_3_u_b_count_in_1['cumcount']+1)\n",
    "df_part_3_u_b_count_in_1['u_b2_count_in_1'] = df_part_3_u_b_count_in_1['behavior_type_2'] * (df_part_3_u_b_count_in_1['cumcount']+1)\n",
    "df_part_3_u_b_count_in_1['u_b3_count_in_1'] = df_part_3_u_b_count_in_1['behavior_type_3'] * (df_part_3_u_b_count_in_1['cumcount']+1)\n",
    "df_part_3_u_b_count_in_1['u_b4_count_in_1'] = df_part_3_u_b_count_in_1['behavior_type_4'] * (df_part_3_u_b_count_in_1['cumcount']+1)\n",
    "df_part_3_u_b_count_in_1 = df_part_3_u_b_count_in_1.groupby('user_id').agg({'u_b1_count_in_1': np.sum,\n",
    "                                                                            'u_b2_count_in_1': np.sum,\n",
    "                                                                            'u_b3_count_in_1': np.sum,\n",
    "                                                                            'u_b4_count_in_1': np.sum})\n",
    "df_part_3_u_b_count_in_1.reset_index(inplace = True)\n",
    "df_part_3_u_b_count_in_1['u_b_count_in_1']  = df_part_3_u_b_count_in_1[['u_b1_count_in_1',\n",
    "                                                                        'u_b2_count_in_1',\n",
    "                                                                        'u_b3_count_in_1',\n",
    "                                                                        'u_b4_count_in_1']].apply(lambda x: x.sum(), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8e0db96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the result of count_in_6, count_in_3, count_in_1\n",
    "\n",
    "df_part_3_u_b_count = pd.merge(df_part_3_u_b_count_in_6, \n",
    "                               df_part_3_u_b_count_in_3, on = ['user_id'], how = 'left').fillna(0)\n",
    "df_part_3_u_b_count = pd.merge(df_part_3_u_b_count, \n",
    "                               df_part_3_u_b_count_in_1, on = ['user_id'], how = 'left').fillna(0)\n",
    "                                    \n",
    "df_part_3_u_b_count[['u_b1_count_in_6',\n",
    "                     'u_b2_count_in_6',\n",
    "                     'u_b3_count_in_6',\n",
    "                     'u_b4_count_in_6',\n",
    "                      'u_b_count_in_6',\n",
    "                     'u_b1_count_in_3',\n",
    "                     'u_b2_count_in_3',\n",
    "                     'u_b3_count_in_3',\n",
    "                     'u_b4_count_in_3',\n",
    "                      'u_b_count_in_3',\n",
    "                     'u_b1_count_in_1',\n",
    "                     'u_b2_count_in_1',\n",
    "                     'u_b3_count_in_1',\n",
    "                     'u_b4_count_in_1',\n",
    "                      'u_b_count_in_1']] = df_part_3_u_b_count[['u_b1_count_in_6',\n",
    "                                                                'u_b2_count_in_6',\n",
    "                                                                'u_b3_count_in_6',\n",
    "                                                                'u_b4_count_in_6',\n",
    "                                                                 'u_b_count_in_6',\n",
    "                                                                'u_b1_count_in_3',\n",
    "                                                                'u_b2_count_in_3',\n",
    "                                                                'u_b3_count_in_3',\n",
    "                                                                'u_b4_count_in_3',\n",
    "                                                                 'u_b_count_in_3',\n",
    "                                                                'u_b1_count_in_1',\n",
    "                                                                'u_b2_count_in_1',\n",
    "                                                                'u_b3_count_in_1',\n",
    "                                                                'u_b4_count_in_1',\n",
    "                                                                 'u_b_count_in_1']].astype(int)\n",
    "                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "389bc04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15494/940773871.py:6: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_3_u_b4_time = df_part_3[df_part_3['behavior_type'] == 4].drop_duplicates(['user_id'],'first')[['user_id','time']]\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15494/940773871.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_3_u_b_time = df_part_3.drop_duplicates(['user_id'],'first')[['user_id','time']]\n"
     ]
    }
   ],
   "source": [
    "# u_b4_rate\n",
    "df_part_3_u_b_count['u_b4_rate'] = df_part_3_u_b_count['u_b4_count_in_6'] / df_part_3_u_b_count['u_b_count_in_6']\n",
    "\n",
    "# u_b4_diff_time\n",
    "df_part_3 = df_part_3.sort_values(by = ['user_id', 'time'])\n",
    "df_part_3_u_b4_time = df_part_3[df_part_3['behavior_type'] == 4].drop_duplicates(['user_id'],'first')[['user_id','time']]\n",
    "df_part_3_u_b4_time.columns = ['user_id','b4_first_time']\n",
    "df_part_3_u_b_time = df_part_3.drop_duplicates(['user_id'],'first')[['user_id','time']]\n",
    "df_part_3_u_b_time.columns = ['user_id','b_first_time']\n",
    "df_part_3_u_b_b4_time = pd.merge(df_part_3_u_b_time, df_part_3_u_b4_time, on = ['user_id'])\n",
    "df_part_3_u_b_b4_time['u_b4_diff_time'] = df_part_3_u_b_b4_time['b4_first_time'] - df_part_3_u_b_b4_time['b_first_time']\n",
    "df_part_3_u_b_b4_time = df_part_3_u_b_b4_time[['user_id', 'u_b4_diff_time']]\n",
    "df_part_3_u_b_b4_time['u_b4_diff_hours'] = df_part_3_u_b_b4_time['u_b4_diff_time'].apply(lambda x: x.days * 24 + x.seconds//3600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c9c6e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating feature set U\n",
    "f_U_part_3 = pd.merge(df_part_3_u_b_count, \n",
    "                      df_part_3_u_b_b4_time, \n",
    "                      on = ['user_id'], how = 'left')[['user_id',\n",
    "                                                       'u_b1_count_in_6', \n",
    "                                                       'u_b2_count_in_6', \n",
    "                                                       'u_b3_count_in_6', \n",
    "                                                       'u_b4_count_in_6', \n",
    "                                                       'u_b_count_in_6',\n",
    "                                                       'u_b1_count_in_3',\n",
    "                                                       'u_b2_count_in_3', \n",
    "                                                       'u_b3_count_in_3',\n",
    "                                                       'u_b4_count_in_3', \n",
    "                                                       'u_b_count_in_3',\n",
    "                                                       'u_b1_count_in_1',\n",
    "                                                       'u_b2_count_in_1', \n",
    "                                                       'u_b3_count_in_1',\n",
    "                                                       'u_b4_count_in_1', \n",
    "                                                       'u_b_count_in_1', \n",
    "                                                       'u_b4_rate', \n",
    "                                                       'u_b4_diff_hours']]\n",
    "                      \n",
    "# write to csv file\n",
    "f_U_part_3 = f_U_part_3.round({'u_b4_rate': 3})\n",
    "f_U_part_3.to_csv(path_df_part_3_U, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c29527e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Step 1.2 feature data set I of df_part_3\\n    (1)\\n    i_u_count_in_6\\n    i_u_count_in_3\\n    i_u_count_in_1\\n    (2)\\n    i_b1_count_in_6\\n    i_b2_count_in_6\\n    i_b3_count_in_6\\n    i_b4_count_in_6\\n     i_b_count_in_6\\n    i_b1_count_in_3\\n    i_b2_count_in_3\\n    i_b3_count_in_3\\n    i_b4_count_in_3\\n     i_b_count_in_3\\n    i_b1_count_in_1\\n    i_b2_count_in_1\\n    i_b3_count_in_1\\n    i_b4_count_in_1\\n     i_b_count_in_1\\n    (3)\\n    i_b4_rate  (in_6)\\n    i_b4_diff_hours (in_6)\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###########################################\n",
    "'''Step 1.2 feature data set I of df_part_3\n",
    "    (1)\n",
    "    i_u_count_in_6\n",
    "    i_u_count_in_3\n",
    "    i_u_count_in_1\n",
    "    (2)\n",
    "    i_b1_count_in_6\n",
    "    i_b2_count_in_6\n",
    "    i_b3_count_in_6\n",
    "    i_b4_count_in_6\n",
    "     i_b_count_in_6\n",
    "    i_b1_count_in_3\n",
    "    i_b2_count_in_3\n",
    "    i_b3_count_in_3\n",
    "    i_b4_count_in_3\n",
    "     i_b_count_in_3\n",
    "    i_b1_count_in_1\n",
    "    i_b2_count_in_1\n",
    "    i_b3_count_in_1\n",
    "    i_b4_count_in_1\n",
    "     i_b_count_in_1\n",
    "    (3)\n",
    "    i_b4_rate  (in_6)\n",
    "    i_b4_diff_hours (in_6)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8683cdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "path_df = open(path_df_part_3, 'r')\n",
    "try:\n",
    "    df_part_3 = pd.read_csv(path_df, index_col = False, parse_dates = [0])\n",
    "    df_part_3.columns = ['time','user_id','item_id','behavior_type','item_category']\n",
    "finally:\n",
    "    path_df.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "070a1e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15494/1134727341.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_part_3_in_6['i_u_count_in_6'] = df_part_3_in_6.groupby('item_id').cumcount() + 1\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15494/1134727341.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_3_i_u_count_in_6 = df_part_3_in_6.drop_duplicates(['item_id'], 'last')[['item_id', 'i_u_count_in_6']]\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15494/1134727341.py:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_3_i_u_count_in_3 = df_part_3_in_3.drop_duplicates(['item_id'], 'last')[['item_id', 'i_u_count_in_3']]\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15494/1134727341.py:14: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_3_i_u_count_in_1 = df_part_3_in_1.drop_duplicates(['item_id'], 'last')[['item_id', 'i_u_count_in_1']]\n"
     ]
    }
   ],
   "source": [
    "# i_u_count_in_6\n",
    "df_part_3_in_6 = df_part_3.drop_duplicates(['item_id', 'user_id'])\n",
    "df_part_3_in_6['i_u_count_in_6'] = df_part_3_in_6.groupby('item_id').cumcount() + 1\n",
    "df_part_3_i_u_count_in_6 = df_part_3_in_6.drop_duplicates(['item_id'], 'last')[['item_id', 'i_u_count_in_6']]\n",
    "\n",
    "# i_u_count_in_3\n",
    "df_part_3_in_3 = df_part_3[df_part_3['time'] >= np.datetime64('2014-12-16')].drop_duplicates(['item_id', 'user_id'])\n",
    "df_part_3_in_3['i_u_count_in_3'] = df_part_3_in_3.groupby('item_id').cumcount() + 1\n",
    "df_part_3_i_u_count_in_3 = df_part_3_in_3.drop_duplicates(['item_id'], 'last')[['item_id', 'i_u_count_in_3']]\n",
    "\n",
    "# i_u_count_in_1\n",
    "df_part_3_in_1 = df_part_3[df_part_3['time'] >= np.datetime64('2014-12-18')].drop_duplicates(['item_id', 'user_id'])\n",
    "df_part_3_in_1['i_u_count_in_1'] = df_part_3_in_1.groupby('item_id').cumcount() + 1\n",
    "df_part_3_i_u_count_in_1 = df_part_3_in_1.drop_duplicates(['item_id'], 'last')[['item_id', 'i_u_count_in_1']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dacd467c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge for generation of i_u_count\n",
    "df_part_3_i_u_count = pd.merge(df_part_3_i_u_count_in_6, \n",
    "                               df_part_3_i_u_count_in_3,\n",
    "                               on=['item_id'],how='left').fillna(0)\n",
    "df_part_3_i_u_count = pd.merge(df_part_3_i_u_count, \n",
    "                               df_part_3_i_u_count_in_1,\n",
    "                               on=['item_id'],how='left').fillna(0)\n",
    "df_part_3_i_u_count[['i_u_count_in_6',\n",
    "                     'i_u_count_in_3',\n",
    "                     'i_u_count_in_1']] = df_part_3_i_u_count[['i_u_count_in_6',\n",
    "                                                               'i_u_count_in_3',\n",
    "                                                               'i_u_count_in_1']].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f803544",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15494/650009254.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_3_i_b_count_in_6 = df_part_3.drop_duplicates(['item_id','behavior_type'], 'last')[['item_id','behavior_type','cumcount']]\n"
     ]
    }
   ],
   "source": [
    "# i_b_count_in_6\n",
    "df_part_3['cumcount'] = df_part_3.groupby(['item_id', 'behavior_type']).cumcount()\n",
    "df_part_3_i_b_count_in_6 = df_part_3.drop_duplicates(['item_id','behavior_type'], 'last')[['item_id','behavior_type','cumcount']]\n",
    "df_part_3_i_b_count_in_6 = pd.get_dummies(df_part_3_i_b_count_in_6['behavior_type']).join(df_part_3_i_b_count_in_6[['item_id','cumcount']])\n",
    "df_part_3_i_b_count_in_6.rename(columns = {1:'behavior_type_1',\n",
    "                                           2:'behavior_type_2',\n",
    "                                           3:'behavior_type_3',\n",
    "                                           4:'behavior_type_4'}, inplace=True)\n",
    "df_part_3_i_b_count_in_6['i_b1_count_in_6'] = df_part_3_i_b_count_in_6['behavior_type_1'] * (df_part_3_i_b_count_in_6['cumcount']+1)\n",
    "df_part_3_i_b_count_in_6['i_b2_count_in_6'] = df_part_3_i_b_count_in_6['behavior_type_2'] * (df_part_3_i_b_count_in_6['cumcount']+1)\n",
    "df_part_3_i_b_count_in_6['i_b3_count_in_6'] = df_part_3_i_b_count_in_6['behavior_type_3'] * (df_part_3_i_b_count_in_6['cumcount']+1)\n",
    "df_part_3_i_b_count_in_6['i_b4_count_in_6'] = df_part_3_i_b_count_in_6['behavior_type_4'] * (df_part_3_i_b_count_in_6['cumcount']+1)\n",
    "df_part_3_i_b_count_in_6 = df_part_3_i_b_count_in_6[['item_id', \n",
    "                                                     'i_b1_count_in_6', \n",
    "                                                     'i_b2_count_in_6', \n",
    "                                                     'i_b3_count_in_6',\n",
    "                                                     'i_b4_count_in_6']]\n",
    "df_part_3_i_b_count_in_6 = df_part_3_i_b_count_in_6.groupby('item_id').agg({'i_b1_count_in_6': np.sum,\n",
    "                                                                            'i_b2_count_in_6': np.sum,\n",
    "                                                                            'i_b3_count_in_6': np.sum,\n",
    "                                                                            'i_b4_count_in_6': np.sum})\n",
    "df_part_3_i_b_count_in_6.reset_index(inplace = True)\n",
    "df_part_3_i_b_count_in_6['i_b_count_in_6'] = df_part_3_i_b_count_in_6['i_b1_count_in_6'] + \\\n",
    "                                             df_part_3_i_b_count_in_6['i_b2_count_in_6'] + \\\n",
    "                                             df_part_3_i_b_count_in_6['i_b3_count_in_6'] + \\\n",
    "                                             df_part_3_i_b_count_in_6['i_b4_count_in_6']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8108db46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15494/1510659842.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_part_3_in_3['cumcount'] = df_part_3_in_3.groupby(['item_id', 'behavior_type']).cumcount()\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15494/1510659842.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_3_i_b_count_in_3 = df_part_3.drop_duplicates(['item_id','behavior_type'], 'last')[['item_id','behavior_type','cumcount']]\n"
     ]
    }
   ],
   "source": [
    "# i_b_count_in_3\n",
    "df_part_3_in_3 = df_part_3[df_part_3['time'] >= np.datetime64('2014-12-16')]\n",
    "df_part_3_in_3['cumcount'] = df_part_3_in_3.groupby(['item_id', 'behavior_type']).cumcount()\n",
    "df_part_3_i_b_count_in_3 = df_part_3.drop_duplicates(['item_id','behavior_type'], 'last')[['item_id','behavior_type','cumcount']]\n",
    "df_part_3_i_b_count_in_3 = pd.get_dummies(df_part_3_i_b_count_in_3['behavior_type']).join(df_part_3_i_b_count_in_3[['item_id','cumcount']])\n",
    "df_part_3_i_b_count_in_3.rename(columns = {1:'behavior_type_1',\n",
    "                                           2:'behavior_type_2',\n",
    "                                           3:'behavior_type_3',\n",
    "                                           4:'behavior_type_4'}, inplace=True)\n",
    "df_part_3_i_b_count_in_3['i_b1_count_in_3'] = df_part_3_i_b_count_in_3['behavior_type_1'] * (df_part_3_i_b_count_in_3['cumcount']+1)\n",
    "df_part_3_i_b_count_in_3['i_b2_count_in_3'] = df_part_3_i_b_count_in_3['behavior_type_2'] * (df_part_3_i_b_count_in_3['cumcount']+1)\n",
    "df_part_3_i_b_count_in_3['i_b3_count_in_3'] = df_part_3_i_b_count_in_3['behavior_type_3'] * (df_part_3_i_b_count_in_3['cumcount']+1)\n",
    "df_part_3_i_b_count_in_3['i_b4_count_in_3'] = df_part_3_i_b_count_in_3['behavior_type_4'] * (df_part_3_i_b_count_in_3['cumcount']+1)\n",
    "df_part_3_i_b_count_in_3 = df_part_3_i_b_count_in_3[['item_id', \n",
    "                                                     'i_b1_count_in_3', \n",
    "                                                     'i_b2_count_in_3', \n",
    "                                                     'i_b3_count_in_3',\n",
    "                                                     'i_b4_count_in_3']]\n",
    "df_part_3_i_b_count_in_3 = df_part_3_i_b_count_in_3.groupby('item_id').agg({'i_b1_count_in_3': np.sum,\n",
    "                                                                            'i_b2_count_in_3': np.sum,\n",
    "                                                                            'i_b3_count_in_3': np.sum,\n",
    "                                                                            'i_b4_count_in_3': np.sum})\n",
    "df_part_3_i_b_count_in_3.reset_index(inplace = True)\n",
    "df_part_3_i_b_count_in_3['i_b_count_in_3'] = df_part_3_i_b_count_in_3['i_b1_count_in_3'] + \\\n",
    "                                             df_part_3_i_b_count_in_3['i_b2_count_in_3'] + \\\n",
    "                                             df_part_3_i_b_count_in_3['i_b3_count_in_3'] + \\\n",
    "                                             df_part_3_i_b_count_in_3['i_b4_count_in_3']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "962b6575",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15494/1281211679.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_part_3_in_1['cumcount'] = df_part_3_in_1.groupby(['item_id', 'behavior_type']).cumcount()\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15494/1281211679.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_3_i_b_count_in_1 = df_part_3_in_1.drop_duplicates(['item_id','behavior_type'], 'last')[['item_id','behavior_type','cumcount']]\n"
     ]
    }
   ],
   "source": [
    "# i_b_count_in_1\n",
    "df_part_3_in_1 = df_part_3[df_part_3['time'] >= np.datetime64('2014-12-18')]\n",
    "df_part_3_in_1['cumcount'] = df_part_3_in_1.groupby(['item_id', 'behavior_type']).cumcount()\n",
    "df_part_3_i_b_count_in_1 = df_part_3_in_1.drop_duplicates(['item_id','behavior_type'], 'last')[['item_id','behavior_type','cumcount']]\n",
    "df_part_3_i_b_count_in_1 = pd.get_dummies(df_part_3_i_b_count_in_1['behavior_type']).join(df_part_3_i_b_count_in_1[['item_id','cumcount']])\n",
    "df_part_3_i_b_count_in_1.rename(columns = {1:'behavior_type_1',\n",
    "                                           2:'behavior_type_2',\n",
    "                                           3:'behavior_type_3',\n",
    "                                           4:'behavior_type_4'}, inplace=True)                     \n",
    "df_part_3_i_b_count_in_1['i_b1_count_in_1'] = df_part_3_i_b_count_in_1['behavior_type_1'] * (df_part_3_i_b_count_in_1['cumcount']+1)\n",
    "df_part_3_i_b_count_in_1['i_b2_count_in_1'] = df_part_3_i_b_count_in_1['behavior_type_2'] * (df_part_3_i_b_count_in_1['cumcount']+1)\n",
    "df_part_3_i_b_count_in_1['i_b3_count_in_1'] = df_part_3_i_b_count_in_1['behavior_type_3'] * (df_part_3_i_b_count_in_1['cumcount']+1)\n",
    "df_part_3_i_b_count_in_1['i_b4_count_in_1'] = df_part_3_i_b_count_in_1['behavior_type_4'] * (df_part_3_i_b_count_in_1['cumcount']+1)\n",
    "df_part_3_i_b_count_in_1 = df_part_3_i_b_count_in_1[['item_id', \n",
    "                                                     'i_b1_count_in_1', \n",
    "                                                     'i_b2_count_in_1', \n",
    "                                                     'i_b3_count_in_1',\n",
    "                                                     'i_b4_count_in_1']]\n",
    "df_part_3_i_b_count_in_1 = df_part_3_i_b_count_in_1.groupby('item_id').agg({'i_b1_count_in_1': np.sum,\n",
    "                                                                            'i_b2_count_in_1': np.sum,\n",
    "                                                                            'i_b3_count_in_1': np.sum,\n",
    "                                                                            'i_b4_count_in_1': np.sum})\n",
    "df_part_3_i_b_count_in_1.reset_index(inplace = True)\n",
    "df_part_3_i_b_count_in_1['i_b_count_in_1'] = df_part_3_i_b_count_in_1['i_b1_count_in_1'] + \\\n",
    "                                             df_part_3_i_b_count_in_1['i_b2_count_in_1'] + \\\n",
    "                                             df_part_3_i_b_count_in_1['i_b3_count_in_1'] + \\\n",
    "                                             df_part_3_i_b_count_in_1['i_b4_count_in_1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee2ef7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge for generation of i_b_count\n",
    "df_part_3_i_b_count = pd.merge(df_part_3_i_b_count_in_6, \n",
    "                               df_part_3_i_b_count_in_3, \n",
    "                               on = ['item_id'], how = 'left').fillna(0)\n",
    "df_part_3_i_b_count = pd.merge(df_part_3_i_b_count, \n",
    "                               df_part_3_i_b_count_in_1, \n",
    "                               on = ['item_id'], how = 'left').fillna(0)\n",
    "df_part_3_i_b_count[['i_b1_count_in_6',\n",
    "                     'i_b2_count_in_6',\n",
    "                     'i_b3_count_in_6',\n",
    "                     'i_b4_count_in_6',\n",
    "                      'i_b_count_in_6',\n",
    "                     'i_b1_count_in_3',\n",
    "                     'i_b2_count_in_3',\n",
    "                     'i_b3_count_in_3',\n",
    "                     'i_b4_count_in_3',\n",
    "                      'i_b_count_in_3',\n",
    "                     'i_b1_count_in_1',\n",
    "                     'i_b2_count_in_1',\n",
    "                     'i_b3_count_in_1',\n",
    "                     'i_b4_count_in_1',\n",
    "                      'i_b_count_in_1']] = df_part_3_i_b_count[['i_b1_count_in_6',\n",
    "                                                                'i_b2_count_in_6',\n",
    "                                                                'i_b3_count_in_6',\n",
    "                                                                'i_b4_count_in_6',\n",
    "                                                                 'i_b_count_in_6',\n",
    "                                                                'i_b1_count_in_3',\n",
    "                                                                'i_b2_count_in_3',\n",
    "                                                                'i_b3_count_in_3',\n",
    "                                                                'i_b4_count_in_3',\n",
    "                                                                 'i_b_count_in_3',\n",
    "                                                                'i_b1_count_in_1',\n",
    "                                                                'i_b2_count_in_1',\n",
    "                                                                'i_b3_count_in_1',\n",
    "                                                                'i_b4_count_in_1',\n",
    "                                                                 'i_b_count_in_1']].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e46b1f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15494/292245286.py:6: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_3_i_b4_time = df_part_3[df_part_3['behavior_type'] == 4].drop_duplicates(['item_id'], 'first')[['item_id','time']]\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15494/292245286.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_3_i_b_time = df_part_3.drop_duplicates(['item_id'], 'first')[['item_id','time']]\n"
     ]
    }
   ],
   "source": [
    "# i_b4_rate\n",
    "df_part_3_i_b_count['i_b4_rate'] = df_part_3_i_b_count['i_b4_count_in_6'] / df_part_3_i_b_count['i_b_count_in_6']\n",
    "\n",
    "# i_b4_diff_time\n",
    "df_part_3 = df_part_3.sort_values(by=['item_id', 'time'])\n",
    "df_part_3_i_b4_time = df_part_3[df_part_3['behavior_type'] == 4].drop_duplicates(['item_id'], 'first')[['item_id','time']]\n",
    "df_part_3_i_b4_time.columns = ['item_id','b4_first_time']\n",
    "df_part_3_i_b_time = df_part_3.drop_duplicates(['item_id'], 'first')[['item_id','time']]\n",
    "df_part_3_i_b_time.columns = ['item_id','b_first_time']\n",
    "df_part_3_i_b_b4_time = pd.merge(df_part_3_i_b_time, df_part_3_i_b4_time, on = ['item_id'])\n",
    "df_part_3_i_b_b4_time['i_b4_diff_time']  = df_part_3_i_b_b4_time['b4_first_time'] - df_part_3_i_b_b4_time['b_first_time']\n",
    "df_part_3_i_b_b4_time['i_b4_diff_hours'] = df_part_3_i_b_b4_time['i_b4_diff_time'].apply(lambda x: x.days * 24 + x.seconds//3600)\n",
    "df_part_3_i_b_b4_time = df_part_3_i_b_b4_time[['item_id', 'i_b4_diff_hours']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a215513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating feature set I\n",
    "f_I_part_3 = pd.merge(df_part_3_i_b_count, \n",
    "                      df_part_3_i_b_b4_time, \n",
    "                      on = ['item_id'], how = 'left')\n",
    "f_I_part_3 = pd.merge(f_I_part_3, \n",
    "                      df_part_3_i_u_count, \n",
    "                      on = ['item_id'], how = 'left')[['item_id', \n",
    "                                                       'i_u_count_in_6', \n",
    "                                                       'i_u_count_in_3', \n",
    "                                                       'i_u_count_in_1',\n",
    "                                                       'i_b1_count_in_6', \n",
    "                                                       'i_b2_count_in_6', \n",
    "                                                       'i_b3_count_in_6', \n",
    "                                                       'i_b4_count_in_6', \n",
    "                                                       'i_b_count_in_6', \n",
    "                                                       'i_b1_count_in_3',\n",
    "                                                       'i_b2_count_in_3',\n",
    "                                                       'i_b3_count_in_3',\n",
    "                                                       'i_b4_count_in_3',\n",
    "                                                       'i_b_count_in_3',\n",
    "                                                       'i_b1_count_in_1', \n",
    "                                                       'i_b2_count_in_1', \n",
    "                                                       'i_b3_count_in_1', \n",
    "                                                       'i_b4_count_in_1', \n",
    "                                                       'i_b_count_in_1',\n",
    "                                                       'i_b4_rate', \n",
    "                                                       'i_b4_diff_hours']]\n",
    "                      \n",
    "# write to csv file\n",
    "f_I_part_3 = f_I_part_3.round({'i_b4_rate': 3})\n",
    "f_I_part_3.to_csv(path_df_part_3_I, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03c6cd34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Step 1.3 feature data set C of df_part_3\\n    (1)\\n    c_u_count_in_6\\n    c_u_count_in_3\\n    c_u_count_in_1\\n    (2)\\n    c_b1_count_in_6\\n    c_b2_count_in_6\\n    c_b3_count_in_6\\n    c_b4_count_in_6\\n     c_b_count_in_6\\n    c_b1_count_in_3\\n    c_b2_count_in_3\\n    c_b3_count_in_3\\n    c_b4_count_in_3\\n     c_b_count_in_3\\n    c_b1_count_in_1\\n    c_b2_count_in_1\\n    c_b3_count_in_1\\n    c_b4_count_in_1\\n     c_b_count_in_1\\n    (3)\\n    c_b4_rate  (in_6)\\n    c_b4_diff_hours  (in_6)\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Step 1.3 feature data set C of df_part_3\n",
    "    (1)\n",
    "    c_u_count_in_6\n",
    "    c_u_count_in_3\n",
    "    c_u_count_in_1\n",
    "    (2)\n",
    "    c_b1_count_in_6\n",
    "    c_b2_count_in_6\n",
    "    c_b3_count_in_6\n",
    "    c_b4_count_in_6\n",
    "     c_b_count_in_6\n",
    "    c_b1_count_in_3\n",
    "    c_b2_count_in_3\n",
    "    c_b3_count_in_3\n",
    "    c_b4_count_in_3\n",
    "     c_b_count_in_3\n",
    "    c_b1_count_in_1\n",
    "    c_b2_count_in_1\n",
    "    c_b3_count_in_1\n",
    "    c_b4_count_in_1\n",
    "     c_b_count_in_1\n",
    "    (3)\n",
    "    c_b4_rate  (in_6)\n",
    "    c_b4_diff_hours  (in_6)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88fba084",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15494/304231883.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_part_3_in_6['c_u_count_in_6'] = df_part_3_in_6.groupby('item_category').cumcount() + 1\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15494/304231883.py:12: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_3_c_u_count_in_6 = df_part_3_in_6.drop_duplicates(['item_category'], 'last')[['item_category', 'c_u_count_in_6']]\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15494/304231883.py:17: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_3_c_u_count_in_3 = df_part_3_in_3.drop_duplicates(['item_category'], 'last')[['item_category', 'c_u_count_in_3']]\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15494/304231883.py:22: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_3_c_u_count_in_1 = df_part_3_in_1.drop_duplicates(['item_category'], 'last')[['item_category', 'c_u_count_in_1']]\n"
     ]
    }
   ],
   "source": [
    "# loading data\n",
    "path_df = open(path_df_part_3, 'r')\n",
    "try:\n",
    "    df_part_3 = pd.read_csv(path_df, index_col = False, parse_dates = [0])\n",
    "    df_part_3.columns = ['time','user_id','item_id','behavior_type','item_category']\n",
    "finally:\n",
    "    path_df.close()\n",
    "    \n",
    "# c_u_count_in_6\n",
    "df_part_3_in_6 = df_part_3.drop_duplicates(['item_category', 'user_id'])\n",
    "df_part_3_in_6['c_u_count_in_6'] = df_part_3_in_6.groupby('item_category').cumcount() + 1\n",
    "df_part_3_c_u_count_in_6 = df_part_3_in_6.drop_duplicates(['item_category'], 'last')[['item_category', 'c_u_count_in_6']]\n",
    "\n",
    "# c_u_count_in_3\n",
    "df_part_3_in_3 = df_part_3[df_part_3['time'] >= np.datetime64('2014-12-16')].drop_duplicates(['item_category', 'user_id'])\n",
    "df_part_3_in_3['c_u_count_in_3'] = df_part_3_in_3.groupby('item_category').cumcount() + 1\n",
    "df_part_3_c_u_count_in_3 = df_part_3_in_3.drop_duplicates(['item_category'], 'last')[['item_category', 'c_u_count_in_3']]\n",
    "\n",
    "# c_u_count_in_1\n",
    "df_part_3_in_1 = df_part_3[df_part_3['time'] >= np.datetime64('2014-12-18')].drop_duplicates(['item_category', 'user_id'])\n",
    "df_part_3_in_1['c_u_count_in_1'] = df_part_3_in_1.groupby('item_category').cumcount() + 1\n",
    "df_part_3_c_u_count_in_1 = df_part_3_in_1.drop_duplicates(['item_category'], 'last')[['item_category', 'c_u_count_in_1']]\n",
    "\n",
    "df_part_3_c_u_count = pd.merge(df_part_3_c_u_count_in_6, df_part_3_c_u_count_in_3,on=['item_category'],how='left').fillna(0)\n",
    "df_part_3_c_u_count = pd.merge(df_part_3_c_u_count, df_part_3_c_u_count_in_1,on=['item_category'],how='left').fillna(0)\n",
    "df_part_3_c_u_count[['c_u_count_in_6',\n",
    "                     'c_u_count_in_3',\n",
    "                     'c_u_count_in_1']] = df_part_3_c_u_count[['c_u_count_in_6',\n",
    "                                                               'c_u_count_in_3',\n",
    "                                                               'c_u_count_in_1']].astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de1aee6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15494/592882810.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_3_c_b_count_in_6 = df_part_3.drop_duplicates(['item_category','behavior_type'], 'last')[['item_category','behavior_type','cumcount']]\n"
     ]
    }
   ],
   "source": [
    "# c_b_count_in_6\n",
    "df_part_3['cumcount'] = df_part_3.groupby(['item_category', 'behavior_type']).cumcount()\n",
    "df_part_3_c_b_count_in_6 = df_part_3.drop_duplicates(['item_category','behavior_type'], 'last')[['item_category','behavior_type','cumcount']]\n",
    "df_part_3_c_b_count_in_6 = pd.get_dummies(df_part_3_c_b_count_in_6['behavior_type']).join(df_part_3_c_b_count_in_6[['item_category','cumcount']])\n",
    "df_part_3_c_b_count_in_6.rename(columns = {1:'behavior_type_1',\n",
    "                                           2:'behavior_type_2',\n",
    "                                           3:'behavior_type_3',\n",
    "                                           4:'behavior_type_4'}, inplace=True)\n",
    "df_part_3_c_b_count_in_6['c_b1_count_in_6'] = df_part_3_c_b_count_in_6['behavior_type_1'] * (df_part_3_c_b_count_in_6['cumcount']+1)\n",
    "df_part_3_c_b_count_in_6['c_b2_count_in_6'] = df_part_3_c_b_count_in_6['behavior_type_2'] * (df_part_3_c_b_count_in_6['cumcount']+1)\n",
    "df_part_3_c_b_count_in_6['c_b3_count_in_6'] = df_part_3_c_b_count_in_6['behavior_type_3'] * (df_part_3_c_b_count_in_6['cumcount']+1)\n",
    "df_part_3_c_b_count_in_6['c_b4_count_in_6'] = df_part_3_c_b_count_in_6['behavior_type_4'] * (df_part_3_c_b_count_in_6['cumcount']+1)\n",
    "df_part_3_c_b_count_in_6 = df_part_3_c_b_count_in_6[['item_category', \n",
    "                                                     'c_b1_count_in_6', \n",
    "                                                     'c_b2_count_in_6', \n",
    "                                                     'c_b3_count_in_6',\n",
    "                                                     'c_b4_count_in_6']]\n",
    "df_part_3_c_b_count_in_6 = df_part_3_c_b_count_in_6.groupby('item_category').agg({'c_b1_count_in_6': np.sum,\n",
    "                                                                                  'c_b2_count_in_6': np.sum,\n",
    "                                                                                  'c_b3_count_in_6': np.sum,\n",
    "                                                                                  'c_b4_count_in_6': np.sum})\n",
    "df_part_3_c_b_count_in_6.reset_index(inplace = True)\n",
    "df_part_3_c_b_count_in_6['c_b_count_in_6'] = df_part_3_c_b_count_in_6['c_b1_count_in_6'] + \\\n",
    "                                             df_part_3_c_b_count_in_6['c_b2_count_in_6'] + \\\n",
    "                                             df_part_3_c_b_count_in_6['c_b3_count_in_6'] + \\\n",
    "                                             df_part_3_c_b_count_in_6['c_b4_count_in_6']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99208600",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15494/2387681510.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_part_3_in_3['cumcount'] = df_part_3_in_3.groupby(['item_category', 'behavior_type']).cumcount()\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15494/2387681510.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_3_c_b_count_in_3 = df_part_3_in_3.drop_duplicates(['item_category','behavior_type'], 'last')[['item_category','behavior_type','cumcount']]\n"
     ]
    }
   ],
   "source": [
    "# c_b_count_in_3\n",
    "df_part_3_in_3 = df_part_3[df_part_3['time'] >= np.datetime64('2014-12-16')]\n",
    "df_part_3_in_3['cumcount'] = df_part_3_in_3.groupby(['item_category', 'behavior_type']).cumcount()\n",
    "df_part_3_c_b_count_in_3 = df_part_3_in_3.drop_duplicates(['item_category','behavior_type'], 'last')[['item_category','behavior_type','cumcount']]\n",
    "df_part_3_c_b_count_in_3 = pd.get_dummies(df_part_3_c_b_count_in_3['behavior_type']).join(df_part_3_c_b_count_in_3[['item_category','cumcount']])\n",
    "df_part_3_c_b_count_in_3.rename(columns = {1:'behavior_type_1',\n",
    "                                           2:'behavior_type_2',\n",
    "                                           3:'behavior_type_3',\n",
    "                                           4:'behavior_type_4'}, inplace=True)\n",
    "df_part_3_c_b_count_in_3['c_b1_count_in_3'] = df_part_3_c_b_count_in_3['behavior_type_1'] * (df_part_3_c_b_count_in_3['cumcount']+1)\n",
    "df_part_3_c_b_count_in_3['c_b2_count_in_3'] = df_part_3_c_b_count_in_3['behavior_type_2'] * (df_part_3_c_b_count_in_3['cumcount']+1)\n",
    "df_part_3_c_b_count_in_3['c_b3_count_in_3'] = df_part_3_c_b_count_in_3['behavior_type_3'] * (df_part_3_c_b_count_in_3['cumcount']+1)\n",
    "df_part_3_c_b_count_in_3['c_b4_count_in_3'] = df_part_3_c_b_count_in_3['behavior_type_4'] * (df_part_3_c_b_count_in_3['cumcount']+1)\n",
    "df_part_3_c_b_count_in_3 = df_part_3_c_b_count_in_3[['item_category', \n",
    "                                                     'c_b1_count_in_3', \n",
    "                                                     'c_b2_count_in_3', \n",
    "                                                     'c_b3_count_in_3',\n",
    "                                                     'c_b4_count_in_3']]\n",
    "df_part_3_c_b_count_in_3 = df_part_3_c_b_count_in_3.groupby('item_category').agg({'c_b1_count_in_3': np.sum,\n",
    "                                                                                  'c_b2_count_in_3': np.sum,\n",
    "                                                                                  'c_b3_count_in_3': np.sum,\n",
    "                                                                                  'c_b4_count_in_3': np.sum})\n",
    "df_part_3_c_b_count_in_3.reset_index(inplace = True)\n",
    "df_part_3_c_b_count_in_3['c_b_count_in_3'] = df_part_3_c_b_count_in_3['c_b1_count_in_3'] + \\\n",
    "                                             df_part_3_c_b_count_in_3['c_b2_count_in_3'] + \\\n",
    "                                             df_part_3_c_b_count_in_3['c_b3_count_in_3'] + \\\n",
    "                                             df_part_3_c_b_count_in_3['c_b4_count_in_3']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7777c05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15494/2655015251.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_part_3_in_1['cumcount'] = df_part_3_in_1.groupby(['item_category', 'behavior_type']).cumcount()\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15494/2655015251.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_3_c_b_count_in_1 = df_part_3_in_1.drop_duplicates(['item_category','behavior_type'], 'last')[['item_category','behavior_type','cumcount']]\n"
     ]
    }
   ],
   "source": [
    "# c_b_count_in_1\n",
    "df_part_3_in_1 = df_part_3[df_part_3['time'] >= np.datetime64('2014-12-18')]\n",
    "df_part_3_in_1['cumcount'] = df_part_3_in_1.groupby(['item_category', 'behavior_type']).cumcount()\n",
    "df_part_3_c_b_count_in_1 = df_part_3_in_1.drop_duplicates(['item_category','behavior_type'], 'last')[['item_category','behavior_type','cumcount']]\n",
    "df_part_3_c_b_count_in_1 = pd.get_dummies(df_part_3_c_b_count_in_1['behavior_type']).join(df_part_3_c_b_count_in_1[['item_category','cumcount']])\n",
    "df_part_3_c_b_count_in_1.rename(columns = {1:'behavior_type_1',\n",
    "                                           2:'behavior_type_2',\n",
    "                                           3:'behavior_type_3',\n",
    "                                           4:'behavior_type_4'}, inplace=True)\n",
    "df_part_3_c_b_count_in_1['c_b1_count_in_1'] = df_part_3_c_b_count_in_1['behavior_type_1'] * (df_part_3_c_b_count_in_1['cumcount']+1)\n",
    "df_part_3_c_b_count_in_1['c_b2_count_in_1'] = df_part_3_c_b_count_in_1['behavior_type_2'] * (df_part_3_c_b_count_in_1['cumcount']+1)\n",
    "df_part_3_c_b_count_in_1['c_b3_count_in_1'] = df_part_3_c_b_count_in_1['behavior_type_3'] * (df_part_3_c_b_count_in_1['cumcount']+1)\n",
    "df_part_3_c_b_count_in_1['c_b4_count_in_1'] = df_part_3_c_b_count_in_1['behavior_type_4'] * (df_part_3_c_b_count_in_1['cumcount']+1)\n",
    "df_part_3_c_b_count_in_1 = df_part_3_c_b_count_in_1[['item_category', \n",
    "                                                     'c_b1_count_in_1', \n",
    "                                                     'c_b2_count_in_1', \n",
    "                                                     'c_b3_count_in_1',\n",
    "                                                     'c_b4_count_in_1']]\n",
    "df_part_3_c_b_count_in_1 = df_part_3_c_b_count_in_1.groupby('item_category').agg({'c_b1_count_in_1': np.sum,\n",
    "                                                                                  'c_b2_count_in_1': np.sum,\n",
    "                                                                                  'c_b3_count_in_1': np.sum,\n",
    "                                                                                  'c_b4_count_in_1': np.sum})\n",
    "df_part_3_c_b_count_in_1.reset_index(inplace = True)\n",
    "df_part_3_c_b_count_in_1['c_b_count_in_1'] = df_part_3_c_b_count_in_1['c_b1_count_in_1'] + \\\n",
    "                                             df_part_3_c_b_count_in_1['c_b2_count_in_1'] + \\\n",
    "                                             df_part_3_c_b_count_in_1['c_b3_count_in_1'] + \\\n",
    "                                             df_part_3_c_b_count_in_1['c_b4_count_in_1']    \n",
    "                                             \n",
    "df_part_3_c_b_count = pd.merge(df_part_3_c_b_count_in_6, df_part_3_c_b_count_in_3, on = ['item_category'], how = 'left').fillna(0)                                      \n",
    "df_part_3_c_b_count = pd.merge(df_part_3_c_b_count, df_part_3_c_b_count_in_1, on = ['item_category'], how = 'left').fillna(0)\n",
    "df_part_3_c_b_count[['c_b1_count_in_6',\n",
    "                     'c_b2_count_in_6',\n",
    "                     'c_b3_count_in_6',\n",
    "                     'c_b4_count_in_6',\n",
    "                      'c_b_count_in_6',\n",
    "                     'c_b1_count_in_3',\n",
    "                     'c_b2_count_in_3',\n",
    "                     'c_b3_count_in_3',\n",
    "                     'c_b4_count_in_3',\n",
    "                      'c_b_count_in_3',\n",
    "                     'c_b1_count_in_1',\n",
    "                     'c_b2_count_in_1',\n",
    "                     'c_b3_count_in_1',\n",
    "                     'c_b4_count_in_1',\n",
    "                      'c_b_count_in_1']] = df_part_3_c_b_count[['c_b1_count_in_6',\n",
    "                                                                'c_b2_count_in_6',\n",
    "                                                                'c_b3_count_in_6',\n",
    "                                                                'c_b4_count_in_6',\n",
    "                                                                 'c_b_count_in_6',\n",
    "                                                                'c_b1_count_in_3',\n",
    "                                                                'c_b2_count_in_3',\n",
    "                                                                'c_b3_count_in_3',\n",
    "                                                                'c_b4_count_in_3',\n",
    "                                                                 'c_b_count_in_3',\n",
    "                                                                'c_b1_count_in_1',\n",
    "                                                                'c_b2_count_in_1',\n",
    "                                                                'c_b3_count_in_1',\n",
    "                                                                'c_b4_count_in_1',\n",
    "                                                                 'c_b_count_in_1']].astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fff84b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15494/1907502808.py:6: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_3_c_b4_time = df_part_3[df_part_3['behavior_type'] == 4].drop_duplicates(['item_category'], 'first')[['item_category','time']]\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15494/1907502808.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_3_c_b_time = df_part_3.drop_duplicates(['item_category'], 'first')[['item_category','time']]\n"
     ]
    }
   ],
   "source": [
    "# c_b4_rate\n",
    "df_part_3_c_b_count['c_b4_rate'] = df_part_3_c_b_count['c_b4_count_in_6'] / df_part_3_c_b_count['c_b_count_in_6']\n",
    "\n",
    "# c_b4_diff_time\n",
    "df_part_3 = df_part_3.sort_values(by=['item_category', 'time'])\n",
    "df_part_3_c_b4_time = df_part_3[df_part_3['behavior_type'] == 4].drop_duplicates(['item_category'], 'first')[['item_category','time']]\n",
    "df_part_3_c_b4_time.columns = ['item_category','b4_first_time']\n",
    "df_part_3_c_b_time = df_part_3.drop_duplicates(['item_category'], 'first')[['item_category','time']]\n",
    "df_part_3_c_b_time.columns = ['item_category','b_first_time']\n",
    "df_part_3_c_b_b4_time = pd.merge(df_part_3_c_b_time, df_part_3_c_b4_time, on = ['item_category'])\n",
    "df_part_3_c_b_b4_time['c_b4_diff_time']  = df_part_3_c_b_b4_time['b4_first_time'] - df_part_3_c_b_b4_time['b_first_time']\n",
    "df_part_3_c_b_b4_time['c_b4_diff_hours'] = df_part_3_c_b_b4_time['c_b4_diff_time'].apply(lambda x: x.days * 24 + x.seconds//3600)\n",
    "df_part_3_c_b_b4_time = df_part_3_c_b_b4_time[['item_category',\n",
    "                                               'c_b4_diff_hours']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "00a8b97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating feature set C\n",
    "f_C_part_3 = pd.merge(df_part_3_c_u_count, df_part_3_c_b_count, on = ['item_category'], how = 'left')\n",
    "f_C_part_3 = pd.merge(f_C_part_3, df_part_3_c_b_b4_time, on = ['item_category'], how = 'left')\n",
    "f_C_part_3 = f_C_part_3.round({'c_b4_rate': 3})\n",
    "\n",
    "# write to csv file\n",
    "f_C_part_3.to_csv(path_df_part_3_C, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c8dbca24",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "'''Step 1.4 feature data set IC of df_part_3\n",
    "    ic_u_rank_in_c  (in_6)\n",
    "    ic_b_rank_in_c  (in_6)\n",
    "    ic_b4_rank_in_c  (in_6)\n",
    "'''\n",
    "\n",
    "\n",
    "# get df_part_3_i_ub_count\n",
    "path_df = open(path_df_part_3_I, 'r')\n",
    "try:\n",
    "    df_part_3_I = pd.read_csv(path_df, index_col = False)\n",
    "finally:\n",
    "    path_df.close()\n",
    "df_part_3_i_ub_count = df_part_3_I[['item_id','i_u_count_in_6','i_b_count_in_6','i_b4_count_in_6']]\n",
    "del(df_part_3_I)\n",
    "\n",
    "# get df_part_3_uic for merge i & c\n",
    "path_df = open(path_df_part_3_uic, 'r')\n",
    "try:\n",
    "    df_part_3_uic = pd.read_csv(path_df, index_col = False)\n",
    "finally:\n",
    "    path_df.close()\n",
    "df_part_3_ic_u_b_count = pd.merge(df_part_3_uic, df_part_3_i_ub_count, on=['item_id'], how='left').fillna(0)\n",
    "df_part_3_ic_u_b_count = df_part_3_ic_u_b_count.drop_duplicates(['item_id','item_category'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "09ecf4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ic_u_rank_in_c\n",
    "df_part_3_ic_u_b_count['ic_u_rank_in_c'] = df_part_3_ic_u_b_count.groupby('item_category')['i_u_count_in_6'].rank(method='min',ascending=False).astype('int')\n",
    "# ic_b_rank_in_c\n",
    "df_part_3_ic_u_b_count['ic_b_rank_in_c'] = df_part_3_ic_u_b_count.groupby('item_category')['i_b_count_in_6'].rank(method='min',ascending=False).astype('int')\n",
    "# ic_b4_rank_in_c\n",
    "df_part_3_ic_u_b_count['ic_b4_rank_in_c'] = df_part_3_ic_u_b_count.groupby('item_category')['i_b4_count_in_6'].rank(method='min',ascending=False).astype('int')\n",
    "\n",
    "f_IC_part_3 = df_part_3_ic_u_b_count[['item_id', \n",
    "                                      'item_category', \n",
    "                                      'ic_u_rank_in_c', \n",
    "                                      'ic_b_rank_in_c', \n",
    "                                      'ic_b4_rank_in_c']]\n",
    "# write to csv file\n",
    "f_IC_part_3.to_csv(path_df_part_3_IC, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72387b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Step 1.5 feature data set UI of df_part_3\n",
    "    (1)\n",
    "    ui_b1_count_in_6\n",
    "    ui_b2_count_in_6\n",
    "    ui_b3_count_in_6\n",
    "    ui_b4_count_in_6\n",
    "     ui_b_count_in_6\n",
    "    ui_b1_count_in_3\n",
    "    ui_b2_count_in_3\n",
    "    ui_b3_count_in_3\n",
    "    ui_b4_count_in_3\n",
    "     ui_b_count_in_3\n",
    "    ui_b1_count_in_1\n",
    "    ui_b2_count_in_1\n",
    "    ui_b3_count_in_1\n",
    "    ui_b4_count_in_1\n",
    "     ui_b_count_in_1\n",
    "    (2)\n",
    "    ui_b_count_rank_in_u  (in_6)\n",
    "    ui_b_count_rank_in_uc (in_6)\n",
    "    (3)\n",
    "    ui_b1_last_hours  (in_6)\n",
    "    ui_b2_last_hours  (in_6)\n",
    "    ui_b3_last_hours  (in_6)\n",
    "    ui_b4_last_hours  (in_6)\n",
    "'''\n",
    "\n",
    "\n",
    "path_df = open(path_df_part_3, 'r')\n",
    "try:\n",
    "    df_part_3 = pd.read_csv(path_df, index_col = False, parse_dates = [0])\n",
    "    df_part_3.columns = ['time','user_id','item_id','behavior_type','item_category']\n",
    "finally:\n",
    "    path_df.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "25e461c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15494/2646421850.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_3_ui_b_count_in_6 = df_part_3.drop_duplicates(['user_id','item_id','behavior_type'],'last')[['user_id','item_id','behavior_type','cumcount']]\n"
     ]
    }
   ],
   "source": [
    "# ui_b_count_in_6\n",
    "df_part_3['cumcount'] = df_part_3.groupby(['user_id', 'item_id', 'behavior_type']).cumcount()\n",
    "df_part_3_ui_b_count_in_6 = df_part_3.drop_duplicates(['user_id','item_id','behavior_type'],'last')[['user_id','item_id','behavior_type','cumcount']]\n",
    "df_part_3_ui_b_count_in_6 = pd.get_dummies(df_part_3_ui_b_count_in_6['behavior_type']).join(df_part_3_ui_b_count_in_6[['user_id','item_id','cumcount']])\n",
    "df_part_3_ui_b_count_in_6.rename(columns = {1:'behavior_type_1',\n",
    "                                            2:'behavior_type_2',\n",
    "                                            3:'behavior_type_3',\n",
    "                                            4:'behavior_type_4'}, inplace=True)  \n",
    "df_part_3_ui_b_count_in_6['ui_b1_count_in_6'] = df_part_3_ui_b_count_in_6['behavior_type_1'] * (df_part_3_ui_b_count_in_6['cumcount']+1)\n",
    "df_part_3_ui_b_count_in_6['ui_b2_count_in_6'] = df_part_3_ui_b_count_in_6['behavior_type_2'] * (df_part_3_ui_b_count_in_6['cumcount']+1)\n",
    "df_part_3_ui_b_count_in_6['ui_b3_count_in_6'] = df_part_3_ui_b_count_in_6['behavior_type_3'] * (df_part_3_ui_b_count_in_6['cumcount']+1)\n",
    "df_part_3_ui_b_count_in_6['ui_b4_count_in_6'] = df_part_3_ui_b_count_in_6['behavior_type_4'] * (df_part_3_ui_b_count_in_6['cumcount']+1)\n",
    "df_part_3_ui_b_count_in_6 = df_part_3_ui_b_count_in_6[['user_id', \n",
    "                                                       'item_id', \n",
    "                                                       'ui_b1_count_in_6', \n",
    "                                                       'ui_b2_count_in_6', \n",
    "                                                       'ui_b3_count_in_6',\n",
    "                                                       'ui_b4_count_in_6']]\n",
    "df_part_3_ui_b_count_in_6 = df_part_3_ui_b_count_in_6.groupby(['user_id', 'item_id']).agg({'ui_b1_count_in_6': np.sum,\n",
    "                                                                                           'ui_b2_count_in_6': np.sum,\n",
    "                                                                                           'ui_b3_count_in_6': np.sum,\n",
    "                                                                                           'ui_b4_count_in_6': np.sum})\n",
    "df_part_3_ui_b_count_in_6.reset_index(inplace = True)\n",
    "df_part_3_ui_b_count_in_6['ui_b_count_in_6'] = df_part_3_ui_b_count_in_6['ui_b1_count_in_6'] + \\\n",
    "                                               df_part_3_ui_b_count_in_6['ui_b2_count_in_6'] + \\\n",
    "                                               df_part_3_ui_b_count_in_6['ui_b3_count_in_6'] + \\\n",
    "                                               df_part_3_ui_b_count_in_6['ui_b4_count_in_6']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "02309ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15494/3010479064.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_part_3_in_3['cumcount'] = df_part_3_in_3.groupby(['user_id', 'item_id', 'behavior_type']).cumcount()\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15494/3010479064.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_3_ui_b_count_in_3 = df_part_3.drop_duplicates(['user_id','item_id','behavior_type'],'last')[['user_id','item_id','behavior_type','cumcount']]\n"
     ]
    }
   ],
   "source": [
    "# ui_b_count_in_3\n",
    "df_part_3_in_3 = df_part_3[df_part_3['time'] >= np.datetime64('2014-12-16')]\n",
    "df_part_3_in_3['cumcount'] = df_part_3_in_3.groupby(['user_id', 'item_id', 'behavior_type']).cumcount()\n",
    "df_part_3_ui_b_count_in_3 = df_part_3.drop_duplicates(['user_id','item_id','behavior_type'],'last')[['user_id','item_id','behavior_type','cumcount']]\n",
    "df_part_3_ui_b_count_in_3 = pd.get_dummies(df_part_3_ui_b_count_in_3['behavior_type']).join(df_part_3_ui_b_count_in_3[['user_id','item_id','cumcount']])\n",
    "df_part_3_ui_b_count_in_3.rename(columns = {1:'behavior_type_1',\n",
    "                                            2:'behavior_type_2',\n",
    "                                            3:'behavior_type_3',\n",
    "                                            4:'behavior_type_4'}, inplace=True)  \n",
    "df_part_3_ui_b_count_in_3['ui_b1_count_in_3'] = df_part_3_ui_b_count_in_3['behavior_type_1'] * (df_part_3_ui_b_count_in_3['cumcount']+1)\n",
    "df_part_3_ui_b_count_in_3['ui_b2_count_in_3'] = df_part_3_ui_b_count_in_3['behavior_type_2'] * (df_part_3_ui_b_count_in_3['cumcount']+1)\n",
    "df_part_3_ui_b_count_in_3['ui_b3_count_in_3'] = df_part_3_ui_b_count_in_3['behavior_type_3'] * (df_part_3_ui_b_count_in_3['cumcount']+1)\n",
    "df_part_3_ui_b_count_in_3['ui_b4_count_in_3'] = df_part_3_ui_b_count_in_3['behavior_type_4'] * (df_part_3_ui_b_count_in_3['cumcount']+1)\n",
    "df_part_3_ui_b_count_in_3 = df_part_3_ui_b_count_in_3[['user_id', \n",
    "                                                       'item_id', \n",
    "                                                       'ui_b1_count_in_3', \n",
    "                                                       'ui_b2_count_in_3', \n",
    "                                                       'ui_b3_count_in_3',\n",
    "                                                       'ui_b4_count_in_3']]\n",
    "df_part_3_ui_b_count_in_3 = df_part_3_ui_b_count_in_3.groupby(['user_id', 'item_id']).agg({'ui_b1_count_in_3': np.sum,\n",
    "                                                                                           'ui_b2_count_in_3': np.sum,\n",
    "                                                                                           'ui_b3_count_in_3': np.sum,\n",
    "                                                                                           'ui_b4_count_in_3': np.sum})\n",
    "df_part_3_ui_b_count_in_3.reset_index(inplace = True)\n",
    "df_part_3_ui_b_count_in_3['ui_b_count_in_3'] = df_part_3_ui_b_count_in_3['ui_b1_count_in_3'] + \\\n",
    "                                               df_part_3_ui_b_count_in_3['ui_b2_count_in_3'] + \\\n",
    "                                               df_part_3_ui_b_count_in_3['ui_b3_count_in_3'] + \\\n",
    "                                               df_part_3_ui_b_count_in_3['ui_b4_count_in_3']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e689f247",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15494/2798784129.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_part_3_in_1['cumcount'] = df_part_3_in_1.groupby(['user_id', 'item_id', 'behavior_type']).cumcount()\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15494/2798784129.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_3_ui_b_count_in_1 = df_part_3_in_1.drop_duplicates(['user_id','item_id','behavior_type'], 'last')[['user_id','item_id','behavior_type','cumcount']]\n"
     ]
    }
   ],
   "source": [
    "# ui_b_count_in_1\n",
    "df_part_3_in_1 = df_part_3[df_part_3['time'] >= np.datetime64('2014-12-18')]\n",
    "df_part_3_in_1['cumcount'] = df_part_3_in_1.groupby(['user_id', 'item_id', 'behavior_type']).cumcount()\n",
    "df_part_3_ui_b_count_in_1 = df_part_3_in_1.drop_duplicates(['user_id','item_id','behavior_type'], 'last')[['user_id','item_id','behavior_type','cumcount']]\n",
    "df_part_3_ui_b_count_in_1 = pd.get_dummies(df_part_3_ui_b_count_in_1['behavior_type']).join(df_part_3_ui_b_count_in_1[['user_id','item_id','cumcount']])\n",
    "df_part_3_ui_b_count_in_1.rename(columns = {1:'behavior_type_1',\n",
    "                                            2:'behavior_type_2',\n",
    "                                            3:'behavior_type_3',\n",
    "                                            4:'behavior_type_4'}, inplace=True)\n",
    "df_part_3_ui_b_count_in_1['ui_b1_count_in_1'] = df_part_3_ui_b_count_in_1['behavior_type_1'] * (df_part_3_ui_b_count_in_1['cumcount']+1)\n",
    "df_part_3_ui_b_count_in_1['ui_b2_count_in_1'] = df_part_3_ui_b_count_in_1['behavior_type_2'] * (df_part_3_ui_b_count_in_1['cumcount']+1)\n",
    "df_part_3_ui_b_count_in_1['ui_b3_count_in_1'] = df_part_3_ui_b_count_in_1['behavior_type_3'] * (df_part_3_ui_b_count_in_1['cumcount']+1)\n",
    "df_part_3_ui_b_count_in_1['ui_b4_count_in_1'] = df_part_3_ui_b_count_in_1['behavior_type_4'] * (df_part_3_ui_b_count_in_1['cumcount']+1)\n",
    "df_part_3_ui_b_count_in_1 = df_part_3_ui_b_count_in_1[['user_id',\n",
    "                                                       'item_id', \n",
    "                                                       'ui_b1_count_in_1', \n",
    "                                                       'ui_b2_count_in_1', \n",
    "                                                       'ui_b3_count_in_1',\n",
    "                                                       'ui_b4_count_in_1']]\n",
    "df_part_3_ui_b_count_in_1 = df_part_3_ui_b_count_in_1.groupby(['user_id', 'item_id']).agg({'ui_b1_count_in_1': np.sum,\n",
    "                                                                                           'ui_b2_count_in_1': np.sum,\n",
    "                                                                                           'ui_b3_count_in_1': np.sum,\n",
    "                                                                                           'ui_b4_count_in_1': np.sum})\n",
    "df_part_3_ui_b_count_in_1.reset_index(inplace = True)\n",
    "df_part_3_ui_b_count_in_1['ui_b_count_in_1'] = df_part_3_ui_b_count_in_1['ui_b1_count_in_1'] + \\\n",
    "                                               df_part_3_ui_b_count_in_1['ui_b2_count_in_1'] + \\\n",
    "                                               df_part_3_ui_b_count_in_1['ui_b3_count_in_1'] + \\\n",
    "                                               df_part_3_ui_b_count_in_1['ui_b4_count_in_1']\n",
    "                                             \n",
    "df_part_3_ui_b_count = pd.merge(df_part_3_ui_b_count_in_6, df_part_3_ui_b_count_in_3, on = ['user_id','item_id'], how = 'left').fillna(0)\n",
    "df_part_3_ui_b_count = pd.merge(df_part_3_ui_b_count, df_part_3_ui_b_count_in_1, on = ['user_id','item_id'], how = 'left').fillna(0)\n",
    "df_part_3_ui_b_count[['ui_b1_count_in_6',\n",
    "                      'ui_b2_count_in_6',\n",
    "                      'ui_b3_count_in_6',\n",
    "                      'ui_b4_count_in_6',\n",
    "                       'ui_b_count_in_6',\n",
    "                      'ui_b1_count_in_3',\n",
    "                      'ui_b2_count_in_3',\n",
    "                      'ui_b3_count_in_3',\n",
    "                      'ui_b4_count_in_3',\n",
    "                       'ui_b_count_in_3',\n",
    "                      'ui_b1_count_in_1',\n",
    "                      'ui_b2_count_in_1',\n",
    "                      'ui_b3_count_in_1',\n",
    "                      'ui_b4_count_in_1',\n",
    "                       'ui_b_count_in_1']] = df_part_3_ui_b_count[['ui_b1_count_in_6',\n",
    "                                                                   'ui_b2_count_in_6',\n",
    "                                                                   'ui_b3_count_in_6',\n",
    "                                                                   'ui_b4_count_in_6',\n",
    "                                                                    'ui_b_count_in_6',\n",
    "                                                                   'ui_b1_count_in_3',\n",
    "                                                                   'ui_b2_count_in_3',\n",
    "                                                                   'ui_b3_count_in_3',\n",
    "                                                                   'ui_b4_count_in_3',\n",
    "                                                                    'ui_b_count_in_3',\n",
    "                                                                   'ui_b1_count_in_1',\n",
    "                                                                   'ui_b2_count_in_1',\n",
    "                                                                   'ui_b3_count_in_1',\n",
    "                                                                   'ui_b4_count_in_1',\n",
    "                                                                    'ui_b_count_in_1']].astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3a68c3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ui_b_count_rank_in_u\n",
    "df_part_3_ui_b_count['ui_b_count_rank_in_u'] = df_part_3_ui_b_count.groupby(['user_id'])['ui_b_count_in_6'].rank(method='min',ascending=False).astype('int')\n",
    "\n",
    "# ui_b_count_rank_in_uc\n",
    "path_df = open(path_df_part_3_uic, 'r')\n",
    "try:\n",
    "    df_part_3_uic = pd.read_csv(path_df, index_col = False)\n",
    "finally:\n",
    "    path_df.close()\n",
    "df_part_3_ui_b_count = pd.merge(df_part_3_uic, df_part_3_ui_b_count, on = ['user_id','item_id'], how = 'left')\n",
    "df_part_3_ui_b_count['ui_b_count_rank_in_uc'] = df_part_3_ui_b_count.groupby(['user_id','item_category'])['ui_b_count_rank_in_u'].rank(method='min',ascending=True).astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "33b745f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15494/2144523673.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_3_ui_b_last_time = df_part_3.drop_duplicates(['user_id','item_id','behavior_type'],'last')[['user_id','item_id','behavior_type','time']]\n"
     ]
    }
   ],
   "source": [
    "# ui_b_last_time\n",
    "df_part_3.sort_values(by=['user_id','item_id','behavior_type','time'], inplace=True)\n",
    "df_part_3_ui_b_last_time = df_part_3.drop_duplicates(['user_id','item_id','behavior_type'],'last')[['user_id','item_id','behavior_type','time']]\n",
    "\n",
    "df_part_3_ui_b_last_time['ui_b1_last_time'] = df_part_3_ui_b_last_time[df_part_3_ui_b_last_time['behavior_type'] == 1]['time']\n",
    "df_part_3_ui_b_last_time['ui_b2_last_time'] = df_part_3_ui_b_last_time[df_part_3_ui_b_last_time['behavior_type'] == 2]['time']\n",
    "df_part_3_ui_b_last_time['ui_b3_last_time'] = df_part_3_ui_b_last_time[df_part_3_ui_b_last_time['behavior_type'] == 3]['time']\n",
    "df_part_3_ui_b_last_time['ui_b4_last_time'] = df_part_3_ui_b_last_time[df_part_3_ui_b_last_time['behavior_type'] == 4]['time']\n",
    "\n",
    "df_part_3_ui_b_last_time.loc[df_part_3_ui_b_last_time['ui_b1_last_time'].notnull(), 'ui_b1_last_hours'] = (pd.to_datetime('2014-12-19') - df_part_3_ui_b_last_time['ui_b1_last_time'])             \n",
    "df_part_3_ui_b_last_time['ui_b1_last_hours'] = df_part_3_ui_b_last_time[df_part_3_ui_b_last_time['ui_b1_last_hours'].notnull()]['ui_b1_last_hours'].apply(lambda x: x.days*24 + x.seconds//3600)\n",
    "\n",
    "df_part_3_ui_b_last_time.loc[df_part_3_ui_b_last_time['ui_b2_last_time'].notnull(), 'ui_b2_last_hours'] = (pd.to_datetime('2014-12-19') - df_part_3_ui_b_last_time['ui_b2_last_time'])             \n",
    "df_part_3_ui_b_last_time['ui_b2_last_hours'] = df_part_3_ui_b_last_time[df_part_3_ui_b_last_time['ui_b2_last_hours'].notnull()]['ui_b2_last_hours'].apply(lambda x: x.days*24 + x.seconds//3600)\n",
    "\n",
    "df_part_3_ui_b_last_time.loc[df_part_3_ui_b_last_time['ui_b3_last_time'].notnull(), 'ui_b3_last_hours'] = (pd.to_datetime('2014-12-19') - df_part_3_ui_b_last_time['ui_b3_last_time'])             \n",
    "df_part_3_ui_b_last_time['ui_b3_last_hours'] = df_part_3_ui_b_last_time[df_part_3_ui_b_last_time['ui_b3_last_hours'].notnull()]['ui_b3_last_hours'].apply(lambda x: x.days*24 + x.seconds//3600)\n",
    "\n",
    "df_part_3_ui_b_last_time.loc[df_part_3_ui_b_last_time['ui_b4_last_time'].notnull(), 'ui_b4_last_hours'] = (pd.to_datetime('2014-12-19') - df_part_3_ui_b_last_time['ui_b4_last_time'])             \n",
    "df_part_3_ui_b_last_time['ui_b4_last_hours'] = df_part_3_ui_b_last_time[df_part_3_ui_b_last_time['ui_b4_last_hours'].notnull()]['ui_b4_last_hours'].apply(lambda x: x.days*24 + x.seconds//3600)\n",
    "\n",
    "df_part_3_ui_b_last_time = df_part_3_ui_b_last_time[['user_id',\n",
    "                                                     'item_id',\n",
    "                                                     'ui_b1_last_hours',\n",
    "                                                     'ui_b2_last_hours',\n",
    "                                                     'ui_b3_last_hours',\n",
    "                                                     'ui_b4_last_hours']] \n",
    "\n",
    "df_part_3_ui_b_last_time = df_part_3_ui_b_last_time.groupby(['user_id', 'item_id']).agg({'ui_b1_last_hours': np.sum,\n",
    "                                                                                         'ui_b2_last_hours': np.sum,\n",
    "                                                                                         'ui_b3_last_hours': np.sum,\n",
    "                                                                                         'ui_b4_last_hours': np.sum})\n",
    "df_part_3_ui_b_last_time.reset_index(inplace = True)\n",
    "\n",
    "# merge for generation of f_UI_part_3\n",
    "f_UI_part_3 = pd.merge(df_part_3_ui_b_count, df_part_3_ui_b_last_time, how='left', on=['user_id', 'item_id'])\n",
    "\n",
    "# write to csv file\n",
    "f_UI_part_3.to_csv(path_df_part_3_UI, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4832eed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Step 1.6 feature data set UC of df_part_3\\n    (1)\\n    uc_b1_count_in_6\\n    uc_b2_count_in_6\\n    uc_b3_count_in_6\\n    uc_b4_count_in_6\\n     uc_b_count_in_6\\n    uc_b1_count_in_3\\n    uc_b2_count_in_3\\n    uc_b3_count_in_3\\n    uc_b4_count_in_3\\n     uc_b_count_in_3\\n    uc_b1_count_in_1\\n    uc_b2_count_in_1\\n    uc_b3_count_in_1\\n    uc_b4_count_in_1\\n     uc_b_count_in_1\\n    (2)\\n    uc_b_count_rank_in_u  (in_6)\\n    (3)\\n    uc_b1_last_hours  (in_6)\\n    uc_b2_last_hours  (in_6)\\n    uc_b3_last_hours  (in_6)\\n    uc_b4_last_hours  (in_6)\\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################################\n",
    "'''Step 1.6 feature data set UC of df_part_3\n",
    "    (1)\n",
    "    uc_b1_count_in_6\n",
    "    uc_b2_count_in_6\n",
    "    uc_b3_count_in_6\n",
    "    uc_b4_count_in_6\n",
    "     uc_b_count_in_6\n",
    "    uc_b1_count_in_3\n",
    "    uc_b2_count_in_3\n",
    "    uc_b3_count_in_3\n",
    "    uc_b4_count_in_3\n",
    "     uc_b_count_in_3\n",
    "    uc_b1_count_in_1\n",
    "    uc_b2_count_in_1\n",
    "    uc_b3_count_in_1\n",
    "    uc_b4_count_in_1\n",
    "     uc_b_count_in_1\n",
    "    (2)\n",
    "    uc_b_count_rank_in_u  (in_6)\n",
    "    (3)\n",
    "    uc_b1_last_hours  (in_6)\n",
    "    uc_b2_last_hours  (in_6)\n",
    "    uc_b3_last_hours  (in_6)\n",
    "    uc_b4_last_hours  (in_6)\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "007fdfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_df = open(path_df_part_3, 'r')\n",
    "try:\n",
    "    df_part_3 = pd.read_csv(path_df, index_col = False, parse_dates = [0])\n",
    "    df_part_3.columns = ['time','user_id','item_id','behavior_type','item_category']\n",
    "finally:\n",
    "    path_df.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9c505b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>behavior_type</th>\n",
       "      <th>item_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-12-13 14:00:00</td>\n",
       "      <td>10001082</td>\n",
       "      <td>275221686</td>\n",
       "      <td>1</td>\n",
       "      <td>10576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-12-14 03:00:00</td>\n",
       "      <td>10001082</td>\n",
       "      <td>220586551</td>\n",
       "      <td>1</td>\n",
       "      <td>7079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-12-14 16:00:00</td>\n",
       "      <td>10001082</td>\n",
       "      <td>209290607</td>\n",
       "      <td>1</td>\n",
       "      <td>5894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-12-15 08:00:00</td>\n",
       "      <td>10001082</td>\n",
       "      <td>22667958</td>\n",
       "      <td>1</td>\n",
       "      <td>10523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-12-14 03:00:00</td>\n",
       "      <td>10001082</td>\n",
       "      <td>125083630</td>\n",
       "      <td>1</td>\n",
       "      <td>4722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time   user_id    item_id  behavior_type  item_category\n",
       "0 2014-12-13 14:00:00  10001082  275221686              1          10576\n",
       "1 2014-12-14 03:00:00  10001082  220586551              1           7079\n",
       "2 2014-12-14 16:00:00  10001082  209290607              1           5894\n",
       "3 2014-12-15 08:00:00  10001082   22667958              1          10523\n",
       "4 2014-12-14 03:00:00  10001082  125083630              1           4722"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_part_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "98facb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uc_b_count_in_6\n",
    "df_part_3['cumcount'] = df_part_3.groupby(['user_id', 'item_category', 'behavior_type']).cumcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0b0bbaad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15494/420699176.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_3_uc_b_count_in_6 = df_part_3.drop_duplicates(['user_id','item_category','behavior_type'],'last')[['user_id','item_category','behavior_type','cumcount']]\n"
     ]
    }
   ],
   "source": [
    "df_part_3_uc_b_count_in_6 = df_part_3.drop_duplicates(['user_id','item_category','behavior_type'],'last')[['user_id','item_category','behavior_type','cumcount']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "21f94cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part_3_uc_b_count_in_6 = pd.get_dummies(df_part_3_uc_b_count_in_6['behavior_type']).join(df_part_3_uc_b_count_in_6[['user_id','item_category','cumcount']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "29f15846",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part_3_uc_b_count_in_6.rename(columns = {1:'behavior_type_1',\n",
    "                                            2:'behavior_type_2',\n",
    "                                            3:'behavior_type_3',\n",
    "                                            4:'behavior_type_4'}, inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e0fff1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part_3_uc_b_count_in_6['uc_b1_count_in_6'] = df_part_3_uc_b_count_in_6['behavior_type_1'] * (df_part_3_uc_b_count_in_6['cumcount']+1)\n",
    "df_part_3_uc_b_count_in_6['uc_b2_count_in_6'] = df_part_3_uc_b_count_in_6['behavior_type_2'] * (df_part_3_uc_b_count_in_6['cumcount']+1)\n",
    "df_part_3_uc_b_count_in_6['uc_b3_count_in_6'] = df_part_3_uc_b_count_in_6['behavior_type_3'] * (df_part_3_uc_b_count_in_6['cumcount']+1)\n",
    "df_part_3_uc_b_count_in_6['uc_b4_count_in_6'] = df_part_3_uc_b_count_in_6['behavior_type_4'] * (df_part_3_uc_b_count_in_6['cumcount']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e532cbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part_3_uc_b_count_in_6 = df_part_3_uc_b_count_in_6[['user_id', \n",
    "                                                       'item_category', \n",
    "                                                       'uc_b1_count_in_6', \n",
    "                                                       'uc_b2_count_in_6', \n",
    "                                                       'uc_b3_count_in_6',\n",
    "                                                       'uc_b4_count_in_6']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "90d86122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_category</th>\n",
       "      <th>uc_b1_count_in_6</th>\n",
       "      <th>uc_b2_count_in_6</th>\n",
       "      <th>uc_b3_count_in_6</th>\n",
       "      <th>uc_b4_count_in_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10001082</td>\n",
       "      <td>4722</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10001082</td>\n",
       "      <td>3200</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10001082</td>\n",
       "      <td>13230</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10001082</td>\n",
       "      <td>7079</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10001082</td>\n",
       "      <td>5334</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  item_category  uc_b1_count_in_6  uc_b2_count_in_6  \\\n",
       "4   10001082           4722                 1                 0   \n",
       "5   10001082           3200                 1                 0   \n",
       "10  10001082          13230                 1                 0   \n",
       "11  10001082           7079                 0                 0   \n",
       "13  10001082           5334                 1                 0   \n",
       "\n",
       "    uc_b3_count_in_6  uc_b4_count_in_6  \n",
       "4                  0                 0  \n",
       "5                  0                 0  \n",
       "10                 0                 0  \n",
       "11                 0                 1  \n",
       "13                 0                 0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_part_3_uc_b_count_in_6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6999cf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part_3_uc_b_count_in_6 = df_part_3_uc_b_count_in_6.groupby(['user_id', 'item_category']).agg({'uc_b1_count_in_6': np.sum,\n",
    "                                                                                                 'uc_b2_count_in_6': np.sum,\n",
    "                                                                                                 'uc_b3_count_in_6': np.sum,\n",
    "                                                                                                 'uc_b4_count_in_6': np.sum})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "df0a08ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>uc_b1_count_in_6</th>\n",
       "      <th>uc_b2_count_in_6</th>\n",
       "      <th>uc_b3_count_in_6</th>\n",
       "      <th>uc_b4_count_in_6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th>item_category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">492</th>\n",
       "      <th>2170</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2926</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6344</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6986</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7440</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       uc_b1_count_in_6  uc_b2_count_in_6  uc_b3_count_in_6  \\\n",
       "user_id item_category                                                         \n",
       "492     2170                          2                 0                 0   \n",
       "        2926                          3                 0                 0   \n",
       "        6344                          2                 0                 0   \n",
       "        6986                          2                 0                 0   \n",
       "        7440                          4                 0                 0   \n",
       "\n",
       "                       uc_b4_count_in_6  \n",
       "user_id item_category                    \n",
       "492     2170                          0  \n",
       "        2926                          0  \n",
       "        6344                          0  \n",
       "        6986                          0  \n",
       "        7440                          0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_part_3_uc_b_count_in_6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2382e3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part_3_uc_b_count_in_6.reset_index(inplace = True)\n",
    "df_part_3_uc_b_count_in_6['uc_b_count_in_6'] = df_part_3_uc_b_count_in_6['uc_b1_count_in_6'] + \\\n",
    "                                               df_part_3_uc_b_count_in_6['uc_b2_count_in_6'] + \\\n",
    "                                               df_part_3_uc_b_count_in_6['uc_b3_count_in_6'] + \\\n",
    "                                               df_part_3_uc_b_count_in_6['uc_b4_count_in_6']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "36bf7e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15494/1355581888.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_part_3_in_3['cumcount'] = df_part_3_in_3.groupby(['user_id', 'item_category', 'behavior_type']).cumcount()\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15494/1355581888.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_3_uc_b_count_in_3 = df_part_3.drop_duplicates(['user_id','item_category','behavior_type'],'last')[['user_id','item_category','behavior_type','cumcount']]\n"
     ]
    }
   ],
   "source": [
    "# uc_b_count_in_3\n",
    "df_part_3_in_3 = df_part_3[df_part_3['time'] >= np.datetime64('2014-12-16')]\n",
    "df_part_3_in_3['cumcount'] = df_part_3_in_3.groupby(['user_id', 'item_category', 'behavior_type']).cumcount()\n",
    "df_part_3_uc_b_count_in_3 = df_part_3.drop_duplicates(['user_id','item_category','behavior_type'],'last')[['user_id','item_category','behavior_type','cumcount']]\n",
    "df_part_3_uc_b_count_in_3 = pd.get_dummies(df_part_3_uc_b_count_in_3['behavior_type']).join(df_part_3_uc_b_count_in_3[['user_id','item_category','cumcount']])\n",
    "df_part_3_uc_b_count_in_3.rename(columns = {1:'behavior_type_1',\n",
    "                                            2:'behavior_type_2',\n",
    "                                            3:'behavior_type_3',\n",
    "                                            4:'behavior_type_4'}, inplace=True)  \n",
    "df_part_3_uc_b_count_in_3['uc_b1_count_in_3'] = df_part_3_uc_b_count_in_3['behavior_type_1'] * (df_part_3_uc_b_count_in_3['cumcount']+1)\n",
    "df_part_3_uc_b_count_in_3['uc_b2_count_in_3'] = df_part_3_uc_b_count_in_3['behavior_type_2'] * (df_part_3_uc_b_count_in_3['cumcount']+1)\n",
    "df_part_3_uc_b_count_in_3['uc_b3_count_in_3'] = df_part_3_uc_b_count_in_3['behavior_type_3'] * (df_part_3_uc_b_count_in_3['cumcount']+1)\n",
    "df_part_3_uc_b_count_in_3['uc_b4_count_in_3'] = df_part_3_uc_b_count_in_3['behavior_type_4'] * (df_part_3_uc_b_count_in_3['cumcount']+1)\n",
    "df_part_3_uc_b_count_in_3 = df_part_3_uc_b_count_in_3[['user_id', \n",
    "                                                       'item_category', \n",
    "                                                       'uc_b1_count_in_3', \n",
    "                                                       'uc_b2_count_in_3', \n",
    "                                                       'uc_b3_count_in_3',\n",
    "                                                       'uc_b4_count_in_3']]\n",
    "df_part_3_uc_b_count_in_3 = df_part_3_uc_b_count_in_3.groupby(['user_id', 'item_category']).agg({'uc_b1_count_in_3': np.sum,\n",
    "                                                                                                 'uc_b2_count_in_3': np.sum,\n",
    "                                                                                                 'uc_b3_count_in_3': np.sum,\n",
    "                                                                                                 'uc_b4_count_in_3': np.sum})\n",
    "df_part_3_uc_b_count_in_3.reset_index(inplace = True)\n",
    "df_part_3_uc_b_count_in_3['uc_b_count_in_3'] = df_part_3_uc_b_count_in_3['uc_b1_count_in_3'] + \\\n",
    "                                               df_part_3_uc_b_count_in_3['uc_b2_count_in_3'] + \\\n",
    "                                               df_part_3_uc_b_count_in_3['uc_b3_count_in_3'] + \\\n",
    "                                               df_part_3_uc_b_count_in_3['uc_b4_count_in_3']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b0aea990",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15494/399754624.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_part_3_in_1['cumcount'] = df_part_3_in_1.groupby(['user_id', 'item_category', 'behavior_type']).cumcount()\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15494/399754624.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_3_uc_b_count_in_1 = df_part_3_in_1.drop_duplicates(['user_id','item_category','behavior_type'], 'last')[['user_id','item_category','behavior_type','cumcount']]\n"
     ]
    }
   ],
   "source": [
    "# uc_b_count_in_1\n",
    "df_part_3_in_1 = df_part_3[df_part_3['time'] >= np.datetime64('2014-12-18')]\n",
    "df_part_3_in_1['cumcount'] = df_part_3_in_1.groupby(['user_id', 'item_category', 'behavior_type']).cumcount()\n",
    "df_part_3_uc_b_count_in_1 = df_part_3_in_1.drop_duplicates(['user_id','item_category','behavior_type'], 'last')[['user_id','item_category','behavior_type','cumcount']]\n",
    "df_part_3_uc_b_count_in_1 = pd.get_dummies(df_part_3_uc_b_count_in_1['behavior_type']).join(df_part_3_uc_b_count_in_1[['user_id','item_category','cumcount']])\n",
    "df_part_3_uc_b_count_in_1.rename(columns = {1:'behavior_type_1',\n",
    "                                            2:'behavior_type_2',\n",
    "                                            3:'behavior_type_3',\n",
    "                                            4:'behavior_type_4'}, inplace=True)\n",
    "df_part_3_uc_b_count_in_1['uc_b1_count_in_1'] = df_part_3_uc_b_count_in_1['behavior_type_1'] * (df_part_3_uc_b_count_in_1['cumcount']+1)\n",
    "df_part_3_uc_b_count_in_1['uc_b2_count_in_1'] = df_part_3_uc_b_count_in_1['behavior_type_2'] * (df_part_3_uc_b_count_in_1['cumcount']+1)\n",
    "df_part_3_uc_b_count_in_1['uc_b3_count_in_1'] = df_part_3_uc_b_count_in_1['behavior_type_3'] * (df_part_3_uc_b_count_in_1['cumcount']+1)\n",
    "df_part_3_uc_b_count_in_1['uc_b4_count_in_1'] = df_part_3_uc_b_count_in_1['behavior_type_4'] * (df_part_3_uc_b_count_in_1['cumcount']+1)\n",
    "df_part_3_uc_b_count_in_1 = df_part_3_uc_b_count_in_1[['user_id',\n",
    "                                                       'item_category', \n",
    "                                                       'uc_b1_count_in_1', \n",
    "                                                       'uc_b2_count_in_1', \n",
    "                                                       'uc_b3_count_in_1',\n",
    "                                                       'uc_b4_count_in_1']]\n",
    "df_part_3_uc_b_count_in_1 = df_part_3_uc_b_count_in_1.groupby(['user_id', 'item_category']).agg({'uc_b1_count_in_1': np.sum,\n",
    "                                                                                                 'uc_b2_count_in_1': np.sum,\n",
    "                                                                                                 'uc_b3_count_in_1': np.sum,\n",
    "                                                                                                 'uc_b4_count_in_1': np.sum})\n",
    "df_part_3_uc_b_count_in_1.reset_index(inplace = True)\n",
    "df_part_3_uc_b_count_in_1['uc_b_count_in_1'] = df_part_3_uc_b_count_in_1['uc_b1_count_in_1'] + \\\n",
    "                                               df_part_3_uc_b_count_in_1['uc_b2_count_in_1'] + \\\n",
    "                                               df_part_3_uc_b_count_in_1['uc_b3_count_in_1'] + \\\n",
    "                                               df_part_3_uc_b_count_in_1['uc_b4_count_in_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c4eb6c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part_3_uc_b_count = pd.merge(df_part_3_uc_b_count_in_6, df_part_3_uc_b_count_in_3, on = ['user_id','item_category'], how = 'left').fillna(0)\n",
    "df_part_3_uc_b_count = pd.merge(df_part_3_uc_b_count, df_part_3_uc_b_count_in_1, on = ['user_id','item_category'], how = 'left').fillna(0)\n",
    "df_part_3_uc_b_count[['uc_b1_count_in_6',\n",
    "                      'uc_b2_count_in_6',\n",
    "                      'uc_b3_count_in_6',\n",
    "                      'uc_b4_count_in_6',\n",
    "                       'uc_b_count_in_6',\n",
    "                      'uc_b1_count_in_3',\n",
    "                      'uc_b2_count_in_3',\n",
    "                      'uc_b3_count_in_3',\n",
    "                      'uc_b4_count_in_3',\n",
    "                       'uc_b_count_in_3',\n",
    "                      'uc_b1_count_in_1',\n",
    "                      'uc_b2_count_in_1',\n",
    "                      'uc_b3_count_in_1',\n",
    "                      'uc_b4_count_in_1',\n",
    "                       'uc_b_count_in_1']] = df_part_3_uc_b_count[['uc_b1_count_in_6',\n",
    "                                                                   'uc_b2_count_in_6',\n",
    "                                                                   'uc_b3_count_in_6',\n",
    "                                                                   'uc_b4_count_in_6',\n",
    "                                                                    'uc_b_count_in_6',\n",
    "                                                                   'uc_b1_count_in_3',\n",
    "                                                                   'uc_b2_count_in_3',\n",
    "                                                                   'uc_b3_count_in_3',\n",
    "                                                                   'uc_b4_count_in_3',\n",
    "                                                                    'uc_b_count_in_3',\n",
    "                                                                   'uc_b1_count_in_1',\n",
    "                                                                   'uc_b2_count_in_1',\n",
    "                                                                   'uc_b3_count_in_1',\n",
    "                                                                   'uc_b4_count_in_1',\n",
    "                                                                    'uc_b_count_in_1']].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9594069c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15494/4052594918.py:6: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_3_uc_b_last_time = df_part_3.drop_duplicates(['user_id','item_category','behavior_type'],'last')[['user_id','item_category','behavior_type','time']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " part3 done \n"
     ]
    }
   ],
   "source": [
    "# uc_b_count_rank_in_u\n",
    "df_part_3_uc_b_count['uc_b_count_rank_in_u'] = df_part_3_uc_b_count.groupby(['user_id'])['uc_b_count_in_6'].rank(method='min',ascending=False).astype('int')\n",
    "\n",
    "# uc_b_last_time\n",
    "df_part_3.sort_values(by=['user_id','item_category','behavior_type','time'], inplace=True)\n",
    "df_part_3_uc_b_last_time = df_part_3.drop_duplicates(['user_id','item_category','behavior_type'],'last')[['user_id','item_category','behavior_type','time']]\n",
    "\n",
    "df_part_3_uc_b_last_time['uc_b1_last_time'] = df_part_3_uc_b_last_time[df_part_3_uc_b_last_time['behavior_type'] == 1]['time']\n",
    "df_part_3_uc_b_last_time['uc_b2_last_time'] = df_part_3_uc_b_last_time[df_part_3_uc_b_last_time['behavior_type'] == 2]['time']\n",
    "df_part_3_uc_b_last_time['uc_b3_last_time'] = df_part_3_uc_b_last_time[df_part_3_uc_b_last_time['behavior_type'] == 3]['time']\n",
    "df_part_3_uc_b_last_time['uc_b4_last_time'] = df_part_3_uc_b_last_time[df_part_3_uc_b_last_time['behavior_type'] == 4]['time']\n",
    "\n",
    "df_part_3_uc_b_last_time.loc[df_part_3_uc_b_last_time['uc_b1_last_time'].notnull(), 'uc_b1_last_hours'] = (pd.to_datetime('2014-12-19') - df_part_3_uc_b_last_time['uc_b1_last_time'])             \n",
    "df_part_3_uc_b_last_time['uc_b1_last_hours'] = df_part_3_uc_b_last_time[df_part_3_uc_b_last_time['uc_b1_last_hours'].notnull()]['uc_b1_last_hours'].apply(lambda x: x.days*24 + x.seconds//3600)\n",
    "\n",
    "df_part_3_uc_b_last_time.loc[df_part_3_uc_b_last_time['uc_b2_last_time'].notnull(), 'uc_b2_last_hours'] = (pd.to_datetime('2014-12-19') - df_part_3_uc_b_last_time['uc_b2_last_time'])             \n",
    "df_part_3_uc_b_last_time['uc_b2_last_hours'] = df_part_3_uc_b_last_time[df_part_3_uc_b_last_time['uc_b2_last_hours'].notnull()]['uc_b2_last_hours'].apply(lambda x: x.days*24 + x.seconds//3600)\n",
    "\n",
    "df_part_3_uc_b_last_time.loc[df_part_3_uc_b_last_time['uc_b3_last_time'].notnull(), 'uc_b3_last_hours'] = (pd.to_datetime('2014-12-19') - df_part_3_uc_b_last_time['uc_b3_last_time'])             \n",
    "df_part_3_uc_b_last_time['uc_b3_last_hours'] = df_part_3_uc_b_last_time[df_part_3_uc_b_last_time['uc_b3_last_hours'].notnull()]['uc_b3_last_hours'].apply(lambda x: x.days*24 + x.seconds//3600)\n",
    "\n",
    "df_part_3_uc_b_last_time.loc[df_part_3_uc_b_last_time['uc_b4_last_time'].notnull(), 'uc_b4_last_hours'] = (pd.to_datetime('2014-12-19') - df_part_3_uc_b_last_time['uc_b4_last_time'])             \n",
    "df_part_3_uc_b_last_time['uc_b4_last_hours'] = df_part_3_uc_b_last_time[df_part_3_uc_b_last_time['uc_b4_last_hours'].notnull()]['uc_b4_last_hours'].apply(lambda x: x.days*24 + x.seconds//3600)\n",
    "\n",
    "df_part_3_uc_b_last_time = df_part_3_uc_b_last_time[['user_id',\n",
    "                                                     'item_category',\n",
    "                                                     'uc_b1_last_hours',\n",
    "                                                     'uc_b2_last_hours',\n",
    "                                                     'uc_b3_last_hours',\n",
    "                                                     'uc_b4_last_hours']] \n",
    "\n",
    "df_part_3_uc_b_last_time = df_part_3_uc_b_last_time.groupby(['user_id', 'item_category']).agg({'uc_b1_last_hours': np.sum,\n",
    "                                                                                               'uc_b2_last_hours': np.sum,\n",
    "                                                                                               'uc_b3_last_hours': np.sum,\n",
    "                                                                                               'uc_b4_last_hours': np.sum})\n",
    "df_part_3_uc_b_last_time.reset_index(inplace = True)\n",
    "\n",
    "# merge for generation of f_UC_part_3\n",
    "f_UC_part_3 = pd.merge(df_part_3_uc_b_count, df_part_3_uc_b_last_time, how='left', on=['user_id', 'item_category'])\n",
    "\n",
    "# write to csv file\n",
    "f_UC_part_3.to_csv(path_df_part_3_UC, index = False)\n",
    "\n",
    "\n",
    "print(' part3 done ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
