{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29d98a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "construct feature based on U, I, C, UI, UC, IC features types\n",
    "\n",
    "this file for data_set_part_1\n",
    "'''\n",
    "\n",
    "##### file path\n",
    "# input \n",
    "path_df_D = \"/Users/DanDan/Desktop/第一课/code/fresh_comp_offline/tianchi_fresh_comp_train_user.csv\"\n",
    "\n",
    "path_df_part_1 = \"/Users/DanDan/Desktop/第一课/code/fresh_comp_offline/df_part_1.csv\"\n",
    "path_df_part_2 = \"/Users/DanDan/Desktop/第一课/code/fresh_comp_offline/df_part_2.csv\"\n",
    "path_df_part_3 = \"/Users/DanDan/Desktop/第一课/code/fresh_comp_offline/df_part_3.csv\"\n",
    "\n",
    "path_df_part_1_tar = \"/Users/DanDan/Desktop/第一课/code/fresh_comp_offline/df_part_1_tar.csv\"\n",
    "path_df_part_2_tar = \"/Users/DanDan/Desktop/第一课/code/fresh_comp_offline/df_part_2_tar.csv\"\n",
    "\n",
    "path_df_part_1_uic_label = \"/Users/DanDan/Desktop/第一课/code/fresh_comp_offline/df_part_1_uic_label.csv\"\n",
    "path_df_part_2_uic_label = \"/Users/DanDan/Desktop/第一课/code/fresh_comp_offline/df_part_2_uic_label.csv\"\n",
    "path_df_part_3_uic       = \"/Users/DanDan/Desktop/第一课/code/fresh_comp_offline/df_part_3_uic.csv\"\n",
    "\n",
    "# output\n",
    "path_df_part_1_U   = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_1_U.csv\"  \n",
    "path_df_part_1_I   = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_1_I.csv\"\n",
    "path_df_part_1_C   = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_1_C.csv\"\n",
    "path_df_part_1_IC  = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_1_IC.csv\"\n",
    "path_df_part_1_UI  = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_1_UI.csv\"\n",
    "path_df_part_1_UC  = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_1_UC.csv\"\n",
    "\n",
    "path_df_part_2_U   = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_2_U.csv\"  \n",
    "path_df_part_2_I   = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_2_I.csv\"\n",
    "path_df_part_2_C   = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_2_C.csv\"\n",
    "path_df_part_2_IC  = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_2_IC.csv\"\n",
    "path_df_part_2_UI  = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_2_UI.csv\"\n",
    "path_df_part_2_UC  = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_2_UC.csv\"\n",
    "\n",
    "path_df_part_3_U   = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_3_U.csv\"  \n",
    "path_df_part_3_I   = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_3_I.csv\"\n",
    "path_df_part_3_C   = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_3_C.csv\"\n",
    "path_df_part_3_IC  = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_3_IC.csv\"\n",
    "path_df_part_3_UI  = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_3_UI.csv\"\n",
    "path_df_part_3_UC  = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_3_UC.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6526c736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Step 1.1 feature data set U of df_part_1\\n    (1)\\n    u_b1_count_in_6\\n    u_b2_count_in_6\\n    u_b3_count_in_6\\n    u_b4_count_in_6\\n    u_b_count_in_6\\n    (2)\\n    u_b1_count_in_3\\n    u_b2_count_in_3\\n    u_b3_count_in_3\\n    u_b4_count_in_3\\n    u_b_count_in_3\\n    (2)\\n    u_b1_count_in_1\\n    u_b2_count_in_1\\n    u_b3_count_in_1\\n    u_b4_count_in_1\\n    u_b_count_in_1\\n    (3)\\n    u_b4_rate  (in_6)\\n    u_b4_diff_hours (in_6)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# part 1\n",
    "\n",
    "'''Step 1.1 feature data set U of df_part_1\n",
    "    (1)\n",
    "    u_b1_count_in_6\n",
    "    u_b2_count_in_6\n",
    "    u_b3_count_in_6\n",
    "    u_b4_count_in_6\n",
    "    u_b_count_in_6\n",
    "    (2)\n",
    "    u_b1_count_in_3\n",
    "    u_b2_count_in_3\n",
    "    u_b3_count_in_3\n",
    "    u_b4_count_in_3\n",
    "    u_b_count_in_3\n",
    "    (2)\n",
    "    u_b1_count_in_1\n",
    "    u_b2_count_in_1\n",
    "    u_b3_count_in_1\n",
    "    u_b4_count_in_1\n",
    "    u_b_count_in_1\n",
    "    (3)\n",
    "    u_b4_rate  (in_6)\n",
    "    u_b4_diff_hours (in_6)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82a5df2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "path_df = open(path_df_part_1, 'r')\n",
    "try:\n",
    "    df_part_1 = pd.read_csv(path_df, index_col = False, parse_dates = [0])\n",
    "    df_part_1.columns = ['time','user_id','item_id','behavior_type','item_category']\n",
    "finally:\n",
    "    path_df.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7df5d593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>behavior_type</th>\n",
       "      <th>item_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-11-22 12:00:00</td>\n",
       "      <td>10001082</td>\n",
       "      <td>262112219</td>\n",
       "      <td>1</td>\n",
       "      <td>9614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-11-22 12:00:00</td>\n",
       "      <td>10001082</td>\n",
       "      <td>262112219</td>\n",
       "      <td>1</td>\n",
       "      <td>9614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-11-22 12:00:00</td>\n",
       "      <td>10001082</td>\n",
       "      <td>265860266</td>\n",
       "      <td>1</td>\n",
       "      <td>9614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-11-27 15:00:00</td>\n",
       "      <td>100029775</td>\n",
       "      <td>214252945</td>\n",
       "      <td>1</td>\n",
       "      <td>10392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-11-27 15:00:00</td>\n",
       "      <td>100029775</td>\n",
       "      <td>118033464</td>\n",
       "      <td>1</td>\n",
       "      <td>4120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time    user_id    item_id  behavior_type  item_category\n",
       "0 2014-11-22 12:00:00   10001082  262112219              1           9614\n",
       "1 2014-11-22 12:00:00   10001082  262112219              1           9614\n",
       "2 2014-11-22 12:00:00   10001082  265860266              1           9614\n",
       "3 2014-11-27 15:00:00  100029775  214252945              1          10392\n",
       "4 2014-11-27 15:00:00  100029775  118033464              1           4120"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_part_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c610511",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15291/207609390.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_1_u_b_count_in_6 = df_part_1.drop_duplicates(['user_id','behavior_type'], 'last')[['user_id','behavior_type','cumcount']]\n"
     ]
    }
   ],
   "source": [
    "# u_b_count_in_6\n",
    "df_part_1['cumcount'] = df_part_1.groupby(['user_id', 'behavior_type']).cumcount()\n",
    "df_part_1_u_b_count_in_6 = df_part_1.drop_duplicates(['user_id','behavior_type'], 'last')[['user_id','behavior_type','cumcount']]\n",
    "df_part_1_u_b_count_in_6 = pd.get_dummies(df_part_1_u_b_count_in_6['behavior_type']).join(df_part_1_u_b_count_in_6[['user_id','cumcount']])\n",
    "df_part_1_u_b_count_in_6.rename(columns = {1:'behavior_type_1',\n",
    "                                           2:'behavior_type_2',\n",
    "                                           3:'behavior_type_3',\n",
    "                                           4:'behavior_type_4'}, inplace=True)\n",
    "df_part_1_u_b_count_in_6['u_b1_count_in_6'] = df_part_1_u_b_count_in_6['behavior_type_1'] * (df_part_1_u_b_count_in_6['cumcount']+1)\n",
    "df_part_1_u_b_count_in_6['u_b2_count_in_6'] = df_part_1_u_b_count_in_6['behavior_type_2'] * (df_part_1_u_b_count_in_6['cumcount']+1)\n",
    "df_part_1_u_b_count_in_6['u_b3_count_in_6'] = df_part_1_u_b_count_in_6['behavior_type_3'] * (df_part_1_u_b_count_in_6['cumcount']+1)\n",
    "df_part_1_u_b_count_in_6['u_b4_count_in_6'] = df_part_1_u_b_count_in_6['behavior_type_4'] * (df_part_1_u_b_count_in_6['cumcount']+1)\n",
    "df_part_1_u_b_count_in_6 = df_part_1_u_b_count_in_6.groupby('user_id').agg({'u_b1_count_in_6': np.sum,\n",
    "                                                                            'u_b2_count_in_6': np.sum,\n",
    "                                                                            'u_b3_count_in_6': np.sum,\n",
    "                                                                            'u_b4_count_in_6': np.sum})\n",
    "df_part_1_u_b_count_in_6.reset_index(inplace = True)\n",
    "df_part_1_u_b_count_in_6['u_b_count_in_6'] = df_part_1_u_b_count_in_6[['u_b1_count_in_6',\n",
    "                                                                       'u_b2_count_in_6',\n",
    "                                                                       'u_b3_count_in_6',\n",
    "                                                                       'u_b4_count_in_6']].apply(lambda x: x.sum(), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c5abee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15291/3321076007.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_part_1_in_3['cumcount'] = df_part_1_in_3.groupby(['user_id', 'behavior_type']).cumcount()\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15291/3321076007.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_1_u_b_count_in_3 = df_part_1.drop_duplicates(['user_id','behavior_type'], 'last')[['user_id','behavior_type','cumcount']]\n"
     ]
    }
   ],
   "source": [
    "# u_b_count_in_3\n",
    "df_part_1_in_3 = df_part_1[df_part_1['time'] >= np.datetime64('2014-11-25')]\n",
    "df_part_1_in_3['cumcount'] = df_part_1_in_3.groupby(['user_id', 'behavior_type']).cumcount()\n",
    "df_part_1_u_b_count_in_3 = df_part_1.drop_duplicates(['user_id','behavior_type'], 'last')[['user_id','behavior_type','cumcount']]\n",
    "df_part_1_u_b_count_in_3 = pd.get_dummies(df_part_1_u_b_count_in_3['behavior_type']).join(df_part_1_u_b_count_in_3[['user_id','cumcount']])\n",
    "df_part_1_u_b_count_in_3.rename(columns = {1:'behavior_type_1',\n",
    "                                           2:'behavior_type_2',\n",
    "                                           3:'behavior_type_3',\n",
    "                                           4:'behavior_type_4'}, inplace=True)\n",
    "df_part_1_u_b_count_in_3['u_b1_count_in_3'] = df_part_1_u_b_count_in_3['behavior_type_1'] * (df_part_1_u_b_count_in_3['cumcount']+1)\n",
    "df_part_1_u_b_count_in_3['u_b2_count_in_3'] = df_part_1_u_b_count_in_3['behavior_type_2'] * (df_part_1_u_b_count_in_3['cumcount']+1)\n",
    "df_part_1_u_b_count_in_3['u_b3_count_in_3'] = df_part_1_u_b_count_in_3['behavior_type_3'] * (df_part_1_u_b_count_in_3['cumcount']+1)\n",
    "df_part_1_u_b_count_in_3['u_b4_count_in_3'] = df_part_1_u_b_count_in_3['behavior_type_4'] * (df_part_1_u_b_count_in_3['cumcount']+1)\n",
    "df_part_1_u_b_count_in_3 = df_part_1_u_b_count_in_3.groupby('user_id').agg({'u_b1_count_in_3': np.sum,\n",
    "                                                                            'u_b2_count_in_3': np.sum,\n",
    "                                                                            'u_b3_count_in_3': np.sum,\n",
    "                                                                            'u_b4_count_in_3': np.sum})\n",
    "df_part_1_u_b_count_in_3.reset_index(inplace = True)\n",
    "df_part_1_u_b_count_in_3['u_b_count_in_3'] = df_part_1_u_b_count_in_3[['u_b1_count_in_3',\n",
    "                                                                       'u_b2_count_in_3',\n",
    "                                                                       'u_b3_count_in_3',\n",
    "                                                                       'u_b4_count_in_3']].apply(lambda x: x.sum(), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70d8bc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15291/2294981147.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_part_1_in_1['cumcount'] = df_part_1_in_1.groupby(['user_id', 'behavior_type']).cumcount()\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15291/2294981147.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_1_u_b_count_in_1 = df_part_1_in_1.drop_duplicates(['user_id','behavior_type'], 'last')[['user_id','behavior_type','cumcount']]\n"
     ]
    }
   ],
   "source": [
    "# u_b_count_in_1\n",
    "df_part_1_in_1 = df_part_1[df_part_1['time'] >= np.datetime64('2014-11-27')]\n",
    "df_part_1_in_1['cumcount'] = df_part_1_in_1.groupby(['user_id', 'behavior_type']).cumcount()\n",
    "df_part_1_u_b_count_in_1 = df_part_1_in_1.drop_duplicates(['user_id','behavior_type'], 'last')[['user_id','behavior_type','cumcount']]\n",
    "df_part_1_u_b_count_in_1 = pd.get_dummies(df_part_1_u_b_count_in_1['behavior_type']).join(df_part_1_u_b_count_in_1[['user_id','cumcount']])\n",
    "df_part_1_u_b_count_in_1.rename(columns = {1:'behavior_type_1',\n",
    "                                           2:'behavior_type_2',\n",
    "                                           3:'behavior_type_3',\n",
    "                                           4:'behavior_type_4'}, inplace=True)\n",
    "df_part_1_u_b_count_in_1['u_b1_count_in_1'] = df_part_1_u_b_count_in_1['behavior_type_1'] * (df_part_1_u_b_count_in_1['cumcount']+1)\n",
    "df_part_1_u_b_count_in_1['u_b2_count_in_1'] = df_part_1_u_b_count_in_1['behavior_type_2'] * (df_part_1_u_b_count_in_1['cumcount']+1)\n",
    "df_part_1_u_b_count_in_1['u_b3_count_in_1'] = df_part_1_u_b_count_in_1['behavior_type_3'] * (df_part_1_u_b_count_in_1['cumcount']+1)\n",
    "df_part_1_u_b_count_in_1['u_b4_count_in_1'] = df_part_1_u_b_count_in_1['behavior_type_4'] * (df_part_1_u_b_count_in_1['cumcount']+1)\n",
    "df_part_1_u_b_count_in_1 = df_part_1_u_b_count_in_1.groupby('user_id').agg({'u_b1_count_in_1': np.sum,\n",
    "                                                                            'u_b2_count_in_1': np.sum,\n",
    "                                                                            'u_b3_count_in_1': np.sum,\n",
    "                                                                            'u_b4_count_in_1': np.sum})\n",
    "df_part_1_u_b_count_in_1.reset_index(inplace = True)\n",
    "df_part_1_u_b_count_in_1['u_b_count_in_1']  = df_part_1_u_b_count_in_1[['u_b1_count_in_1',\n",
    "                                                                        'u_b2_count_in_1',\n",
    "                                                                        'u_b3_count_in_1',\n",
    "                                                                        'u_b4_count_in_1']].apply(lambda x: x.sum(), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "936cab00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the result of count_in_6, count_in_3, count_in_1\n",
    "\n",
    "df_part_1_u_b_count = pd.merge(df_part_1_u_b_count_in_6, \n",
    "                               df_part_1_u_b_count_in_3, on = ['user_id'], how = 'left').fillna(0)\n",
    "df_part_1_u_b_count = pd.merge(df_part_1_u_b_count, \n",
    "                               df_part_1_u_b_count_in_1, on = ['user_id'], how = 'left').fillna(0)\n",
    "                                    \n",
    "df_part_1_u_b_count[['u_b1_count_in_6',\n",
    "                     'u_b2_count_in_6',\n",
    "                     'u_b3_count_in_6',\n",
    "                     'u_b4_count_in_6',\n",
    "                      'u_b_count_in_6',\n",
    "                     'u_b1_count_in_3',\n",
    "                     'u_b2_count_in_3',\n",
    "                     'u_b3_count_in_3',\n",
    "                     'u_b4_count_in_3',\n",
    "                      'u_b_count_in_3',\n",
    "                     'u_b1_count_in_1',\n",
    "                     'u_b2_count_in_1',\n",
    "                     'u_b3_count_in_1',\n",
    "                     'u_b4_count_in_1',\n",
    "                      'u_b_count_in_1']] = df_part_1_u_b_count[['u_b1_count_in_6',\n",
    "                                                                'u_b2_count_in_6',\n",
    "                                                                'u_b3_count_in_6',\n",
    "                                                                'u_b4_count_in_6',\n",
    "                                                                 'u_b_count_in_6',\n",
    "                                                                'u_b1_count_in_3',\n",
    "                                                                'u_b2_count_in_3',\n",
    "                                                                'u_b3_count_in_3',\n",
    "                                                                'u_b4_count_in_3',\n",
    "                                                                 'u_b_count_in_3',\n",
    "                                                                'u_b1_count_in_1',\n",
    "                                                                'u_b2_count_in_1',\n",
    "                                                                'u_b3_count_in_1',\n",
    "                                                                'u_b4_count_in_1',\n",
    "                                                                 'u_b_count_in_1']].astype(int)\n",
    "                                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df20733b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15291/2430604710.py:6: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_1_u_b4_time = df_part_1[df_part_1['behavior_type'] == 4].drop_duplicates(['user_id'],'first')[['user_id','time']]\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15291/2430604710.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_1_u_b_time = df_part_1.drop_duplicates(['user_id'],'first')[['user_id','time']]\n"
     ]
    }
   ],
   "source": [
    "# u_b4_rate\n",
    "df_part_1_u_b_count['u_b4_rate'] = df_part_1_u_b_count['u_b4_count_in_6'] / df_part_1_u_b_count['u_b_count_in_6']\n",
    "\n",
    "# u_b4_diff_time\n",
    "df_part_1 = df_part_1.sort_values(by = ['user_id', 'time'])\n",
    "df_part_1_u_b4_time = df_part_1[df_part_1['behavior_type'] == 4].drop_duplicates(['user_id'],'first')[['user_id','time']]\n",
    "df_part_1_u_b4_time.columns = ['user_id','b4_first_time']\n",
    "df_part_1_u_b_time = df_part_1.drop_duplicates(['user_id'],'first')[['user_id','time']]\n",
    "df_part_1_u_b_time.columns = ['user_id','b_first_time']\n",
    "df_part_1_u_b_b4_time = pd.merge(df_part_1_u_b_time, df_part_1_u_b4_time, on = ['user_id'])\n",
    "df_part_1_u_b_b4_time['u_b4_diff_time'] = df_part_1_u_b_b4_time['b4_first_time'] - df_part_1_u_b_b4_time['b_first_time']\n",
    "df_part_1_u_b_b4_time = df_part_1_u_b_b4_time[['user_id', 'u_b4_diff_time']]\n",
    "df_part_1_u_b_b4_time['u_b4_diff_hours'] = df_part_1_u_b_b4_time['u_b4_diff_time'].apply(lambda x: x.days * 24 + x.seconds//3600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef7e5682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating feature set U\n",
    "f_U_part_1 = pd.merge(df_part_1_u_b_count, \n",
    "                      df_part_1_u_b_b4_time, \n",
    "                      on = ['user_id'], how = 'left')[['user_id',\n",
    "                                                       'u_b1_count_in_6', \n",
    "                                                       'u_b2_count_in_6', \n",
    "                                                       'u_b3_count_in_6', \n",
    "                                                       'u_b4_count_in_6', \n",
    "                                                       'u_b_count_in_6',\n",
    "                                                       'u_b1_count_in_3',\n",
    "                                                       'u_b2_count_in_3', \n",
    "                                                       'u_b3_count_in_3',\n",
    "                                                       'u_b4_count_in_3', \n",
    "                                                       'u_b_count_in_3',\n",
    "                                                       'u_b1_count_in_1',\n",
    "                                                       'u_b2_count_in_1', \n",
    "                                                       'u_b3_count_in_1',\n",
    "                                                       'u_b4_count_in_1', \n",
    "                                                       'u_b_count_in_1', \n",
    "                                                       'u_b4_rate', \n",
    "                                                       'u_b4_diff_hours']]\n",
    "                      \n",
    "# write to csv file\n",
    "f_U_part_1 = f_U_part_1.round({'u_b4_rate': 3})\n",
    "f_U_part_1.to_csv(path_df_part_1_U, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6ffe35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Step 1.2 feature data set I of df_part_1\\n    (1)\\n    i_u_count_in_6\\n    i_u_count_in_3\\n    i_u_count_in_1\\n    (2)\\n    i_b1_count_in_6\\n    i_b2_count_in_6\\n    i_b3_count_in_6\\n    i_b4_count_in_6\\n     i_b_count_in_6\\n    i_b1_count_in_3\\n    i_b2_count_in_3\\n    i_b3_count_in_3\\n    i_b4_count_in_3\\n     i_b_count_in_3\\n    i_b1_count_in_1\\n    i_b2_count_in_1\\n    i_b3_count_in_1\\n    i_b4_count_in_1\\n     i_b_count_in_1\\n    (3)\\n    i_b4_rate  (in_6)\\n    i_b4_diff_hours  (in_6)\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Step 1.2 feature data set I of df_part_1\n",
    "    (1)\n",
    "    i_u_count_in_6\n",
    "    i_u_count_in_3\n",
    "    i_u_count_in_1\n",
    "    (2)\n",
    "    i_b1_count_in_6\n",
    "    i_b2_count_in_6\n",
    "    i_b3_count_in_6\n",
    "    i_b4_count_in_6\n",
    "     i_b_count_in_6\n",
    "    i_b1_count_in_3\n",
    "    i_b2_count_in_3\n",
    "    i_b3_count_in_3\n",
    "    i_b4_count_in_3\n",
    "     i_b_count_in_3\n",
    "    i_b1_count_in_1\n",
    "    i_b2_count_in_1\n",
    "    i_b3_count_in_1\n",
    "    i_b4_count_in_1\n",
    "     i_b_count_in_1\n",
    "    (3)\n",
    "    i_b4_rate  (in_6)\n",
    "    i_b4_diff_hours  (in_6)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4c7ebb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15291/1432332016.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_part_1_in_6['i_u_count_in_6'] = df_part_1_in_6.groupby('item_id').cumcount() + 1\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15291/1432332016.py:12: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_1_i_u_count_in_6 = df_part_1_in_6.drop_duplicates(['item_id'], 'last')[['item_id', 'i_u_count_in_6']]\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15291/1432332016.py:17: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_1_i_u_count_in_3 = df_part_1_in_3.drop_duplicates(['item_id'], 'last')[['item_id', 'i_u_count_in_3']]\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15291/1432332016.py:22: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_1_i_u_count_in_1 = df_part_1_in_1.drop_duplicates(['item_id'], 'last')[['item_id', 'i_u_count_in_1']]\n"
     ]
    }
   ],
   "source": [
    "# loading data\n",
    "path_df = open(path_df_part_1, 'r')\n",
    "try:\n",
    "    df_part_1 = pd.read_csv(path_df, index_col = False, parse_dates = [0])\n",
    "    df_part_1.columns = ['time','user_id','item_id','behavior_type','item_category']\n",
    "finally:\n",
    "    path_df.close()\n",
    "\n",
    "# i_u_count_in_6\n",
    "df_part_1_in_6 = df_part_1.drop_duplicates(['item_id', 'user_id'])\n",
    "df_part_1_in_6['i_u_count_in_6'] = df_part_1_in_6.groupby('item_id').cumcount() + 1\n",
    "df_part_1_i_u_count_in_6 = df_part_1_in_6.drop_duplicates(['item_id'], 'last')[['item_id', 'i_u_count_in_6']]\n",
    "\n",
    "# i_u_count_in_3\n",
    "df_part_1_in_3 = df_part_1[df_part_1['time'] >= np.datetime64('2014-11-25')].drop_duplicates(['item_id', 'user_id'])\n",
    "df_part_1_in_3['i_u_count_in_3'] = df_part_1_in_3.groupby('item_id').cumcount() + 1\n",
    "df_part_1_i_u_count_in_3 = df_part_1_in_3.drop_duplicates(['item_id'], 'last')[['item_id', 'i_u_count_in_3']]\n",
    "\n",
    "# i_u_count_in_1\n",
    "df_part_1_in_1 = df_part_1[df_part_1['time'] >= np.datetime64('2014-11-27')].drop_duplicates(['item_id', 'user_id'])\n",
    "df_part_1_in_1['i_u_count_in_1'] = df_part_1_in_1.groupby('item_id').cumcount() + 1\n",
    "df_part_1_i_u_count_in_1 = df_part_1_in_1.drop_duplicates(['item_id'], 'last')[['item_id', 'i_u_count_in_1']]\n",
    "\n",
    "# merge for generation of i_u_count\n",
    "df_part_1_i_u_count = pd.merge(df_part_1_i_u_count_in_6, \n",
    "                               df_part_1_i_u_count_in_3,\n",
    "                               on=['item_id'],how='left').fillna(0)\n",
    "df_part_1_i_u_count = pd.merge(df_part_1_i_u_count, \n",
    "                               df_part_1_i_u_count_in_1,\n",
    "                               on=['item_id'],how='left').fillna(0)\n",
    "df_part_1_i_u_count[['i_u_count_in_6',\n",
    "                     'i_u_count_in_3',\n",
    "                     'i_u_count_in_1']] = df_part_1_i_u_count[['i_u_count_in_6',\n",
    "                                                               'i_u_count_in_3',\n",
    "                                                               'i_u_count_in_1']].astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dcf1b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15291/3298181592.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_1_i_b_count_in_6 = df_part_1.drop_duplicates(['item_id','behavior_type'], 'last')[['item_id','behavior_type','cumcount']]\n"
     ]
    }
   ],
   "source": [
    "# i_b_count_in_6\n",
    "df_part_1['cumcount'] = df_part_1.groupby(['item_id', 'behavior_type']).cumcount()\n",
    "df_part_1_i_b_count_in_6 = df_part_1.drop_duplicates(['item_id','behavior_type'], 'last')[['item_id','behavior_type','cumcount']]\n",
    "df_part_1_i_b_count_in_6 = pd.get_dummies(df_part_1_i_b_count_in_6['behavior_type']).join(df_part_1_i_b_count_in_6[['item_id','cumcount']])\n",
    "df_part_1_i_b_count_in_6.rename(columns = {1:'behavior_type_1',\n",
    "                                           2:'behavior_type_2',\n",
    "                                           3:'behavior_type_3',\n",
    "                                           4:'behavior_type_4'}, inplace=True)\n",
    "df_part_1_i_b_count_in_6['i_b1_count_in_6'] = df_part_1_i_b_count_in_6['behavior_type_1'] * (df_part_1_i_b_count_in_6['cumcount']+1)\n",
    "df_part_1_i_b_count_in_6['i_b2_count_in_6'] = df_part_1_i_b_count_in_6['behavior_type_2'] * (df_part_1_i_b_count_in_6['cumcount']+1)\n",
    "df_part_1_i_b_count_in_6['i_b3_count_in_6'] = df_part_1_i_b_count_in_6['behavior_type_3'] * (df_part_1_i_b_count_in_6['cumcount']+1)\n",
    "df_part_1_i_b_count_in_6['i_b4_count_in_6'] = df_part_1_i_b_count_in_6['behavior_type_4'] * (df_part_1_i_b_count_in_6['cumcount']+1)\n",
    "df_part_1_i_b_count_in_6 = df_part_1_i_b_count_in_6[['item_id', \n",
    "                                                     'i_b1_count_in_6', \n",
    "                                                     'i_b2_count_in_6', \n",
    "                                                     'i_b3_count_in_6',\n",
    "                                                     'i_b4_count_in_6']]\n",
    "df_part_1_i_b_count_in_6 = df_part_1_i_b_count_in_6.groupby('item_id').agg({'i_b1_count_in_6': np.sum,\n",
    "                                                                            'i_b2_count_in_6': np.sum,\n",
    "                                                                            'i_b3_count_in_6': np.sum,\n",
    "                                                                            'i_b4_count_in_6': np.sum})\n",
    "df_part_1_i_b_count_in_6.reset_index(inplace = True)\n",
    "df_part_1_i_b_count_in_6['i_b_count_in_6'] = df_part_1_i_b_count_in_6['i_b1_count_in_6'] + \\\n",
    "                                             df_part_1_i_b_count_in_6['i_b2_count_in_6'] + \\\n",
    "                                             df_part_1_i_b_count_in_6['i_b3_count_in_6'] + \\\n",
    "                                             df_part_1_i_b_count_in_6['i_b4_count_in_6']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a0445b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15291/413317735.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_part_1_in_3['cumcount'] = df_part_1_in_3.groupby(['item_id', 'behavior_type']).cumcount()\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15291/413317735.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_1_i_b_count_in_3 = df_part_1.drop_duplicates(['item_id','behavior_type'], 'last')[['item_id','behavior_type','cumcount']]\n"
     ]
    }
   ],
   "source": [
    "# i_b_count_in_3\n",
    "df_part_1_in_3 = df_part_1[df_part_1['time'] >= np.datetime64('2014-11-25')]\n",
    "df_part_1_in_3['cumcount'] = df_part_1_in_3.groupby(['item_id', 'behavior_type']).cumcount()\n",
    "df_part_1_i_b_count_in_3 = df_part_1.drop_duplicates(['item_id','behavior_type'], 'last')[['item_id','behavior_type','cumcount']]\n",
    "df_part_1_i_b_count_in_3 = pd.get_dummies(df_part_1_i_b_count_in_3['behavior_type']).join(df_part_1_i_b_count_in_3[['item_id','cumcount']])\n",
    "df_part_1_i_b_count_in_3.rename(columns = {1:'behavior_type_1',\n",
    "                                           2:'behavior_type_2',\n",
    "                                           3:'behavior_type_3',\n",
    "                                           4:'behavior_type_4'}, inplace=True)\n",
    "df_part_1_i_b_count_in_3['i_b1_count_in_3'] = df_part_1_i_b_count_in_3['behavior_type_1'] * (df_part_1_i_b_count_in_3['cumcount']+1)\n",
    "df_part_1_i_b_count_in_3['i_b2_count_in_3'] = df_part_1_i_b_count_in_3['behavior_type_2'] * (df_part_1_i_b_count_in_3['cumcount']+1)\n",
    "df_part_1_i_b_count_in_3['i_b3_count_in_3'] = df_part_1_i_b_count_in_3['behavior_type_3'] * (df_part_1_i_b_count_in_3['cumcount']+1)\n",
    "df_part_1_i_b_count_in_3['i_b4_count_in_3'] = df_part_1_i_b_count_in_3['behavior_type_4'] * (df_part_1_i_b_count_in_3['cumcount']+1)\n",
    "df_part_1_i_b_count_in_3 = df_part_1_i_b_count_in_3[['item_id', \n",
    "                                                     'i_b1_count_in_3', \n",
    "                                                     'i_b2_count_in_3', \n",
    "                                                     'i_b3_count_in_3',\n",
    "                                                     'i_b4_count_in_3']]\n",
    "df_part_1_i_b_count_in_3 = df_part_1_i_b_count_in_3.groupby('item_id').agg({'i_b1_count_in_3': np.sum,\n",
    "                                                                            'i_b2_count_in_3': np.sum,\n",
    "                                                                            'i_b3_count_in_3': np.sum,\n",
    "                                                                            'i_b4_count_in_3': np.sum})\n",
    "df_part_1_i_b_count_in_3.reset_index(inplace = True)\n",
    "df_part_1_i_b_count_in_3['i_b_count_in_3'] = df_part_1_i_b_count_in_3['i_b1_count_in_3'] + \\\n",
    "                                             df_part_1_i_b_count_in_3['i_b2_count_in_3'] + \\\n",
    "                                             df_part_1_i_b_count_in_3['i_b3_count_in_3'] + \\\n",
    "                                             df_part_1_i_b_count_in_3['i_b4_count_in_3']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "557c19d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15291/1605438805.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_part_1_in_1['cumcount'] = df_part_1_in_1.groupby(['item_id', 'behavior_type']).cumcount()\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15291/1605438805.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_1_i_b_count_in_1 = df_part_1_in_1.drop_duplicates(['item_id','behavior_type'], 'last')[['item_id','behavior_type','cumcount']]\n"
     ]
    }
   ],
   "source": [
    "# i_b_count_in_1\n",
    "df_part_1_in_1 = df_part_1[df_part_1['time'] >= np.datetime64('2014-11-27')]\n",
    "df_part_1_in_1['cumcount'] = df_part_1_in_1.groupby(['item_id', 'behavior_type']).cumcount()\n",
    "df_part_1_i_b_count_in_1 = df_part_1_in_1.drop_duplicates(['item_id','behavior_type'], 'last')[['item_id','behavior_type','cumcount']]\n",
    "df_part_1_i_b_count_in_1 = pd.get_dummies(df_part_1_i_b_count_in_1['behavior_type']).join(df_part_1_i_b_count_in_1[['item_id','cumcount']])\n",
    "df_part_1_i_b_count_in_1.rename(columns = {1:'behavior_type_1',\n",
    "                                           2:'behavior_type_2',\n",
    "                                           3:'behavior_type_3',\n",
    "                                           4:'behavior_type_4'}, inplace=True)                     \n",
    "df_part_1_i_b_count_in_1['i_b1_count_in_1'] = df_part_1_i_b_count_in_1['behavior_type_1'] * (df_part_1_i_b_count_in_1['cumcount']+1)\n",
    "df_part_1_i_b_count_in_1['i_b2_count_in_1'] = df_part_1_i_b_count_in_1['behavior_type_2'] * (df_part_1_i_b_count_in_1['cumcount']+1)\n",
    "df_part_1_i_b_count_in_1['i_b3_count_in_1'] = df_part_1_i_b_count_in_1['behavior_type_3'] * (df_part_1_i_b_count_in_1['cumcount']+1)\n",
    "df_part_1_i_b_count_in_1['i_b4_count_in_1'] = df_part_1_i_b_count_in_1['behavior_type_4'] * (df_part_1_i_b_count_in_1['cumcount']+1)\n",
    "df_part_1_i_b_count_in_1 = df_part_1_i_b_count_in_1[['item_id', \n",
    "                                                     'i_b1_count_in_1', \n",
    "                                                     'i_b2_count_in_1', \n",
    "                                                     'i_b3_count_in_1',\n",
    "                                                     'i_b4_count_in_1']]\n",
    "df_part_1_i_b_count_in_1 = df_part_1_i_b_count_in_1.groupby('item_id').agg({'i_b1_count_in_1': np.sum,\n",
    "                                                                            'i_b2_count_in_1': np.sum,\n",
    "                                                                            'i_b3_count_in_1': np.sum,\n",
    "                                                                            'i_b4_count_in_1': np.sum})\n",
    "df_part_1_i_b_count_in_1.reset_index(inplace = True)\n",
    "df_part_1_i_b_count_in_1['i_b_count_in_1'] = df_part_1_i_b_count_in_1['i_b1_count_in_1'] + \\\n",
    "                                             df_part_1_i_b_count_in_1['i_b2_count_in_1'] + \\\n",
    "                                             df_part_1_i_b_count_in_1['i_b3_count_in_1'] + \\\n",
    "                                             df_part_1_i_b_count_in_1['i_b4_count_in_1']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "472a9ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge for generation of i_b_count\n",
    "df_part_1_i_b_count = pd.merge(df_part_1_i_b_count_in_6, \n",
    "                               df_part_1_i_b_count_in_3, \n",
    "                               on = ['item_id'], how = 'left').fillna(0)\n",
    "df_part_1_i_b_count = pd.merge(df_part_1_i_b_count, \n",
    "                               df_part_1_i_b_count_in_1, \n",
    "                               on = ['item_id'], how = 'left').fillna(0)\n",
    "df_part_1_i_b_count[['i_b1_count_in_6',\n",
    "                     'i_b2_count_in_6',\n",
    "                     'i_b3_count_in_6',\n",
    "                     'i_b4_count_in_6',\n",
    "                      'i_b_count_in_6',\n",
    "                     'i_b1_count_in_3',\n",
    "                     'i_b2_count_in_3',\n",
    "                     'i_b3_count_in_3',\n",
    "                     'i_b4_count_in_3',\n",
    "                      'i_b_count_in_3',\n",
    "                     'i_b1_count_in_1',\n",
    "                     'i_b2_count_in_1',\n",
    "                     'i_b3_count_in_1',\n",
    "                     'i_b4_count_in_1',\n",
    "                      'i_b_count_in_1']] = df_part_1_i_b_count[['i_b1_count_in_6',\n",
    "                                                                'i_b2_count_in_6',\n",
    "                                                                'i_b3_count_in_6',\n",
    "                                                                'i_b4_count_in_6',\n",
    "                                                                 'i_b_count_in_6',\n",
    "                                                                'i_b1_count_in_3',\n",
    "                                                                'i_b2_count_in_3',\n",
    "                                                                'i_b3_count_in_3',\n",
    "                                                                'i_b4_count_in_3',\n",
    "                                                                 'i_b_count_in_3',\n",
    "                                                                'i_b1_count_in_1',\n",
    "                                                                'i_b2_count_in_1',\n",
    "                                                                'i_b3_count_in_1',\n",
    "                                                                'i_b4_count_in_1',\n",
    "                                                                 'i_b_count_in_1']].astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "035613ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15291/3845768618.py:6: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_1_i_b4_time = df_part_1[df_part_1['behavior_type'] == 4].drop_duplicates(['item_id'], 'first')[['item_id','time']]\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15291/3845768618.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_1_i_b_time = df_part_1.drop_duplicates(['item_id'], 'first')[['item_id','time']]\n"
     ]
    }
   ],
   "source": [
    "# i_b4_rate\n",
    "df_part_1_i_b_count['i_b4_rate'] = df_part_1_i_b_count['i_b4_count_in_6'] / df_part_1_i_b_count['i_b_count_in_6']\n",
    "\n",
    "# i_b4_diff_time\n",
    "df_part_1 = df_part_1.sort_values(by=['item_id', 'time'])\n",
    "df_part_1_i_b4_time = df_part_1[df_part_1['behavior_type'] == 4].drop_duplicates(['item_id'], 'first')[['item_id','time']]\n",
    "df_part_1_i_b4_time.columns = ['item_id','b4_first_time']\n",
    "df_part_1_i_b_time = df_part_1.drop_duplicates(['item_id'], 'first')[['item_id','time']]\n",
    "df_part_1_i_b_time.columns = ['item_id','b_first_time']\n",
    "df_part_1_i_b_b4_time = pd.merge(df_part_1_i_b_time, df_part_1_i_b4_time, on = ['item_id'])\n",
    "df_part_1_i_b_b4_time['i_b4_diff_time']  = df_part_1_i_b_b4_time['b4_first_time'] - df_part_1_i_b_b4_time['b_first_time']\n",
    "df_part_1_i_b_b4_time['i_b4_diff_hours'] = df_part_1_i_b_b4_time['i_b4_diff_time'].apply(lambda x: x.days * 24 + x.seconds//3600)\n",
    "df_part_1_i_b_b4_time = df_part_1_i_b_b4_time[['item_id', 'i_b4_diff_hours']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d13187e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating feature set I\n",
    "f_I_part_1 = pd.merge(df_part_1_i_b_count, \n",
    "                      df_part_1_i_b_b4_time, \n",
    "                      on = ['item_id'], how = 'left')\n",
    "f_I_part_1 = pd.merge(f_I_part_1, \n",
    "                      df_part_1_i_u_count, \n",
    "                      on = ['item_id'], how = 'left')[['item_id', \n",
    "                                                       'i_u_count_in_6', \n",
    "                                                       'i_u_count_in_3', \n",
    "                                                       'i_u_count_in_1',\n",
    "                                                       'i_b1_count_in_6', \n",
    "                                                       'i_b2_count_in_6', \n",
    "                                                       'i_b3_count_in_6', \n",
    "                                                       'i_b4_count_in_6', \n",
    "                                                       'i_b_count_in_6', \n",
    "                                                       'i_b1_count_in_3',\n",
    "                                                       'i_b2_count_in_3',\n",
    "                                                       'i_b3_count_in_3',\n",
    "                                                       'i_b4_count_in_3',\n",
    "                                                       'i_b_count_in_3',\n",
    "                                                       'i_b1_count_in_1', \n",
    "                                                       'i_b2_count_in_1', \n",
    "                                                       'i_b3_count_in_1', \n",
    "                                                       'i_b4_count_in_1', \n",
    "                                                       'i_b_count_in_1',\n",
    "                                                       'i_b4_rate', \n",
    "                                                       'i_b4_diff_hours']]\n",
    "                      \n",
    "# write to csv file\n",
    "f_I_part_1 = f_I_part_1.round({'i_b4_rate': 3})\n",
    "f_I_part_1.to_csv(path_df_part_1_I, index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e12b4fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Step 1.3 feature data set C of df_part_1\\n    (1)\\n    c_u_count_in_6\\n    c_u_count_in_3\\n    c_u_count_in_1\\n    (2)\\n    c_b1_count_in_6\\n    c_b2_count_in_6\\n    c_b3_count_in_6\\n    c_b4_count_in_6\\n     c_b_count_in_6\\n    c_b1_count_in_3\\n    c_b2_count_in_3\\n    c_b3_count_in_3\\n    c_b4_count_in_3\\n     c_b_count_in_3\\n    c_b1_count_in_1\\n    c_b2_count_in_1\\n    c_b3_count_in_1\\n    c_b4_count_in_1\\n     c_b_count_in_1\\n    (3)\\n    c_b4_rate  (in_6)\\n    c_b4_diff_hours (in_6)\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Step 1.3 feature data set C of df_part_1\n",
    "    (1)\n",
    "    c_u_count_in_6\n",
    "    c_u_count_in_3\n",
    "    c_u_count_in_1\n",
    "    (2)\n",
    "    c_b1_count_in_6\n",
    "    c_b2_count_in_6\n",
    "    c_b3_count_in_6\n",
    "    c_b4_count_in_6\n",
    "     c_b_count_in_6\n",
    "    c_b1_count_in_3\n",
    "    c_b2_count_in_3\n",
    "    c_b3_count_in_3\n",
    "    c_b4_count_in_3\n",
    "     c_b_count_in_3\n",
    "    c_b1_count_in_1\n",
    "    c_b2_count_in_1\n",
    "    c_b3_count_in_1\n",
    "    c_b4_count_in_1\n",
    "     c_b_count_in_1\n",
    "    (3)\n",
    "    c_b4_rate  (in_6)\n",
    "    c_b4_diff_hours (in_6)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0d014fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "path_df = open(path_df_part_1, 'r')\n",
    "try:\n",
    "    df_part_1 = pd.read_csv(path_df, index_col = False, parse_dates = [0])\n",
    "    df_part_1.columns = ['time','user_id','item_id','behavior_type','item_category']\n",
    "finally:\n",
    "    path_df.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a94150a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15291/420753889.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_part_1_in_6['c_u_count_in_6'] = df_part_1_in_6.groupby('item_category').cumcount() + 1\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15291/420753889.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_1_c_u_count_in_6 = df_part_1_in_6.drop_duplicates(['item_category'], 'last')[['item_category', 'c_u_count_in_6']]\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15291/420753889.py:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_1_c_u_count_in_3 = df_part_1_in_3.drop_duplicates(['item_category'], 'last')[['item_category', 'c_u_count_in_3']]\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15291/420753889.py:14: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_1_c_u_count_in_1 = df_part_1_in_1.drop_duplicates(['item_category'], 'last')[['item_category', 'c_u_count_in_1']]\n"
     ]
    }
   ],
   "source": [
    "# c_u_count_in_6\n",
    "df_part_1_in_6 = df_part_1.drop_duplicates(['item_category', 'user_id'])\n",
    "df_part_1_in_6['c_u_count_in_6'] = df_part_1_in_6.groupby('item_category').cumcount() + 1\n",
    "df_part_1_c_u_count_in_6 = df_part_1_in_6.drop_duplicates(['item_category'], 'last')[['item_category', 'c_u_count_in_6']]\n",
    "\n",
    "# c_u_count_in_3\n",
    "df_part_1_in_3 = df_part_1[df_part_1['time'] >= np.datetime64('2014-11-25')].drop_duplicates(['item_category', 'user_id'])\n",
    "df_part_1_in_3['c_u_count_in_3'] = df_part_1_in_3.groupby('item_category').cumcount() + 1\n",
    "df_part_1_c_u_count_in_3 = df_part_1_in_3.drop_duplicates(['item_category'], 'last')[['item_category', 'c_u_count_in_3']]\n",
    "\n",
    "# c_u_count_in_1\n",
    "df_part_1_in_1 = df_part_1[df_part_1['time'] >= np.datetime64('2014-11-27')].drop_duplicates(['item_category', 'user_id'])\n",
    "df_part_1_in_1['c_u_count_in_1'] = df_part_1_in_1.groupby('item_category').cumcount() + 1\n",
    "df_part_1_c_u_count_in_1 = df_part_1_in_1.drop_duplicates(['item_category'], 'last')[['item_category', 'c_u_count_in_1']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad7e89ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part_1_c_u_count = pd.merge(df_part_1_c_u_count_in_6, df_part_1_c_u_count_in_3,on=['item_category'],how='left').fillna(0)\n",
    "df_part_1_c_u_count = pd.merge(df_part_1_c_u_count, df_part_1_c_u_count_in_1,on=['item_category'],how='left').fillna(0)\n",
    "df_part_1_c_u_count[['c_u_count_in_6',\n",
    "                     'c_u_count_in_3',\n",
    "                     'c_u_count_in_1']] = df_part_1_c_u_count[['c_u_count_in_6',\n",
    "                                                               'c_u_count_in_3',\n",
    "                                                               'c_u_count_in_1']].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9e35e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15291/1597546287.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_1_c_b_count_in_6 = df_part_1.drop_duplicates(['item_category','behavior_type'], 'last')[['item_category','behavior_type','cumcount']]\n"
     ]
    }
   ],
   "source": [
    "# c_b_count_in_6\n",
    "df_part_1['cumcount'] = df_part_1.groupby(['item_category', 'behavior_type']).cumcount()\n",
    "df_part_1_c_b_count_in_6 = df_part_1.drop_duplicates(['item_category','behavior_type'], 'last')[['item_category','behavior_type','cumcount']]\n",
    "df_part_1_c_b_count_in_6 = pd.get_dummies(df_part_1_c_b_count_in_6['behavior_type']).join(df_part_1_c_b_count_in_6[['item_category','cumcount']])\n",
    "df_part_1_c_b_count_in_6.rename(columns = {1:'behavior_type_1',\n",
    "                                           2:'behavior_type_2',\n",
    "                                           3:'behavior_type_3',\n",
    "                                           4:'behavior_type_4'}, inplace=True)\n",
    "df_part_1_c_b_count_in_6['c_b1_count_in_6'] = df_part_1_c_b_count_in_6['behavior_type_1'] * (df_part_1_c_b_count_in_6['cumcount']+1)\n",
    "df_part_1_c_b_count_in_6['c_b2_count_in_6'] = df_part_1_c_b_count_in_6['behavior_type_2'] * (df_part_1_c_b_count_in_6['cumcount']+1)\n",
    "df_part_1_c_b_count_in_6['c_b3_count_in_6'] = df_part_1_c_b_count_in_6['behavior_type_3'] * (df_part_1_c_b_count_in_6['cumcount']+1)\n",
    "df_part_1_c_b_count_in_6['c_b4_count_in_6'] = df_part_1_c_b_count_in_6['behavior_type_4'] * (df_part_1_c_b_count_in_6['cumcount']+1)\n",
    "df_part_1_c_b_count_in_6 = df_part_1_c_b_count_in_6[['item_category', \n",
    "                                                     'c_b1_count_in_6', \n",
    "                                                     'c_b2_count_in_6', \n",
    "                                                     'c_b3_count_in_6',\n",
    "                                                     'c_b4_count_in_6']]\n",
    "df_part_1_c_b_count_in_6 = df_part_1_c_b_count_in_6.groupby('item_category').agg({'c_b1_count_in_6': np.sum,\n",
    "                                                                                  'c_b2_count_in_6': np.sum,\n",
    "                                                                                  'c_b3_count_in_6': np.sum,\n",
    "                                                                                  'c_b4_count_in_6': np.sum})\n",
    "df_part_1_c_b_count_in_6.reset_index(inplace = True)\n",
    "df_part_1_c_b_count_in_6['c_b_count_in_6'] = df_part_1_c_b_count_in_6['c_b1_count_in_6'] + \\\n",
    "                                             df_part_1_c_b_count_in_6['c_b2_count_in_6'] + \\\n",
    "                                             df_part_1_c_b_count_in_6['c_b3_count_in_6'] + \\\n",
    "                                             df_part_1_c_b_count_in_6['c_b4_count_in_6']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83d28a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15291/4277692073.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_part_1_in_3['cumcount'] = df_part_1_in_3.groupby(['item_category', 'behavior_type']).cumcount()\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15291/4277692073.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_1_c_b_count_in_3 = df_part_1_in_3.drop_duplicates(['item_category','behavior_type'], 'last')[['item_category','behavior_type','cumcount']]\n"
     ]
    }
   ],
   "source": [
    "# c_b_count_in_3\n",
    "df_part_1_in_3 = df_part_1[df_part_1['time'] >= np.datetime64('2014-11-25')]\n",
    "df_part_1_in_3['cumcount'] = df_part_1_in_3.groupby(['item_category', 'behavior_type']).cumcount()\n",
    "df_part_1_c_b_count_in_3 = df_part_1_in_3.drop_duplicates(['item_category','behavior_type'], 'last')[['item_category','behavior_type','cumcount']]\n",
    "df_part_1_c_b_count_in_3 = pd.get_dummies(df_part_1_c_b_count_in_3['behavior_type']).join(df_part_1_c_b_count_in_3[['item_category','cumcount']])\n",
    "df_part_1_c_b_count_in_3.rename(columns = {1:'behavior_type_1',\n",
    "                                           2:'behavior_type_2',\n",
    "                                           3:'behavior_type_3',\n",
    "                                           4:'behavior_type_4'}, inplace=True)\n",
    "df_part_1_c_b_count_in_3['c_b1_count_in_3'] = df_part_1_c_b_count_in_3['behavior_type_1'] * (df_part_1_c_b_count_in_3['cumcount']+1)\n",
    "df_part_1_c_b_count_in_3['c_b2_count_in_3'] = df_part_1_c_b_count_in_3['behavior_type_2'] * (df_part_1_c_b_count_in_3['cumcount']+1)\n",
    "df_part_1_c_b_count_in_3['c_b3_count_in_3'] = df_part_1_c_b_count_in_3['behavior_type_3'] * (df_part_1_c_b_count_in_3['cumcount']+1)\n",
    "df_part_1_c_b_count_in_3['c_b4_count_in_3'] = df_part_1_c_b_count_in_3['behavior_type_4'] * (df_part_1_c_b_count_in_3['cumcount']+1)\n",
    "df_part_1_c_b_count_in_3 = df_part_1_c_b_count_in_3[['item_category', \n",
    "                                                     'c_b1_count_in_3', \n",
    "                                                     'c_b2_count_in_3', \n",
    "                                                     'c_b3_count_in_3',\n",
    "                                                     'c_b4_count_in_3']]\n",
    "df_part_1_c_b_count_in_3 = df_part_1_c_b_count_in_3.groupby('item_category').agg({'c_b1_count_in_3': np.sum,\n",
    "                                                                                  'c_b2_count_in_3': np.sum,\n",
    "                                                                                  'c_b3_count_in_3': np.sum,\n",
    "                                                                                  'c_b4_count_in_3': np.sum})\n",
    "df_part_1_c_b_count_in_3.reset_index(inplace = True)\n",
    "df_part_1_c_b_count_in_3['c_b_count_in_3'] = df_part_1_c_b_count_in_3['c_b1_count_in_3'] + \\\n",
    "                                             df_part_1_c_b_count_in_3['c_b2_count_in_3'] + \\\n",
    "                                             df_part_1_c_b_count_in_3['c_b3_count_in_3'] + \\\n",
    "                                             df_part_1_c_b_count_in_3['c_b4_count_in_3']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a24f0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15291/3323511955.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_part_1_in_1['cumcount'] = df_part_1_in_1.groupby(['item_category', 'behavior_type']).cumcount()\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15291/3323511955.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_1_c_b_count_in_1 = df_part_1_in_1.drop_duplicates(['item_category','behavior_type'], 'last')[['item_category','behavior_type','cumcount']]\n"
     ]
    }
   ],
   "source": [
    "# c_b_count_in_1\n",
    "df_part_1_in_1 = df_part_1[df_part_1['time'] >= np.datetime64('2014-11-27')]\n",
    "df_part_1_in_1['cumcount'] = df_part_1_in_1.groupby(['item_category', 'behavior_type']).cumcount()\n",
    "df_part_1_c_b_count_in_1 = df_part_1_in_1.drop_duplicates(['item_category','behavior_type'], 'last')[['item_category','behavior_type','cumcount']]\n",
    "df_part_1_c_b_count_in_1 = pd.get_dummies(df_part_1_c_b_count_in_1['behavior_type']).join(df_part_1_c_b_count_in_1[['item_category','cumcount']])\n",
    "df_part_1_c_b_count_in_1.rename(columns = {1:'behavior_type_1',\n",
    "                                           2:'behavior_type_2',\n",
    "                                           3:'behavior_type_3',\n",
    "                                           4:'behavior_type_4'}, inplace=True)\n",
    "df_part_1_c_b_count_in_1['c_b1_count_in_1'] = df_part_1_c_b_count_in_1['behavior_type_1'] * (df_part_1_c_b_count_in_1['cumcount']+1)\n",
    "df_part_1_c_b_count_in_1['c_b2_count_in_1'] = df_part_1_c_b_count_in_1['behavior_type_2'] * (df_part_1_c_b_count_in_1['cumcount']+1)\n",
    "df_part_1_c_b_count_in_1['c_b3_count_in_1'] = df_part_1_c_b_count_in_1['behavior_type_3'] * (df_part_1_c_b_count_in_1['cumcount']+1)\n",
    "df_part_1_c_b_count_in_1['c_b4_count_in_1'] = df_part_1_c_b_count_in_1['behavior_type_4'] * (df_part_1_c_b_count_in_1['cumcount']+1)\n",
    "df_part_1_c_b_count_in_1 = df_part_1_c_b_count_in_1[['item_category', \n",
    "                                                     'c_b1_count_in_1', \n",
    "                                                     'c_b2_count_in_1', \n",
    "                                                     'c_b3_count_in_1',\n",
    "                                                     'c_b4_count_in_1']]\n",
    "df_part_1_c_b_count_in_1 = df_part_1_c_b_count_in_1.groupby('item_category').agg({'c_b1_count_in_1': np.sum,\n",
    "                                                                                  'c_b2_count_in_1': np.sum,\n",
    "                                                                                  'c_b3_count_in_1': np.sum,\n",
    "                                                                                  'c_b4_count_in_1': np.sum})\n",
    "df_part_1_c_b_count_in_1.reset_index(inplace = True)\n",
    "df_part_1_c_b_count_in_1['c_b_count_in_1'] = df_part_1_c_b_count_in_1['c_b1_count_in_1'] + \\\n",
    "                                             df_part_1_c_b_count_in_1['c_b2_count_in_1'] + \\\n",
    "                                             df_part_1_c_b_count_in_1['c_b3_count_in_1'] + \\\n",
    "                                             df_part_1_c_b_count_in_1['c_b4_count_in_1']    \n",
    "                                             \n",
    "df_part_1_c_b_count = pd.merge(df_part_1_c_b_count_in_6, df_part_1_c_b_count_in_3, on = ['item_category'], how = 'left').fillna(0)                                      \n",
    "df_part_1_c_b_count = pd.merge(df_part_1_c_b_count, df_part_1_c_b_count_in_1, on = ['item_category'], how = 'left').fillna(0)\n",
    "df_part_1_c_b_count[['c_b1_count_in_6',\n",
    "                     'c_b2_count_in_6',\n",
    "                     'c_b3_count_in_6',\n",
    "                     'c_b4_count_in_6',\n",
    "                      'c_b_count_in_6',\n",
    "                     'c_b1_count_in_3',\n",
    "                     'c_b2_count_in_3',\n",
    "                     'c_b3_count_in_3',\n",
    "                     'c_b4_count_in_3',\n",
    "                      'c_b_count_in_3',\n",
    "                     'c_b1_count_in_1',\n",
    "                     'c_b2_count_in_1',\n",
    "                     'c_b3_count_in_1',\n",
    "                     'c_b4_count_in_1',\n",
    "                      'c_b_count_in_1']] = df_part_1_c_b_count[['c_b1_count_in_6',\n",
    "                                                                'c_b2_count_in_6',\n",
    "                                                                'c_b3_count_in_6',\n",
    "                                                                'c_b4_count_in_6',\n",
    "                                                                 'c_b_count_in_6',\n",
    "                                                                'c_b1_count_in_3',\n",
    "                                                                'c_b2_count_in_3',\n",
    "                                                                'c_b3_count_in_3',\n",
    "                                                                'c_b4_count_in_3',\n",
    "                                                                 'c_b_count_in_3',\n",
    "                                                                'c_b1_count_in_1',\n",
    "                                                                'c_b2_count_in_1',\n",
    "                                                                'c_b3_count_in_1',\n",
    "                                                                'c_b4_count_in_1',\n",
    "                                                                 'c_b_count_in_1']].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d3556af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c_b4_rate\n",
    "df_part_1_c_b_count['c_b4_rate'] = df_part_1_c_b_count['c_b4_count_in_6'] / df_part_1_c_b_count['c_b_count_in_6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f4789b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15291/1141088079.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_1_c_b4_time = df_part_1[df_part_1['behavior_type'] == 4].drop_duplicates(['item_category'], 'first')[['item_category','time']]\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15291/1141088079.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_1_c_b_time = df_part_1.drop_duplicates(['item_category'], 'first')[['item_category','time']]\n"
     ]
    }
   ],
   "source": [
    "# c_b4_diff_time\n",
    "df_part_1 = df_part_1.sort_values(by=['item_category', 'time'])\n",
    "df_part_1_c_b4_time = df_part_1[df_part_1['behavior_type'] == 4].drop_duplicates(['item_category'], 'first')[['item_category','time']]\n",
    "df_part_1_c_b4_time.columns = ['item_category','b4_first_time']\n",
    "df_part_1_c_b_time = df_part_1.drop_duplicates(['item_category'], 'first')[['item_category','time']]\n",
    "df_part_1_c_b_time.columns = ['item_category','b_first_time']\n",
    "df_part_1_c_b_b4_time = pd.merge(df_part_1_c_b_time, df_part_1_c_b4_time, on = ['item_category'])\n",
    "df_part_1_c_b_b4_time['c_b4_diff_time']  = df_part_1_c_b_b4_time['b4_first_time'] - df_part_1_c_b_b4_time['b_first_time']\n",
    "df_part_1_c_b_b4_time['c_b4_diff_hours'] = df_part_1_c_b_b4_time['c_b4_diff_time'].apply(lambda x: x.days * 24 + x.seconds//3600)\n",
    "df_part_1_c_b_b4_time = df_part_1_c_b_b4_time[['item_category',\n",
    "                                               'c_b4_diff_hours']]\n",
    "\n",
    "# generating feature set C\n",
    "f_C_part_1 = pd.merge(df_part_1_c_u_count, df_part_1_c_b_count, on = ['item_category'], how = 'left')\n",
    "f_C_part_1 = pd.merge(f_C_part_1, df_part_1_c_b_b4_time, on = ['item_category'], how = 'left')\n",
    "f_C_part_1 = f_C_part_1.round({'c_b4_rate': 3})\n",
    "\n",
    "# write to csv file\n",
    "f_C_part_1.to_csv(path_df_part_1_C, index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d6ab7a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "'''Step 1.4 feature data set IC of df_part_1\n",
    "    ic_u_rank_in_c  (in_6)\n",
    "    ic_b_rank_in_c  (in_6)\n",
    "    ic_b4_rank_in_c  (in_6)\n",
    "'''\n",
    "\n",
    "\n",
    "# get df_part_1_i_ub_count\n",
    "path_df = open(path_df_part_1_I, 'r')\n",
    "try:\n",
    "    df_part_1_I = pd.read_csv(path_df, index_col = False)\n",
    "finally:\n",
    "    path_df.close()\n",
    "df_part_1_i_ub_count = df_part_1_I[['item_id','i_u_count_in_6','i_b_count_in_6','i_b4_count_in_6']]\n",
    "del(df_part_1_I)\n",
    "\n",
    "# get df_part_1_uic for merge i & c\n",
    "path_df = open(path_df_part_1_uic_label, 'r')\n",
    "try:\n",
    "    df_part_1_uic = pd.read_csv(path_df, index_col = False)\n",
    "finally:\n",
    "    path_df.close()\n",
    "df_part_1_ic_u_b_count = pd.merge(df_part_1_uic, df_part_1_i_ub_count, on=['item_id'], how='left').fillna(0)\n",
    "df_part_1_ic_u_b_count = df_part_1_ic_u_b_count.drop_duplicates(['item_id','item_category'])\n",
    "\n",
    "# ic_u_rank_in_c\n",
    "df_part_1_ic_u_b_count['ic_u_rank_in_c'] = df_part_1_ic_u_b_count.groupby('item_category')['i_u_count_in_6'].rank(method='min',ascending=False).astype('int')\n",
    "# ic_b_rank_in_c\n",
    "df_part_1_ic_u_b_count['ic_b_rank_in_c'] = df_part_1_ic_u_b_count.groupby('item_category')['i_b_count_in_6'].rank(method='min',ascending=False).astype('int')\n",
    "# ic_b4_rank_in_c\n",
    "df_part_1_ic_u_b_count['ic_b4_rank_in_c'] = df_part_1_ic_u_b_count.groupby('item_category')['i_b4_count_in_6'].rank(method='min',ascending=False).astype('int')\n",
    "\n",
    "f_IC_part_1 = df_part_1_ic_u_b_count[['item_id', \n",
    "                                      'item_category', \n",
    "                                      'ic_u_rank_in_c', \n",
    "                                      'ic_b_rank_in_c', \n",
    "                                      'ic_b4_rank_in_c']]\n",
    "# write to csv file\n",
    "f_IC_part_1.to_csv(path_df_part_1_IC, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec1357f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Step 1.5 feature data set UI of df_part_1\\n    (1)\\n    ui_b1_count_in_6\\n    ui_b2_count_in_6\\n    ui_b3_count_in_6\\n    ui_b4_count_in_6\\n     ui_b_count_in_6\\n    ui_b1_count_in_3\\n    ui_b2_count_in_3\\n    ui_b3_count_in_3\\n    ui_b4_count_in_3\\n     ui_b_count_in_3\\n    ui_b1_count_in_1\\n    ui_b2_count_in_1\\n    ui_b3_count_in_1\\n    ui_b4_count_in_1\\n     ui_b_count_in_1\\n    (2)\\n    ui_b_count_rank_in_u  (in_6)\\n    ui_b_count_rank_in_uc (in_6)\\n    (3)\\n    ui_b1_last_hours  (in_6)\\n    ui_b2_last_hours  (in_6)\\n    ui_b3_last_hours  (in_6)\\n    ui_b4_last_hours  (in_6)\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################################\n",
    "'''Step 1.5 feature data set UI of df_part_1\n",
    "    (1)\n",
    "    ui_b1_count_in_6\n",
    "    ui_b2_count_in_6\n",
    "    ui_b3_count_in_6\n",
    "    ui_b4_count_in_6\n",
    "     ui_b_count_in_6\n",
    "    ui_b1_count_in_3\n",
    "    ui_b2_count_in_3\n",
    "    ui_b3_count_in_3\n",
    "    ui_b4_count_in_3\n",
    "     ui_b_count_in_3\n",
    "    ui_b1_count_in_1\n",
    "    ui_b2_count_in_1\n",
    "    ui_b3_count_in_1\n",
    "    ui_b4_count_in_1\n",
    "     ui_b_count_in_1\n",
    "    (2)\n",
    "    ui_b_count_rank_in_u  (in_6)\n",
    "    ui_b_count_rank_in_uc (in_6)\n",
    "    (3)\n",
    "    ui_b1_last_hours  (in_6)\n",
    "    ui_b2_last_hours  (in_6)\n",
    "    ui_b3_last_hours  (in_6)\n",
    "    ui_b4_last_hours  (in_6)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d0a39684",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_df = open(path_df_part_1, 'r')\n",
    "try:\n",
    "    df_part_1 = pd.read_csv(path_df, index_col = False, parse_dates = [0])\n",
    "    df_part_1.columns = ['time','user_id','item_id','behavior_type','item_category']\n",
    "finally:\n",
    "    path_df.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c2b62bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15291/1457477996.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_1_ui_b_count_in_6 = df_part_1.drop_duplicates(['user_id','item_id','behavior_type'],'last')[['user_id','item_id','behavior_type','cumcount']]\n"
     ]
    }
   ],
   "source": [
    "# ui_b_count_in_6\n",
    "df_part_1['cumcount'] = df_part_1.groupby(['user_id', 'item_id', 'behavior_type']).cumcount()\n",
    "df_part_1_ui_b_count_in_6 = df_part_1.drop_duplicates(['user_id','item_id','behavior_type'],'last')[['user_id','item_id','behavior_type','cumcount']]\n",
    "df_part_1_ui_b_count_in_6 = pd.get_dummies(df_part_1_ui_b_count_in_6['behavior_type']).join(df_part_1_ui_b_count_in_6[['user_id','item_id','cumcount']])\n",
    "df_part_1_ui_b_count_in_6.rename(columns = {1:'behavior_type_1',\n",
    "                                            2:'behavior_type_2',\n",
    "                                            3:'behavior_type_3',\n",
    "                                            4:'behavior_type_4'}, inplace=True)  \n",
    "df_part_1_ui_b_count_in_6['ui_b1_count_in_6'] = df_part_1_ui_b_count_in_6['behavior_type_1'] * (df_part_1_ui_b_count_in_6['cumcount']+1)\n",
    "df_part_1_ui_b_count_in_6['ui_b2_count_in_6'] = df_part_1_ui_b_count_in_6['behavior_type_2'] * (df_part_1_ui_b_count_in_6['cumcount']+1)\n",
    "df_part_1_ui_b_count_in_6['ui_b3_count_in_6'] = df_part_1_ui_b_count_in_6['behavior_type_3'] * (df_part_1_ui_b_count_in_6['cumcount']+1)\n",
    "df_part_1_ui_b_count_in_6['ui_b4_count_in_6'] = df_part_1_ui_b_count_in_6['behavior_type_4'] * (df_part_1_ui_b_count_in_6['cumcount']+1)\n",
    "df_part_1_ui_b_count_in_6 = df_part_1_ui_b_count_in_6[['user_id', \n",
    "                                                       'item_id', \n",
    "                                                       'ui_b1_count_in_6', \n",
    "                                                       'ui_b2_count_in_6', \n",
    "                                                       'ui_b3_count_in_6',\n",
    "                                                       'ui_b4_count_in_6']]\n",
    "df_part_1_ui_b_count_in_6 = df_part_1_ui_b_count_in_6.groupby(['user_id', 'item_id']).agg({'ui_b1_count_in_6': np.sum,\n",
    "                                                                                           'ui_b2_count_in_6': np.sum,\n",
    "                                                                                           'ui_b3_count_in_6': np.sum,\n",
    "                                                                                           'ui_b4_count_in_6': np.sum})\n",
    "df_part_1_ui_b_count_in_6.reset_index(inplace = True)\n",
    "df_part_1_ui_b_count_in_6['ui_b_count_in_6'] = df_part_1_ui_b_count_in_6['ui_b1_count_in_6'] + \\\n",
    "                                               df_part_1_ui_b_count_in_6['ui_b2_count_in_6'] + \\\n",
    "                                               df_part_1_ui_b_count_in_6['ui_b3_count_in_6'] + \\\n",
    "                                               df_part_1_ui_b_count_in_6['ui_b4_count_in_6']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8100495d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15291/1641191217.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_part_1_in_3['cumcount'] = df_part_1_in_3.groupby(['user_id', 'item_id', 'behavior_type']).cumcount()\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15291/1641191217.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_1_ui_b_count_in_3 = df_part_1.drop_duplicates(['user_id','item_id','behavior_type'],'last')[['user_id','item_id','behavior_type','cumcount']]\n"
     ]
    }
   ],
   "source": [
    "# ui_b_count_in_3\n",
    "df_part_1_in_3 = df_part_1[df_part_1['time'] >= np.datetime64('2014-11-25')]\n",
    "df_part_1_in_3['cumcount'] = df_part_1_in_3.groupby(['user_id', 'item_id', 'behavior_type']).cumcount()\n",
    "df_part_1_ui_b_count_in_3 = df_part_1.drop_duplicates(['user_id','item_id','behavior_type'],'last')[['user_id','item_id','behavior_type','cumcount']]\n",
    "df_part_1_ui_b_count_in_3 = pd.get_dummies(df_part_1_ui_b_count_in_3['behavior_type']).join(df_part_1_ui_b_count_in_3[['user_id','item_id','cumcount']])\n",
    "df_part_1_ui_b_count_in_3.rename(columns = {1:'behavior_type_1',\n",
    "                                            2:'behavior_type_2',\n",
    "                                            3:'behavior_type_3',\n",
    "                                            4:'behavior_type_4'}, inplace=True)  \n",
    "df_part_1_ui_b_count_in_3['ui_b1_count_in_3'] = df_part_1_ui_b_count_in_3['behavior_type_1'] * (df_part_1_ui_b_count_in_3['cumcount']+1)\n",
    "df_part_1_ui_b_count_in_3['ui_b2_count_in_3'] = df_part_1_ui_b_count_in_3['behavior_type_2'] * (df_part_1_ui_b_count_in_3['cumcount']+1)\n",
    "df_part_1_ui_b_count_in_3['ui_b3_count_in_3'] = df_part_1_ui_b_count_in_3['behavior_type_3'] * (df_part_1_ui_b_count_in_3['cumcount']+1)\n",
    "df_part_1_ui_b_count_in_3['ui_b4_count_in_3'] = df_part_1_ui_b_count_in_3['behavior_type_4'] * (df_part_1_ui_b_count_in_3['cumcount']+1)\n",
    "df_part_1_ui_b_count_in_3 = df_part_1_ui_b_count_in_3[['user_id', \n",
    "                                                       'item_id', \n",
    "                                                       'ui_b1_count_in_3', \n",
    "                                                       'ui_b2_count_in_3', \n",
    "                                                       'ui_b3_count_in_3',\n",
    "                                                       'ui_b4_count_in_3']]\n",
    "df_part_1_ui_b_count_in_3 = df_part_1_ui_b_count_in_3.groupby(['user_id', 'item_id']).agg({'ui_b1_count_in_3': np.sum,\n",
    "                                                                                           'ui_b2_count_in_3': np.sum,\n",
    "                                                                                           'ui_b3_count_in_3': np.sum,\n",
    "                                                                                           'ui_b4_count_in_3': np.sum})\n",
    "df_part_1_ui_b_count_in_3.reset_index(inplace = True)\n",
    "df_part_1_ui_b_count_in_3['ui_b_count_in_3'] = df_part_1_ui_b_count_in_3['ui_b1_count_in_3'] + \\\n",
    "                                               df_part_1_ui_b_count_in_3['ui_b2_count_in_3'] + \\\n",
    "                                               df_part_1_ui_b_count_in_3['ui_b3_count_in_3'] + \\\n",
    "                                               df_part_1_ui_b_count_in_3['ui_b4_count_in_3']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a7bf9633",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15291/2403816284.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_part_1_in_1['cumcount'] = df_part_1_in_1.groupby(['user_id', 'item_id', 'behavior_type']).cumcount()\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15291/2403816284.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_1_ui_b_count_in_1 = df_part_1_in_1.drop_duplicates(['user_id','item_id','behavior_type'], 'last')[['user_id','item_id','behavior_type','cumcount']]\n"
     ]
    }
   ],
   "source": [
    "# ui_b_count_in_1\n",
    "df_part_1_in_1 = df_part_1[df_part_1['time'] >= np.datetime64('2014-11-27')]\n",
    "df_part_1_in_1['cumcount'] = df_part_1_in_1.groupby(['user_id', 'item_id', 'behavior_type']).cumcount()\n",
    "df_part_1_ui_b_count_in_1 = df_part_1_in_1.drop_duplicates(['user_id','item_id','behavior_type'], 'last')[['user_id','item_id','behavior_type','cumcount']]\n",
    "df_part_1_ui_b_count_in_1 = pd.get_dummies(df_part_1_ui_b_count_in_1['behavior_type']).join(df_part_1_ui_b_count_in_1[['user_id','item_id','cumcount']])\n",
    "df_part_1_ui_b_count_in_1.rename(columns = {1:'behavior_type_1',\n",
    "                                            2:'behavior_type_2',\n",
    "                                            3:'behavior_type_3',\n",
    "                                            4:'behavior_type_4'}, inplace=True)\n",
    "df_part_1_ui_b_count_in_1['ui_b1_count_in_1'] = df_part_1_ui_b_count_in_1['behavior_type_1'] * (df_part_1_ui_b_count_in_1['cumcount']+1)\n",
    "df_part_1_ui_b_count_in_1['ui_b2_count_in_1'] = df_part_1_ui_b_count_in_1['behavior_type_2'] * (df_part_1_ui_b_count_in_1['cumcount']+1)\n",
    "df_part_1_ui_b_count_in_1['ui_b3_count_in_1'] = df_part_1_ui_b_count_in_1['behavior_type_3'] * (df_part_1_ui_b_count_in_1['cumcount']+1)\n",
    "df_part_1_ui_b_count_in_1['ui_b4_count_in_1'] = df_part_1_ui_b_count_in_1['behavior_type_4'] * (df_part_1_ui_b_count_in_1['cumcount']+1)\n",
    "df_part_1_ui_b_count_in_1 = df_part_1_ui_b_count_in_1[['user_id',\n",
    "                                                       'item_id', \n",
    "                                                       'ui_b1_count_in_1', \n",
    "                                                       'ui_b2_count_in_1', \n",
    "                                                       'ui_b3_count_in_1',\n",
    "                                                       'ui_b4_count_in_1']]\n",
    "df_part_1_ui_b_count_in_1 = df_part_1_ui_b_count_in_1.groupby(['user_id', 'item_id']).agg({'ui_b1_count_in_1': np.sum,\n",
    "                                                                                           'ui_b2_count_in_1': np.sum,\n",
    "                                                                                           'ui_b3_count_in_1': np.sum,\n",
    "                                                                                           'ui_b4_count_in_1': np.sum})\n",
    "df_part_1_ui_b_count_in_1.reset_index(inplace = True)\n",
    "df_part_1_ui_b_count_in_1['ui_b_count_in_1'] = df_part_1_ui_b_count_in_1['ui_b1_count_in_1'] + \\\n",
    "                                               df_part_1_ui_b_count_in_1['ui_b2_count_in_1'] + \\\n",
    "                                               df_part_1_ui_b_count_in_1['ui_b3_count_in_1'] + \\\n",
    "                                               df_part_1_ui_b_count_in_1['ui_b4_count_in_1']\n",
    "                                             \n",
    "df_part_1_ui_b_count = pd.merge(df_part_1_ui_b_count_in_6, df_part_1_ui_b_count_in_3, on = ['user_id','item_id'], how = 'left').fillna(0)\n",
    "df_part_1_ui_b_count = pd.merge(df_part_1_ui_b_count, df_part_1_ui_b_count_in_1, on = ['user_id','item_id'], how = 'left').fillna(0)\n",
    "df_part_1_ui_b_count[['ui_b1_count_in_6',\n",
    "                      'ui_b2_count_in_6',\n",
    "                      'ui_b3_count_in_6',\n",
    "                      'ui_b4_count_in_6',\n",
    "                       'ui_b_count_in_6',\n",
    "                      'ui_b1_count_in_3',\n",
    "                      'ui_b2_count_in_3',\n",
    "                      'ui_b3_count_in_3',\n",
    "                      'ui_b4_count_in_3',\n",
    "                       'ui_b_count_in_3',\n",
    "                      'ui_b1_count_in_1',\n",
    "                      'ui_b2_count_in_1',\n",
    "                      'ui_b3_count_in_1',\n",
    "                      'ui_b4_count_in_1',\n",
    "                       'ui_b_count_in_1']] = df_part_1_ui_b_count[['ui_b1_count_in_6',\n",
    "                                                                   'ui_b2_count_in_6',\n",
    "                                                                   'ui_b3_count_in_6',\n",
    "                                                                   'ui_b4_count_in_6',\n",
    "                                                                    'ui_b_count_in_6',\n",
    "                                                                   'ui_b1_count_in_3',\n",
    "                                                                   'ui_b2_count_in_3',\n",
    "                                                                   'ui_b3_count_in_3',\n",
    "                                                                   'ui_b4_count_in_3',\n",
    "                                                                    'ui_b_count_in_3',\n",
    "                                                                   'ui_b1_count_in_1',\n",
    "                                                                   'ui_b2_count_in_1',\n",
    "                                                                   'ui_b3_count_in_1',\n",
    "                                                                   'ui_b4_count_in_1',\n",
    "                                                                    'ui_b_count_in_1']].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "06224da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ui_b_count_rank_in_u\n",
    "df_part_1_ui_b_count['ui_b_count_rank_in_u'] = df_part_1_ui_b_count.groupby(['user_id'])['ui_b_count_in_6'].rank(method='min',ascending=False).astype('int')\n",
    "\n",
    "# ui_b_count_rank_in_uc\n",
    "path_df = open(path_df_part_1_uic_label, 'r')\n",
    "try:\n",
    "    df_part_1_uic = pd.read_csv(path_df, index_col = False)\n",
    "finally:\n",
    "    path_df.close()\n",
    "df_part_1_ui_b_count = pd.merge(df_part_1_uic, df_part_1_ui_b_count, on = ['user_id','item_id'], how = 'left')\n",
    "df_part_1_ui_b_count['ui_b_count_rank_in_uc'] = df_part_1_ui_b_count.groupby(['user_id','item_category'])['ui_b_count_rank_in_u'].rank(method='min',ascending=True).astype('int')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3c6e9ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15291/578439699.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_1_ui_b_last_time = df_part_1.drop_duplicates(['user_id','item_id','behavior_type'],'last')[['user_id','item_id','behavior_type','time']]\n"
     ]
    }
   ],
   "source": [
    "# ui_b_last_time\n",
    "df_part_1.sort_values(by=['user_id','item_id','behavior_type','time'], inplace=True)\n",
    "df_part_1_ui_b_last_time = df_part_1.drop_duplicates(['user_id','item_id','behavior_type'],'last')[['user_id','item_id','behavior_type','time']]\n",
    "\n",
    "df_part_1_ui_b_last_time['ui_b1_last_time'] = df_part_1_ui_b_last_time[df_part_1_ui_b_last_time['behavior_type'] == 1]['time']\n",
    "df_part_1_ui_b_last_time['ui_b2_last_time'] = df_part_1_ui_b_last_time[df_part_1_ui_b_last_time['behavior_type'] == 2]['time']\n",
    "df_part_1_ui_b_last_time['ui_b3_last_time'] = df_part_1_ui_b_last_time[df_part_1_ui_b_last_time['behavior_type'] == 3]['time']\n",
    "df_part_1_ui_b_last_time['ui_b4_last_time'] = df_part_1_ui_b_last_time[df_part_1_ui_b_last_time['behavior_type'] == 4]['time']\n",
    "\n",
    "df_part_1_ui_b_last_time.loc[df_part_1_ui_b_last_time['ui_b1_last_time'].notnull(), 'ui_b1_last_hours'] = (pd.to_datetime('2014-11-28') - df_part_1_ui_b_last_time['ui_b1_last_time'])             \n",
    "df_part_1_ui_b_last_time['ui_b1_last_hours'] = df_part_1_ui_b_last_time[df_part_1_ui_b_last_time['ui_b1_last_hours'].notnull()]['ui_b1_last_hours'].apply(lambda x: x.days*24 + x.seconds//3600)\n",
    "\n",
    "df_part_1_ui_b_last_time.loc[df_part_1_ui_b_last_time['ui_b2_last_time'].notnull(), 'ui_b2_last_hours'] = (pd.to_datetime('2014-11-28') - df_part_1_ui_b_last_time['ui_b2_last_time'])             \n",
    "df_part_1_ui_b_last_time['ui_b2_last_hours'] = df_part_1_ui_b_last_time[df_part_1_ui_b_last_time['ui_b2_last_hours'].notnull()]['ui_b2_last_hours'].apply(lambda x: x.days*24 + x.seconds//3600)\n",
    "\n",
    "df_part_1_ui_b_last_time.loc[df_part_1_ui_b_last_time['ui_b3_last_time'].notnull(), 'ui_b3_last_hours'] = (pd.to_datetime('2014-11-28') - df_part_1_ui_b_last_time['ui_b3_last_time'])             \n",
    "df_part_1_ui_b_last_time['ui_b3_last_hours'] = df_part_1_ui_b_last_time[df_part_1_ui_b_last_time['ui_b3_last_hours'].notnull()]['ui_b3_last_hours'].apply(lambda x: x.days*24 + x.seconds//3600)\n",
    "\n",
    "df_part_1_ui_b_last_time.loc[df_part_1_ui_b_last_time['ui_b4_last_time'].notnull(), 'ui_b4_last_hours'] = (pd.to_datetime('2014-11-28') - df_part_1_ui_b_last_time['ui_b4_last_time'])             \n",
    "df_part_1_ui_b_last_time['ui_b4_last_hours'] = df_part_1_ui_b_last_time[df_part_1_ui_b_last_time['ui_b4_last_hours'].notnull()]['ui_b4_last_hours'].apply(lambda x: x.days*24 + x.seconds//3600)\n",
    "\n",
    "df_part_1_ui_b_last_time = df_part_1_ui_b_last_time[['user_id',\n",
    "                                                     'item_id',\n",
    "                                                     'ui_b1_last_hours',\n",
    "                                                     'ui_b2_last_hours',\n",
    "                                                     'ui_b3_last_hours',\n",
    "                                                     'ui_b4_last_hours']] \n",
    "\n",
    "df_part_1_ui_b_last_time = df_part_1_ui_b_last_time.groupby(['user_id', 'item_id']).agg({'ui_b1_last_hours': np.sum,\n",
    "                                                                                         'ui_b2_last_hours': np.sum,\n",
    "                                                                                         'ui_b3_last_hours': np.sum,\n",
    "                                                                                         'ui_b4_last_hours': np.sum})\n",
    "df_part_1_ui_b_last_time.reset_index(inplace = True)\n",
    "\n",
    "# merge for generation of f_UI_part_1\n",
    "f_UI_part_1 = pd.merge(df_part_1_ui_b_count, df_part_1_ui_b_last_time, how='left', on=['user_id', 'item_id'])\n",
    "\n",
    "# write to csv file\n",
    "f_UI_part_1.to_csv(path_df_part_1_UI, index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "adbbc738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Step 1.6 feature data set UC of df_part_1\\n    (1)\\n    uc_b1_count_in_6\\n    uc_b2_count_in_6\\n    uc_b3_count_in_6\\n    uc_b4_count_in_6\\n     uc_b_count_in_6\\n    uc_b1_count_in_3\\n    uc_b2_count_in_3\\n    uc_b3_count_in_3\\n    uc_b4_count_in_3\\n     uc_b_count_in_3\\n    uc_b1_count_in_1\\n    uc_b2_count_in_1\\n    uc_b3_count_in_1\\n    uc_b4_count_in_1\\n     uc_b_count_in_1\\n    (2)\\n    uc_b_count_rank_in_u  (in_6)\\n    (3)\\n    uc_b1_last_hours  (in_6)\\n    uc_b2_last_hours  (in_6)\\n    uc_b3_last_hours  (in_6)\\n    uc_b4_last_hours  (in_6)\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################################\n",
    "'''Step 1.6 feature data set UC of df_part_1\n",
    "    (1)\n",
    "    uc_b1_count_in_6\n",
    "    uc_b2_count_in_6\n",
    "    uc_b3_count_in_6\n",
    "    uc_b4_count_in_6\n",
    "     uc_b_count_in_6\n",
    "    uc_b1_count_in_3\n",
    "    uc_b2_count_in_3\n",
    "    uc_b3_count_in_3\n",
    "    uc_b4_count_in_3\n",
    "     uc_b_count_in_3\n",
    "    uc_b1_count_in_1\n",
    "    uc_b2_count_in_1\n",
    "    uc_b3_count_in_1\n",
    "    uc_b4_count_in_1\n",
    "     uc_b_count_in_1\n",
    "    (2)\n",
    "    uc_b_count_rank_in_u  (in_6)\n",
    "    (3)\n",
    "    uc_b1_last_hours  (in_6)\n",
    "    uc_b2_last_hours  (in_6)\n",
    "    uc_b3_last_hours  (in_6)\n",
    "    uc_b4_last_hours  (in_6)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "76751f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_df = open(path_df_part_1, 'r')\n",
    "try:\n",
    "    df_part_1 = pd.read_csv(path_df, index_col = False, parse_dates = [0])\n",
    "    df_part_1.columns = ['time','user_id','item_id','behavior_type','item_category']\n",
    "finally:\n",
    "    path_df.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9ad67589",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15291/4224979974.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_1_uc_b_count_in_6 = df_part_1.drop_duplicates(['user_id','item_category','behavior_type'],'last')[['user_id','item_category','behavior_type','cumcount']]\n"
     ]
    }
   ],
   "source": [
    "# uc_b_count_in_6\n",
    "df_part_1['cumcount'] = df_part_1.groupby(['user_id', 'item_category', 'behavior_type']).cumcount()\n",
    "df_part_1_uc_b_count_in_6 = df_part_1.drop_duplicates(['user_id','item_category','behavior_type'],'last')[['user_id','item_category','behavior_type','cumcount']]\n",
    "df_part_1_uc_b_count_in_6 = pd.get_dummies(df_part_1_uc_b_count_in_6['behavior_type']).join(df_part_1_uc_b_count_in_6[['user_id','item_category','cumcount']])\n",
    "df_part_1_uc_b_count_in_6.rename(columns = {1:'behavior_type_1',\n",
    "                                            2:'behavior_type_2',\n",
    "                                            3:'behavior_type_3',\n",
    "                                            4:'behavior_type_4'}, inplace=True)  \n",
    "df_part_1_uc_b_count_in_6['uc_b1_count_in_6'] = df_part_1_uc_b_count_in_6['behavior_type_1'] * (df_part_1_uc_b_count_in_6['cumcount']+1)\n",
    "df_part_1_uc_b_count_in_6['uc_b2_count_in_6'] = df_part_1_uc_b_count_in_6['behavior_type_2'] * (df_part_1_uc_b_count_in_6['cumcount']+1)\n",
    "df_part_1_uc_b_count_in_6['uc_b3_count_in_6'] = df_part_1_uc_b_count_in_6['behavior_type_3'] * (df_part_1_uc_b_count_in_6['cumcount']+1)\n",
    "df_part_1_uc_b_count_in_6['uc_b4_count_in_6'] = df_part_1_uc_b_count_in_6['behavior_type_4'] * (df_part_1_uc_b_count_in_6['cumcount']+1)\n",
    "df_part_1_uc_b_count_in_6 = df_part_1_uc_b_count_in_6[['user_id', \n",
    "                                                       'item_category', \n",
    "                                                       'uc_b1_count_in_6', \n",
    "                                                       'uc_b2_count_in_6', \n",
    "                                                       'uc_b3_count_in_6',\n",
    "                                                       'uc_b4_count_in_6']]\n",
    "df_part_1_uc_b_count_in_6 = df_part_1_uc_b_count_in_6.groupby(['user_id', 'item_category']).agg({'uc_b1_count_in_6': np.sum,\n",
    "                                                                                                 'uc_b2_count_in_6': np.sum,\n",
    "                                                                                                 'uc_b3_count_in_6': np.sum,\n",
    "                                                                                                 'uc_b4_count_in_6': np.sum})\n",
    "df_part_1_uc_b_count_in_6.reset_index(inplace = True)\n",
    "df_part_1_uc_b_count_in_6['uc_b_count_in_6'] = df_part_1_uc_b_count_in_6['uc_b1_count_in_6'] + \\\n",
    "                                               df_part_1_uc_b_count_in_6['uc_b2_count_in_6'] + \\\n",
    "                                               df_part_1_uc_b_count_in_6['uc_b3_count_in_6'] + \\\n",
    "                                               df_part_1_uc_b_count_in_6['uc_b4_count_in_6']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b200187f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15291/813666947.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_part_1_in_3['cumcount'] = df_part_1_in_3.groupby(['user_id', 'item_category', 'behavior_type']).cumcount()\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15291/813666947.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_1_uc_b_count_in_3 = df_part_1.drop_duplicates(['user_id','item_category','behavior_type'],'last')[['user_id','item_category','behavior_type','cumcount']]\n"
     ]
    }
   ],
   "source": [
    "# uc_b_count_in_3\n",
    "df_part_1_in_3 = df_part_1[df_part_1['time'] >= np.datetime64('2014-11-25')]\n",
    "df_part_1_in_3['cumcount'] = df_part_1_in_3.groupby(['user_id', 'item_category', 'behavior_type']).cumcount()\n",
    "df_part_1_uc_b_count_in_3 = df_part_1.drop_duplicates(['user_id','item_category','behavior_type'],'last')[['user_id','item_category','behavior_type','cumcount']]\n",
    "df_part_1_uc_b_count_in_3 = pd.get_dummies(df_part_1_uc_b_count_in_3['behavior_type']).join(df_part_1_uc_b_count_in_3[['user_id','item_category','cumcount']])\n",
    "df_part_1_uc_b_count_in_3.rename(columns = {1:'behavior_type_1',\n",
    "                                            2:'behavior_type_2',\n",
    "                                            3:'behavior_type_3',\n",
    "                                            4:'behavior_type_4'}, inplace=True)  \n",
    "df_part_1_uc_b_count_in_3['uc_b1_count_in_3'] = df_part_1_uc_b_count_in_3['behavior_type_1'] * (df_part_1_uc_b_count_in_3['cumcount']+1)\n",
    "df_part_1_uc_b_count_in_3['uc_b2_count_in_3'] = df_part_1_uc_b_count_in_3['behavior_type_2'] * (df_part_1_uc_b_count_in_3['cumcount']+1)\n",
    "df_part_1_uc_b_count_in_3['uc_b3_count_in_3'] = df_part_1_uc_b_count_in_3['behavior_type_3'] * (df_part_1_uc_b_count_in_3['cumcount']+1)\n",
    "df_part_1_uc_b_count_in_3['uc_b4_count_in_3'] = df_part_1_uc_b_count_in_3['behavior_type_4'] * (df_part_1_uc_b_count_in_3['cumcount']+1)\n",
    "df_part_1_uc_b_count_in_3 = df_part_1_uc_b_count_in_3[['user_id', \n",
    "                                                       'item_category', \n",
    "                                                       'uc_b1_count_in_3', \n",
    "                                                       'uc_b2_count_in_3', \n",
    "                                                       'uc_b3_count_in_3',\n",
    "                                                       'uc_b4_count_in_3']]\n",
    "df_part_1_uc_b_count_in_3 = df_part_1_uc_b_count_in_3.groupby(['user_id', 'item_category']).agg({'uc_b1_count_in_3': np.sum,\n",
    "                                                                                                 'uc_b2_count_in_3': np.sum,\n",
    "                                                                                                 'uc_b3_count_in_3': np.sum,\n",
    "                                                                                                 'uc_b4_count_in_3': np.sum})\n",
    "df_part_1_uc_b_count_in_3.reset_index(inplace = True)\n",
    "df_part_1_uc_b_count_in_3['uc_b_count_in_3'] = df_part_1_uc_b_count_in_3['uc_b1_count_in_3'] + \\\n",
    "                                               df_part_1_uc_b_count_in_3['uc_b2_count_in_3'] + \\\n",
    "                                               df_part_1_uc_b_count_in_3['uc_b3_count_in_3'] + \\\n",
    "                                               df_part_1_uc_b_count_in_3['uc_b4_count_in_3']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5ed42b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15291/1793754335.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_part_1_in_1['cumcount'] = df_part_1_in_1.groupby(['user_id', 'item_category', 'behavior_type']).cumcount()\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15291/1793754335.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_1_uc_b_count_in_1 = df_part_1_in_1.drop_duplicates(['user_id','item_category','behavior_type'], 'last')[['user_id','item_category','behavior_type','cumcount']]\n"
     ]
    }
   ],
   "source": [
    "# uc_b_count_in_1\n",
    "df_part_1_in_1 = df_part_1[df_part_1['time'] >= np.datetime64('2014-11-27')]\n",
    "df_part_1_in_1['cumcount'] = df_part_1_in_1.groupby(['user_id', 'item_category', 'behavior_type']).cumcount()\n",
    "df_part_1_uc_b_count_in_1 = df_part_1_in_1.drop_duplicates(['user_id','item_category','behavior_type'], 'last')[['user_id','item_category','behavior_type','cumcount']]\n",
    "df_part_1_uc_b_count_in_1 = pd.get_dummies(df_part_1_uc_b_count_in_1['behavior_type']).join(df_part_1_uc_b_count_in_1[['user_id','item_category','cumcount']])\n",
    "df_part_1_uc_b_count_in_1.rename(columns = {1:'behavior_type_1',\n",
    "                                            2:'behavior_type_2',\n",
    "                                            3:'behavior_type_3',\n",
    "                                            4:'behavior_type_4'}, inplace=True)\n",
    "df_part_1_uc_b_count_in_1['uc_b1_count_in_1'] = df_part_1_uc_b_count_in_1['behavior_type_1'] * (df_part_1_uc_b_count_in_1['cumcount']+1)\n",
    "df_part_1_uc_b_count_in_1['uc_b2_count_in_1'] = df_part_1_uc_b_count_in_1['behavior_type_2'] * (df_part_1_uc_b_count_in_1['cumcount']+1)\n",
    "df_part_1_uc_b_count_in_1['uc_b3_count_in_1'] = df_part_1_uc_b_count_in_1['behavior_type_3'] * (df_part_1_uc_b_count_in_1['cumcount']+1)\n",
    "df_part_1_uc_b_count_in_1['uc_b4_count_in_1'] = df_part_1_uc_b_count_in_1['behavior_type_4'] * (df_part_1_uc_b_count_in_1['cumcount']+1)\n",
    "df_part_1_uc_b_count_in_1 = df_part_1_uc_b_count_in_1[['user_id',\n",
    "                                                       'item_category', \n",
    "                                                       'uc_b1_count_in_1', \n",
    "                                                       'uc_b2_count_in_1', \n",
    "                                                       'uc_b3_count_in_1',\n",
    "                                                       'uc_b4_count_in_1']]\n",
    "df_part_1_uc_b_count_in_1 = df_part_1_uc_b_count_in_1.groupby(['user_id', 'item_category']).agg({'uc_b1_count_in_1': np.sum,\n",
    "                                                                                                 'uc_b2_count_in_1': np.sum,\n",
    "                                                                                                 'uc_b3_count_in_1': np.sum,\n",
    "                                                                                                 'uc_b4_count_in_1': np.sum})\n",
    "df_part_1_uc_b_count_in_1.reset_index(inplace = True)\n",
    "df_part_1_uc_b_count_in_1['uc_b_count_in_1'] = df_part_1_uc_b_count_in_1['uc_b1_count_in_1'] + \\\n",
    "                                               df_part_1_uc_b_count_in_1['uc_b2_count_in_1'] + \\\n",
    "                                               df_part_1_uc_b_count_in_1['uc_b3_count_in_1'] + \\\n",
    "                                               df_part_1_uc_b_count_in_1['uc_b4_count_in_1']\n",
    "                                             \n",
    "df_part_1_uc_b_count = pd.merge(df_part_1_uc_b_count_in_6, df_part_1_uc_b_count_in_3, on = ['user_id','item_category'], how = 'left').fillna(0)\n",
    "df_part_1_uc_b_count = pd.merge(df_part_1_uc_b_count, df_part_1_uc_b_count_in_1, on = ['user_id','item_category'], how = 'left').fillna(0)\n",
    "df_part_1_uc_b_count[['uc_b1_count_in_6',\n",
    "                      'uc_b2_count_in_6',\n",
    "                      'uc_b3_count_in_6',\n",
    "                      'uc_b4_count_in_6',\n",
    "                       'uc_b_count_in_6',\n",
    "                      'uc_b1_count_in_3',\n",
    "                      'uc_b2_count_in_3',\n",
    "                      'uc_b3_count_in_3',\n",
    "                      'uc_b4_count_in_3',\n",
    "                       'uc_b_count_in_3',\n",
    "                      'uc_b1_count_in_1',\n",
    "                      'uc_b2_count_in_1',\n",
    "                      'uc_b3_count_in_1',\n",
    "                      'uc_b4_count_in_1',\n",
    "                       'uc_b_count_in_1']] = df_part_1_uc_b_count[['uc_b1_count_in_6',\n",
    "                                                                   'uc_b2_count_in_6',\n",
    "                                                                   'uc_b3_count_in_6',\n",
    "                                                                   'uc_b4_count_in_6',\n",
    "                                                                    'uc_b_count_in_6',\n",
    "                                                                   'uc_b1_count_in_3',\n",
    "                                                                   'uc_b2_count_in_3',\n",
    "                                                                   'uc_b3_count_in_3',\n",
    "                                                                   'uc_b4_count_in_3',\n",
    "                                                                    'uc_b_count_in_3',\n",
    "                                                                   'uc_b1_count_in_1',\n",
    "                                                                   'uc_b2_count_in_1',\n",
    "                                                                   'uc_b3_count_in_1',\n",
    "                                                                   'uc_b4_count_in_1',\n",
    "                                                                    'uc_b_count_in_1']].astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a54f80a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15291/661449523.py:6: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_1_uc_b_last_time = df_part_1.drop_duplicates(['user_id','item_category','behavior_type'],'last')[['user_id','item_category','behavior_type','time']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " part1 done \n"
     ]
    }
   ],
   "source": [
    "# uc_b_count_rank_in_u\n",
    "df_part_1_uc_b_count['uc_b_count_rank_in_u'] = df_part_1_uc_b_count.groupby(['user_id'])['uc_b_count_in_6'].rank(method='min',ascending=False).astype('int')\n",
    "\n",
    "# uc_b_last_time\n",
    "df_part_1.sort_values(by=['user_id','item_category','behavior_type','time'], inplace=True)\n",
    "df_part_1_uc_b_last_time = df_part_1.drop_duplicates(['user_id','item_category','behavior_type'],'last')[['user_id','item_category','behavior_type','time']]\n",
    "\n",
    "df_part_1_uc_b_last_time['uc_b1_last_time'] = df_part_1_uc_b_last_time[df_part_1_uc_b_last_time['behavior_type'] == 1]['time']\n",
    "df_part_1_uc_b_last_time['uc_b2_last_time'] = df_part_1_uc_b_last_time[df_part_1_uc_b_last_time['behavior_type'] == 2]['time']\n",
    "df_part_1_uc_b_last_time['uc_b3_last_time'] = df_part_1_uc_b_last_time[df_part_1_uc_b_last_time['behavior_type'] == 3]['time']\n",
    "df_part_1_uc_b_last_time['uc_b4_last_time'] = df_part_1_uc_b_last_time[df_part_1_uc_b_last_time['behavior_type'] == 4]['time']\n",
    "\n",
    "df_part_1_uc_b_last_time.loc[df_part_1_uc_b_last_time['uc_b1_last_time'].notnull(), 'uc_b1_last_hours'] = (pd.to_datetime('2014-11-28') - df_part_1_uc_b_last_time['uc_b1_last_time'])             \n",
    "df_part_1_uc_b_last_time['uc_b1_last_hours'] = df_part_1_uc_b_last_time[df_part_1_uc_b_last_time['uc_b1_last_hours'].notnull()]['uc_b1_last_hours'].apply(lambda x: x.days*24 + x.seconds//3600)\n",
    "\n",
    "df_part_1_uc_b_last_time.loc[df_part_1_uc_b_last_time['uc_b2_last_time'].notnull(), 'uc_b2_last_hours'] = (pd.to_datetime('2014-11-28') - df_part_1_uc_b_last_time['uc_b2_last_time'])             \n",
    "df_part_1_uc_b_last_time['uc_b2_last_hours'] = df_part_1_uc_b_last_time[df_part_1_uc_b_last_time['uc_b2_last_hours'].notnull()]['uc_b2_last_hours'].apply(lambda x: x.days*24 + x.seconds//3600)\n",
    "\n",
    "df_part_1_uc_b_last_time.loc[df_part_1_uc_b_last_time['uc_b3_last_time'].notnull(), 'uc_b3_last_hours'] = (pd.to_datetime('2014-11-28') - df_part_1_uc_b_last_time['uc_b3_last_time'])             \n",
    "df_part_1_uc_b_last_time['uc_b3_last_hours'] = df_part_1_uc_b_last_time[df_part_1_uc_b_last_time['uc_b3_last_hours'].notnull()]['uc_b3_last_hours'].apply(lambda x: x.days*24 + x.seconds//3600)\n",
    "\n",
    "df_part_1_uc_b_last_time.loc[df_part_1_uc_b_last_time['uc_b4_last_time'].notnull(), 'uc_b4_last_hours'] = (pd.to_datetime('2014-11-28') - df_part_1_uc_b_last_time['uc_b4_last_time'])             \n",
    "df_part_1_uc_b_last_time['uc_b4_last_hours'] = df_part_1_uc_b_last_time[df_part_1_uc_b_last_time['uc_b4_last_hours'].notnull()]['uc_b4_last_hours'].apply(lambda x: x.days*24 + x.seconds//3600)\n",
    "\n",
    "df_part_1_uc_b_last_time = df_part_1_uc_b_last_time[['user_id',\n",
    "                                                     'item_category',\n",
    "                                                     'uc_b1_last_hours',\n",
    "                                                     'uc_b2_last_hours',\n",
    "                                                     'uc_b3_last_hours',\n",
    "                                                     'uc_b4_last_hours']] \n",
    "\n",
    "df_part_1_uc_b_last_time = df_part_1_uc_b_last_time.groupby(['user_id', 'item_category']).agg({'uc_b1_last_hours': np.sum,\n",
    "                                                                                               'uc_b2_last_hours': np.sum,\n",
    "                                                                                               'uc_b3_last_hours': np.sum,\n",
    "                                                                                               'uc_b4_last_hours': np.sum})\n",
    "df_part_1_uc_b_last_time.reset_index(inplace = True)\n",
    "\n",
    "# merge for generation of f_UC_part_1\n",
    "f_UC_part_1 = pd.merge(df_part_1_uc_b_count, df_part_1_uc_b_last_time, how='left', on=['user_id', 'item_category'])\n",
    "\n",
    "# write to csv file\n",
    "f_UC_part_1.to_csv(path_df_part_1_UC, index = False)\n",
    "\n",
    "\n",
    "print(' part1 done ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
