{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1978c67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "this file for data_set_part_2\n",
    "\n",
    "    part 1 - train: 11.22~11.27 > 11.28;\n",
    "    part 2 - train: 11.29~12.04 > 12.05;\n",
    "    part 3 - test: 12.13~12.18 (> 12.19);\n",
    "    \n",
    "'''\n",
    "\n",
    "##### file path\n",
    "# input \n",
    "path_df_D = \"/Users/DanDan/Desktop/第一课/code/fresh_comp_offline/tianchi_fresh_comp_train_user.csv\"\n",
    "\n",
    "path_df_part_1 = \"/Users/DanDan/Desktop/第一课/code/fresh_comp_offline/df_part_1.csv\"\n",
    "path_df_part_2 = \"/Users/DanDan/Desktop/第一课/code/fresh_comp_offline/df_part_2.csv\"\n",
    "path_df_part_3 = \"/Users/DanDan/Desktop/第一课/code/fresh_comp_offline/df_part_3.csv\"\n",
    "\n",
    "path_df_part_1_tar = \"/Users/DanDan/Desktop/第一课/code/fresh_comp_offline/df_part_1_tar.csv\"\n",
    "path_df_part_2_tar = \"/Users/DanDan/Desktop/第一课/code/fresh_comp_offline/df_part_2_tar.csv\"\n",
    "\n",
    "path_df_part_1_uic_label = \"/Users/DanDan/Desktop/第一课/code/fresh_comp_offline/df_part_1_uic_label.csv\"\n",
    "path_df_part_2_uic_label = \"/Users/DanDan/Desktop/第一课/code/fresh_comp_offline/df_part_2_uic_label.csv\"\n",
    "path_df_part_3_uic       = \"/Users/DanDan/Desktop/第一课/code/fresh_comp_offline/df_part_3_uic.csv\"\n",
    "\n",
    "# output\n",
    "path_df_part_1_U   = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_1_U.csv\"  \n",
    "path_df_part_1_I   = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_1_I.csv\"\n",
    "path_df_part_1_C   = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_1_C.csv\"\n",
    "path_df_part_1_IC  = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_1_IC.csv\"\n",
    "path_df_part_1_UI  = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_1_UI.csv\"\n",
    "path_df_part_1_UC  = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_1_UC.csv\"\n",
    "\n",
    "path_df_part_2_U   = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_2_U.csv\"  \n",
    "path_df_part_2_I   = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_2_I.csv\"\n",
    "path_df_part_2_C   = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_2_C.csv\"\n",
    "path_df_part_2_IC  = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_2_IC.csv\"\n",
    "path_df_part_2_UI  = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_2_UI.csv\"\n",
    "path_df_part_2_UC  = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_2_UC.csv\"\n",
    "\n",
    "path_df_part_3_U   = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_3_U.csv\"  \n",
    "path_df_part_3_I   = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_3_I.csv\"\n",
    "path_df_part_3_C   = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_3_C.csv\"\n",
    "path_df_part_3_IC  = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_3_IC.csv\"\n",
    "path_df_part_3_UI  = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_3_UI.csv\"\n",
    "path_df_part_3_UC  = \"/Users/DanDan/Desktop/第一课/code/feature/df_part_3_UC.csv\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "452cd5ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Step 1.1 feature data set U of df_part_2\\n    (1)\\n    u_b1_count_in_6\\n    u_b2_count_in_6\\n    u_b3_count_in_6\\n    u_b4_count_in_6\\n    u_b_count_in_6\\n    (2)\\n    u_b1_count_in_3\\n    u_b2_count_in_3\\n    u_b3_count_in_3\\n    u_b4_count_in_3\\n    u_b_count_in_3\\n    (2)\\n    u_b1_count_in_1\\n    u_b2_count_in_1\\n    u_b3_count_in_1\\n    u_b4_count_in_1\\n    u_b_count_in_1\\n    (3)\\n    u_b4_rate  (in_6)\\n    u_b4_diff_hours  (in_6)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "##========================================================##\n",
    "##======================== Part 2 ========================##\n",
    "##========================================================##\n",
    "\n",
    "###########################################\n",
    "'''Step 1.1 feature data set U of df_part_2\n",
    "    (1)\n",
    "    u_b1_count_in_6\n",
    "    u_b2_count_in_6\n",
    "    u_b3_count_in_6\n",
    "    u_b4_count_in_6\n",
    "    u_b_count_in_6\n",
    "    (2)\n",
    "    u_b1_count_in_3\n",
    "    u_b2_count_in_3\n",
    "    u_b3_count_in_3\n",
    "    u_b4_count_in_3\n",
    "    u_b_count_in_3\n",
    "    (2)\n",
    "    u_b1_count_in_1\n",
    "    u_b2_count_in_1\n",
    "    u_b3_count_in_1\n",
    "    u_b4_count_in_1\n",
    "    u_b_count_in_1\n",
    "    (3)\n",
    "    u_b4_rate  (in_6)\n",
    "    u_b4_diff_hours  (in_6)\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74e3e449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "path_df = open(path_df_part_2, 'r')\n",
    "try:\n",
    "    df_part_2 = pd.read_csv(path_df, index_col = False, parse_dates = [0])\n",
    "    df_part_2.columns = ['time','user_id','item_id','behavior_type','item_category']\n",
    "finally:\n",
    "    path_df.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd9070a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15406/3935137682.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_2_u_b_count_in_6 = df_part_2.drop_duplicates(['user_id','behavior_type'], 'last')[['user_id','behavior_type','cumcount']]\n"
     ]
    }
   ],
   "source": [
    "# u_b_count_in_6\n",
    "df_part_2['cumcount'] = df_part_2.groupby(['user_id', 'behavior_type']).cumcount()\n",
    "df_part_2_u_b_count_in_6 = df_part_2.drop_duplicates(['user_id','behavior_type'], 'last')[['user_id','behavior_type','cumcount']]\n",
    "df_part_2_u_b_count_in_6 = pd.get_dummies(df_part_2_u_b_count_in_6['behavior_type']).join(df_part_2_u_b_count_in_6[['user_id','cumcount']])\n",
    "df_part_2_u_b_count_in_6.rename(columns = {1:'behavior_type_1',\n",
    "                                           2:'behavior_type_2',\n",
    "                                           3:'behavior_type_3',\n",
    "                                           4:'behavior_type_4'}, inplace=True)\n",
    "df_part_2_u_b_count_in_6['u_b1_count_in_6'] = df_part_2_u_b_count_in_6['behavior_type_1'] * (df_part_2_u_b_count_in_6['cumcount']+1)\n",
    "df_part_2_u_b_count_in_6['u_b2_count_in_6'] = df_part_2_u_b_count_in_6['behavior_type_2'] * (df_part_2_u_b_count_in_6['cumcount']+1)\n",
    "df_part_2_u_b_count_in_6['u_b3_count_in_6'] = df_part_2_u_b_count_in_6['behavior_type_3'] * (df_part_2_u_b_count_in_6['cumcount']+1)\n",
    "df_part_2_u_b_count_in_6['u_b4_count_in_6'] = df_part_2_u_b_count_in_6['behavior_type_4'] * (df_part_2_u_b_count_in_6['cumcount']+1)\n",
    "df_part_2_u_b_count_in_6 = df_part_2_u_b_count_in_6.groupby('user_id').agg({'u_b1_count_in_6': np.sum,\n",
    "                                                                            'u_b2_count_in_6': np.sum,\n",
    "                                                                            'u_b3_count_in_6': np.sum,\n",
    "                                                                            'u_b4_count_in_6': np.sum})\n",
    "df_part_2_u_b_count_in_6.reset_index(inplace = True)\n",
    "df_part_2_u_b_count_in_6['u_b_count_in_6'] = df_part_2_u_b_count_in_6[['u_b1_count_in_6',\n",
    "                                                                       'u_b2_count_in_6',\n",
    "                                                                       'u_b3_count_in_6',\n",
    "                                                                       'u_b4_count_in_6']].apply(lambda x: x.sum(), axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20f79ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15406/1583613131.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_part_2_in_3['cumcount'] = df_part_2_in_3.groupby(['user_id', 'behavior_type']).cumcount()\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15406/1583613131.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_2_u_b_count_in_3 = df_part_2.drop_duplicates(['user_id','behavior_type'], 'last')[['user_id','behavior_type','cumcount']]\n"
     ]
    }
   ],
   "source": [
    "# u_b_count_in_3\n",
    "df_part_2_in_3 = df_part_2[df_part_2['time'] >= np.datetime64('2014-12-02')]\n",
    "df_part_2_in_3['cumcount'] = df_part_2_in_3.groupby(['user_id', 'behavior_type']).cumcount()\n",
    "df_part_2_u_b_count_in_3 = df_part_2.drop_duplicates(['user_id','behavior_type'], 'last')[['user_id','behavior_type','cumcount']]\n",
    "df_part_2_u_b_count_in_3 = pd.get_dummies(df_part_2_u_b_count_in_3['behavior_type']).join(df_part_2_u_b_count_in_3[['user_id','cumcount']])\n",
    "df_part_2_u_b_count_in_3.rename(columns = {1:'behavior_type_1',\n",
    "                                           2:'behavior_type_2',\n",
    "                                           3:'behavior_type_3',\n",
    "                                           4:'behavior_type_4'}, inplace=True)\n",
    "df_part_2_u_b_count_in_3['u_b1_count_in_3'] = df_part_2_u_b_count_in_3['behavior_type_1'] * (df_part_2_u_b_count_in_3['cumcount']+1)\n",
    "df_part_2_u_b_count_in_3['u_b2_count_in_3'] = df_part_2_u_b_count_in_3['behavior_type_2'] * (df_part_2_u_b_count_in_3['cumcount']+1)\n",
    "df_part_2_u_b_count_in_3['u_b3_count_in_3'] = df_part_2_u_b_count_in_3['behavior_type_3'] * (df_part_2_u_b_count_in_3['cumcount']+1)\n",
    "df_part_2_u_b_count_in_3['u_b4_count_in_3'] = df_part_2_u_b_count_in_3['behavior_type_4'] * (df_part_2_u_b_count_in_3['cumcount']+1)\n",
    "df_part_2_u_b_count_in_3 = df_part_2_u_b_count_in_3.groupby('user_id').agg({'u_b1_count_in_3': np.sum,\n",
    "                                                                            'u_b2_count_in_3': np.sum,\n",
    "                                                                            'u_b3_count_in_3': np.sum,\n",
    "                                                                            'u_b4_count_in_3': np.sum})\n",
    "df_part_2_u_b_count_in_3.reset_index(inplace = True)\n",
    "df_part_2_u_b_count_in_3['u_b_count_in_3'] = df_part_2_u_b_count_in_3[['u_b1_count_in_3',\n",
    "                                                                       'u_b2_count_in_3',\n",
    "                                                                       'u_b3_count_in_3',\n",
    "                                                                       'u_b4_count_in_3']].apply(lambda x: x.sum(), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe3aa141",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15406/4178538308.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_part_2_in_1['cumcount'] = df_part_2_in_1.groupby(['user_id', 'behavior_type']).cumcount()\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15406/4178538308.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_2_u_b_count_in_1 = df_part_2_in_1.drop_duplicates(['user_id','behavior_type'], 'last')[['user_id','behavior_type','cumcount']]\n"
     ]
    }
   ],
   "source": [
    "# u_b_count_in_1\n",
    "df_part_2_in_1 = df_part_2[df_part_2['time'] >= np.datetime64('2014-12-04')]\n",
    "df_part_2_in_1['cumcount'] = df_part_2_in_1.groupby(['user_id', 'behavior_type']).cumcount()\n",
    "df_part_2_u_b_count_in_1 = df_part_2_in_1.drop_duplicates(['user_id','behavior_type'], 'last')[['user_id','behavior_type','cumcount']]\n",
    "df_part_2_u_b_count_in_1 = pd.get_dummies(df_part_2_u_b_count_in_1['behavior_type']).join(df_part_2_u_b_count_in_1[['user_id','cumcount']])\n",
    "df_part_2_u_b_count_in_1.rename(columns = {1:'behavior_type_1',\n",
    "                                           2:'behavior_type_2',\n",
    "                                           3:'behavior_type_3',\n",
    "                                           4:'behavior_type_4'}, inplace=True)\n",
    "df_part_2_u_b_count_in_1['u_b1_count_in_1'] = df_part_2_u_b_count_in_1['behavior_type_1'] * (df_part_2_u_b_count_in_1['cumcount']+1)\n",
    "df_part_2_u_b_count_in_1['u_b2_count_in_1'] = df_part_2_u_b_count_in_1['behavior_type_2'] * (df_part_2_u_b_count_in_1['cumcount']+1)\n",
    "df_part_2_u_b_count_in_1['u_b3_count_in_1'] = df_part_2_u_b_count_in_1['behavior_type_3'] * (df_part_2_u_b_count_in_1['cumcount']+1)\n",
    "df_part_2_u_b_count_in_1['u_b4_count_in_1'] = df_part_2_u_b_count_in_1['behavior_type_4'] * (df_part_2_u_b_count_in_1['cumcount']+1)\n",
    "df_part_2_u_b_count_in_1 = df_part_2_u_b_count_in_1.groupby('user_id').agg({'u_b1_count_in_1': np.sum,\n",
    "                                                                            'u_b2_count_in_1': np.sum,\n",
    "                                                                            'u_b3_count_in_1': np.sum,\n",
    "                                                                            'u_b4_count_in_1': np.sum})\n",
    "df_part_2_u_b_count_in_1.reset_index(inplace = True)\n",
    "df_part_2_u_b_count_in_1['u_b_count_in_1']  = df_part_2_u_b_count_in_1[['u_b1_count_in_1',\n",
    "                                                                        'u_b2_count_in_1',\n",
    "                                                                        'u_b3_count_in_1',\n",
    "                                                                        'u_b4_count_in_1']].apply(lambda x: x.sum(), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9f28da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the result of count_in_6, count_in_3, count_in_1\n",
    "\n",
    "df_part_2_u_b_count = pd.merge(df_part_2_u_b_count_in_6, \n",
    "                               df_part_2_u_b_count_in_3, on = ['user_id'], how = 'left').fillna(0)\n",
    "df_part_2_u_b_count = pd.merge(df_part_2_u_b_count, \n",
    "                               df_part_2_u_b_count_in_1, on = ['user_id'], how = 'left').fillna(0)\n",
    "                                    \n",
    "df_part_2_u_b_count[['u_b1_count_in_6',\n",
    "                     'u_b2_count_in_6',\n",
    "                     'u_b3_count_in_6',\n",
    "                     'u_b4_count_in_6',\n",
    "                      'u_b_count_in_6',\n",
    "                     'u_b1_count_in_3',\n",
    "                     'u_b2_count_in_3',\n",
    "                     'u_b3_count_in_3',\n",
    "                     'u_b4_count_in_3',\n",
    "                      'u_b_count_in_3',\n",
    "                     'u_b1_count_in_1',\n",
    "                     'u_b2_count_in_1',\n",
    "                     'u_b3_count_in_1',\n",
    "                     'u_b4_count_in_1',\n",
    "                      'u_b_count_in_1']] = df_part_2_u_b_count[['u_b1_count_in_6',\n",
    "                                                                'u_b2_count_in_6',\n",
    "                                                                'u_b3_count_in_6',\n",
    "                                                                'u_b4_count_in_6',\n",
    "                                                                 'u_b_count_in_6',\n",
    "                                                                'u_b1_count_in_3',\n",
    "                                                                'u_b2_count_in_3',\n",
    "                                                                'u_b3_count_in_3',\n",
    "                                                                'u_b4_count_in_3',\n",
    "                                                                 'u_b_count_in_3',\n",
    "                                                                'u_b1_count_in_1',\n",
    "                                                                'u_b2_count_in_1',\n",
    "                                                                'u_b3_count_in_1',\n",
    "                                                                'u_b4_count_in_1',\n",
    "                                                                 'u_b_count_in_1']].astype(int)\n",
    "                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63382d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15406/2963754705.py:6: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_2_u_b4_time = df_part_2[df_part_2['behavior_type'] == 4].drop_duplicates(['user_id'],'first')[['user_id','time']]\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15406/2963754705.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_2_u_b_time = df_part_2.drop_duplicates(['user_id'],'first')[['user_id','time']]\n"
     ]
    }
   ],
   "source": [
    "# u_b4_rate\n",
    "df_part_2_u_b_count['u_b4_rate'] = df_part_2_u_b_count['u_b4_count_in_6'] / df_part_2_u_b_count['u_b_count_in_6']\n",
    "\n",
    "# u_b4_diff_time\n",
    "df_part_2 = df_part_2.sort_values(by = ['user_id', 'time'])\n",
    "df_part_2_u_b4_time = df_part_2[df_part_2['behavior_type'] == 4].drop_duplicates(['user_id'],'first')[['user_id','time']]\n",
    "df_part_2_u_b4_time.columns = ['user_id','b4_first_time']\n",
    "df_part_2_u_b_time = df_part_2.drop_duplicates(['user_id'],'first')[['user_id','time']]\n",
    "df_part_2_u_b_time.columns = ['user_id','b_first_time']\n",
    "df_part_2_u_b_b4_time = pd.merge(df_part_2_u_b_time, df_part_2_u_b4_time, on = ['user_id'])\n",
    "df_part_2_u_b_b4_time['u_b4_diff_time'] = df_part_2_u_b_b4_time['b4_first_time'] - df_part_2_u_b_b4_time['b_first_time']\n",
    "df_part_2_u_b_b4_time = df_part_2_u_b_b4_time[['user_id', 'u_b4_diff_time']]\n",
    "df_part_2_u_b_b4_time['u_b4_diff_hours'] = df_part_2_u_b_b4_time['u_b4_diff_time'].apply(lambda x: x.days * 24 + x.seconds//3600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86fc34b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating feature set U\n",
    "f_U_part_2 = pd.merge(df_part_2_u_b_count, \n",
    "                      df_part_2_u_b_b4_time, \n",
    "                      on = ['user_id'], how = 'left')[['user_id',\n",
    "                                                       'u_b1_count_in_6', \n",
    "                                                       'u_b2_count_in_6', \n",
    "                                                       'u_b3_count_in_6', \n",
    "                                                       'u_b4_count_in_6', \n",
    "                                                       'u_b_count_in_6',\n",
    "                                                       'u_b1_count_in_3',\n",
    "                                                       'u_b2_count_in_3', \n",
    "                                                       'u_b3_count_in_3',\n",
    "                                                       'u_b4_count_in_3', \n",
    "                                                       'u_b_count_in_3',\n",
    "                                                       'u_b1_count_in_1',\n",
    "                                                       'u_b2_count_in_1', \n",
    "                                                       'u_b3_count_in_1',\n",
    "                                                       'u_b4_count_in_1', \n",
    "                                                       'u_b_count_in_1', \n",
    "                                                       'u_b4_rate', \n",
    "                                                       'u_b4_diff_hours']]\n",
    "                      \n",
    "# write to csv file\n",
    "f_U_part_2 = f_U_part_2.round({'u_b4_rate': 3})\n",
    "f_U_part_2.to_csv(path_df_part_2_U, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7d8d252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Step 1.2 feature data set I of df_part_2\\n    (1)\\n    i_u_count_in_6\\n    i_u_count_in_3\\n    i_u_count_in_1\\n    (2)\\n    i_b1_count_in_6\\n    i_b2_count_in_6\\n    i_b3_count_in_6\\n    i_b4_count_in_6\\n     i_b_count_in_6\\n    i_b1_count_in_3\\n    i_b2_count_in_3\\n    i_b3_count_in_3\\n    i_b4_count_in_3\\n     i_b_count_in_3\\n    i_b1_count_in_1\\n    i_b2_count_in_1\\n    i_b3_count_in_1\\n    i_b4_count_in_1\\n     i_b_count_in_1\\n    (3)\\n    i_b4_rate  (in_6)\\n    i_b4_diff_hours  (in_6)\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###########################################\n",
    "'''Step 1.2 feature data set I of df_part_2\n",
    "    (1)\n",
    "    i_u_count_in_6\n",
    "    i_u_count_in_3\n",
    "    i_u_count_in_1\n",
    "    (2)\n",
    "    i_b1_count_in_6\n",
    "    i_b2_count_in_6\n",
    "    i_b3_count_in_6\n",
    "    i_b4_count_in_6\n",
    "     i_b_count_in_6\n",
    "    i_b1_count_in_3\n",
    "    i_b2_count_in_3\n",
    "    i_b3_count_in_3\n",
    "    i_b4_count_in_3\n",
    "     i_b_count_in_3\n",
    "    i_b1_count_in_1\n",
    "    i_b2_count_in_1\n",
    "    i_b3_count_in_1\n",
    "    i_b4_count_in_1\n",
    "     i_b_count_in_1\n",
    "    (3)\n",
    "    i_b4_rate  (in_6)\n",
    "    i_b4_diff_hours  (in_6)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6cd0b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "path_df = open(path_df_part_2, 'r')\n",
    "try:\n",
    "    df_part_2 = pd.read_csv(path_df, index_col = False, parse_dates = [0])\n",
    "    df_part_2.columns = ['time','user_id','item_id','behavior_type','item_category']\n",
    "finally:\n",
    "    path_df.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "beee9f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15406/783143894.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_part_2_in_6['i_u_count_in_6'] = df_part_2_in_6.groupby('item_id').cumcount() + 1\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15406/783143894.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_2_i_u_count_in_6 = df_part_2_in_6.drop_duplicates(['item_id'], 'last')[['item_id', 'i_u_count_in_6']]\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15406/783143894.py:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_2_i_u_count_in_3 = df_part_2_in_3.drop_duplicates(['item_id'], 'last')[['item_id', 'i_u_count_in_3']]\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15406/783143894.py:14: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_2_i_u_count_in_1 = df_part_2_in_1.drop_duplicates(['item_id'], 'last')[['item_id', 'i_u_count_in_1']]\n"
     ]
    }
   ],
   "source": [
    "# i_u_count_in_6\n",
    "df_part_2_in_6 = df_part_2.drop_duplicates(['item_id', 'user_id'])\n",
    "df_part_2_in_6['i_u_count_in_6'] = df_part_2_in_6.groupby('item_id').cumcount() + 1\n",
    "df_part_2_i_u_count_in_6 = df_part_2_in_6.drop_duplicates(['item_id'], 'last')[['item_id', 'i_u_count_in_6']]\n",
    "\n",
    "# i_u_count_in_3\n",
    "df_part_2_in_3 = df_part_2[df_part_2['time'] >= np.datetime64('2014-12-02')].drop_duplicates(['item_id', 'user_id'])\n",
    "df_part_2_in_3['i_u_count_in_3'] = df_part_2_in_3.groupby('item_id').cumcount() + 1\n",
    "df_part_2_i_u_count_in_3 = df_part_2_in_3.drop_duplicates(['item_id'], 'last')[['item_id', 'i_u_count_in_3']]\n",
    "\n",
    "# i_u_count_in_1\n",
    "df_part_2_in_1 = df_part_2[df_part_2['time'] >= np.datetime64('2014-12-04')].drop_duplicates(['item_id', 'user_id'])\n",
    "df_part_2_in_1['i_u_count_in_1'] = df_part_2_in_1.groupby('item_id').cumcount() + 1\n",
    "df_part_2_i_u_count_in_1 = df_part_2_in_1.drop_duplicates(['item_id'], 'last')[['item_id', 'i_u_count_in_1']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94701e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge for generation of i_u_count\n",
    "df_part_2_i_u_count = pd.merge(df_part_2_i_u_count_in_6, \n",
    "                               df_part_2_i_u_count_in_3,\n",
    "                               on=['item_id'],how='left').fillna(0)\n",
    "df_part_2_i_u_count = pd.merge(df_part_2_i_u_count, \n",
    "                               df_part_2_i_u_count_in_1,\n",
    "                               on=['item_id'],how='left').fillna(0)\n",
    "df_part_2_i_u_count[['i_u_count_in_6',\n",
    "                     'i_u_count_in_3',\n",
    "                     'i_u_count_in_1']] = df_part_2_i_u_count[['i_u_count_in_6',\n",
    "                                                               'i_u_count_in_3',\n",
    "                                                               'i_u_count_in_1']].astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d190493b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15406/1407780206.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_2_i_b_count_in_6 = df_part_2.drop_duplicates(['item_id','behavior_type'], 'last')[['item_id','behavior_type','cumcount']]\n"
     ]
    }
   ],
   "source": [
    "# i_b_count_in_6\n",
    "df_part_2['cumcount'] = df_part_2.groupby(['item_id', 'behavior_type']).cumcount()\n",
    "df_part_2_i_b_count_in_6 = df_part_2.drop_duplicates(['item_id','behavior_type'], 'last')[['item_id','behavior_type','cumcount']]\n",
    "df_part_2_i_b_count_in_6 = pd.get_dummies(df_part_2_i_b_count_in_6['behavior_type']).join(df_part_2_i_b_count_in_6[['item_id','cumcount']])\n",
    "df_part_2_i_b_count_in_6.rename(columns = {1:'behavior_type_1',\n",
    "                                           2:'behavior_type_2',\n",
    "                                           3:'behavior_type_3',\n",
    "                                           4:'behavior_type_4'}, inplace=True)\n",
    "df_part_2_i_b_count_in_6['i_b1_count_in_6'] = df_part_2_i_b_count_in_6['behavior_type_1'] * (df_part_2_i_b_count_in_6['cumcount']+1)\n",
    "df_part_2_i_b_count_in_6['i_b2_count_in_6'] = df_part_2_i_b_count_in_6['behavior_type_2'] * (df_part_2_i_b_count_in_6['cumcount']+1)\n",
    "df_part_2_i_b_count_in_6['i_b3_count_in_6'] = df_part_2_i_b_count_in_6['behavior_type_3'] * (df_part_2_i_b_count_in_6['cumcount']+1)\n",
    "df_part_2_i_b_count_in_6['i_b4_count_in_6'] = df_part_2_i_b_count_in_6['behavior_type_4'] * (df_part_2_i_b_count_in_6['cumcount']+1)\n",
    "df_part_2_i_b_count_in_6 = df_part_2_i_b_count_in_6[['item_id', \n",
    "                                                     'i_b1_count_in_6', \n",
    "                                                     'i_b2_count_in_6', \n",
    "                                                     'i_b3_count_in_6',\n",
    "                                                     'i_b4_count_in_6']]\n",
    "df_part_2_i_b_count_in_6 = df_part_2_i_b_count_in_6.groupby('item_id').agg({'i_b1_count_in_6': np.sum,\n",
    "                                                                            'i_b2_count_in_6': np.sum,\n",
    "                                                                            'i_b3_count_in_6': np.sum,\n",
    "                                                                            'i_b4_count_in_6': np.sum})\n",
    "df_part_2_i_b_count_in_6.reset_index(inplace = True)\n",
    "df_part_2_i_b_count_in_6['i_b_count_in_6'] = df_part_2_i_b_count_in_6['i_b1_count_in_6'] + \\\n",
    "                                             df_part_2_i_b_count_in_6['i_b2_count_in_6'] + \\\n",
    "                                             df_part_2_i_b_count_in_6['i_b3_count_in_6'] + \\\n",
    "                                             df_part_2_i_b_count_in_6['i_b4_count_in_6']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e99b7f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15406/445181245.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_part_2_in_3['cumcount'] = df_part_2_in_3.groupby(['item_id', 'behavior_type']).cumcount()\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15406/445181245.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_2_i_b_count_in_3 = df_part_2.drop_duplicates(['item_id','behavior_type'], 'last')[['item_id','behavior_type','cumcount']]\n"
     ]
    }
   ],
   "source": [
    "# i_b_count_in_3\n",
    "df_part_2_in_3 = df_part_2[df_part_2['time'] >= np.datetime64('2014-12-02')]\n",
    "df_part_2_in_3['cumcount'] = df_part_2_in_3.groupby(['item_id', 'behavior_type']).cumcount()\n",
    "df_part_2_i_b_count_in_3 = df_part_2.drop_duplicates(['item_id','behavior_type'], 'last')[['item_id','behavior_type','cumcount']]\n",
    "df_part_2_i_b_count_in_3 = pd.get_dummies(df_part_2_i_b_count_in_3['behavior_type']).join(df_part_2_i_b_count_in_3[['item_id','cumcount']])\n",
    "df_part_2_i_b_count_in_3.rename(columns = {1:'behavior_type_1',\n",
    "                                           2:'behavior_type_2',\n",
    "                                           3:'behavior_type_3',\n",
    "                                           4:'behavior_type_4'}, inplace=True)\n",
    "df_part_2_i_b_count_in_3['i_b1_count_in_3'] = df_part_2_i_b_count_in_3['behavior_type_1'] * (df_part_2_i_b_count_in_3['cumcount']+1)\n",
    "df_part_2_i_b_count_in_3['i_b2_count_in_3'] = df_part_2_i_b_count_in_3['behavior_type_2'] * (df_part_2_i_b_count_in_3['cumcount']+1)\n",
    "df_part_2_i_b_count_in_3['i_b3_count_in_3'] = df_part_2_i_b_count_in_3['behavior_type_3'] * (df_part_2_i_b_count_in_3['cumcount']+1)\n",
    "df_part_2_i_b_count_in_3['i_b4_count_in_3'] = df_part_2_i_b_count_in_3['behavior_type_4'] * (df_part_2_i_b_count_in_3['cumcount']+1)\n",
    "df_part_2_i_b_count_in_3 = df_part_2_i_b_count_in_3[['item_id', \n",
    "                                                     'i_b1_count_in_3', \n",
    "                                                     'i_b2_count_in_3', \n",
    "                                                     'i_b3_count_in_3',\n",
    "                                                     'i_b4_count_in_3']]\n",
    "df_part_2_i_b_count_in_3 = df_part_2_i_b_count_in_3.groupby('item_id').agg({'i_b1_count_in_3': np.sum,\n",
    "                                                                            'i_b2_count_in_3': np.sum,\n",
    "                                                                            'i_b3_count_in_3': np.sum,\n",
    "                                                                            'i_b4_count_in_3': np.sum})\n",
    "df_part_2_i_b_count_in_3.reset_index(inplace = True)\n",
    "df_part_2_i_b_count_in_3['i_b_count_in_3'] = df_part_2_i_b_count_in_3['i_b1_count_in_3'] + \\\n",
    "                                             df_part_2_i_b_count_in_3['i_b2_count_in_3'] + \\\n",
    "                                             df_part_2_i_b_count_in_3['i_b3_count_in_3'] + \\\n",
    "                                             df_part_2_i_b_count_in_3['i_b4_count_in_3']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc7b11fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15406/1871931535.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_part_2_in_1['cumcount'] = df_part_2_in_1.groupby(['item_id', 'behavior_type']).cumcount()\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15406/1871931535.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_2_i_b_count_in_1 = df_part_2_in_1.drop_duplicates(['item_id','behavior_type'], 'last')[['item_id','behavior_type','cumcount']]\n"
     ]
    }
   ],
   "source": [
    "# i_b_count_in_1\n",
    "df_part_2_in_1 = df_part_2[df_part_2['time'] >= np.datetime64('2014-12-04')]\n",
    "df_part_2_in_1['cumcount'] = df_part_2_in_1.groupby(['item_id', 'behavior_type']).cumcount()\n",
    "df_part_2_i_b_count_in_1 = df_part_2_in_1.drop_duplicates(['item_id','behavior_type'], 'last')[['item_id','behavior_type','cumcount']]\n",
    "df_part_2_i_b_count_in_1 = pd.get_dummies(df_part_2_i_b_count_in_1['behavior_type']).join(df_part_2_i_b_count_in_1[['item_id','cumcount']])\n",
    "df_part_2_i_b_count_in_1.rename(columns = {1:'behavior_type_1',\n",
    "                                           2:'behavior_type_2',\n",
    "                                           3:'behavior_type_3',\n",
    "                                           4:'behavior_type_4'}, inplace=True)                     \n",
    "df_part_2_i_b_count_in_1['i_b1_count_in_1'] = df_part_2_i_b_count_in_1['behavior_type_1'] * (df_part_2_i_b_count_in_1['cumcount']+1)\n",
    "df_part_2_i_b_count_in_1['i_b2_count_in_1'] = df_part_2_i_b_count_in_1['behavior_type_2'] * (df_part_2_i_b_count_in_1['cumcount']+1)\n",
    "df_part_2_i_b_count_in_1['i_b3_count_in_1'] = df_part_2_i_b_count_in_1['behavior_type_3'] * (df_part_2_i_b_count_in_1['cumcount']+1)\n",
    "df_part_2_i_b_count_in_1['i_b4_count_in_1'] = df_part_2_i_b_count_in_1['behavior_type_4'] * (df_part_2_i_b_count_in_1['cumcount']+1)\n",
    "df_part_2_i_b_count_in_1 = df_part_2_i_b_count_in_1[['item_id', \n",
    "                                                     'i_b1_count_in_1', \n",
    "                                                     'i_b2_count_in_1', \n",
    "                                                     'i_b3_count_in_1',\n",
    "                                                     'i_b4_count_in_1']]\n",
    "df_part_2_i_b_count_in_1 = df_part_2_i_b_count_in_1.groupby('item_id').agg({'i_b1_count_in_1': np.sum,\n",
    "                                                                            'i_b2_count_in_1': np.sum,\n",
    "                                                                            'i_b3_count_in_1': np.sum,\n",
    "                                                                            'i_b4_count_in_1': np.sum})\n",
    "df_part_2_i_b_count_in_1.reset_index(inplace = True)\n",
    "df_part_2_i_b_count_in_1['i_b_count_in_1'] = df_part_2_i_b_count_in_1['i_b1_count_in_1'] + \\\n",
    "                                             df_part_2_i_b_count_in_1['i_b2_count_in_1'] + \\\n",
    "                                             df_part_2_i_b_count_in_1['i_b3_count_in_1'] + \\\n",
    "                                             df_part_2_i_b_count_in_1['i_b4_count_in_1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56fa968d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge for generation of i_b_count\n",
    "df_part_2_i_b_count = pd.merge(df_part_2_i_b_count_in_6, \n",
    "                               df_part_2_i_b_count_in_3, \n",
    "                               on = ['item_id'], how = 'left').fillna(0)\n",
    "df_part_2_i_b_count = pd.merge(df_part_2_i_b_count, \n",
    "                               df_part_2_i_b_count_in_1, \n",
    "                               on = ['item_id'], how = 'left').fillna(0)\n",
    "df_part_2_i_b_count[['i_b1_count_in_6',\n",
    "                     'i_b2_count_in_6',\n",
    "                     'i_b3_count_in_6',\n",
    "                     'i_b4_count_in_6',\n",
    "                      'i_b_count_in_6',\n",
    "                     'i_b1_count_in_3',\n",
    "                     'i_b2_count_in_3',\n",
    "                     'i_b3_count_in_3',\n",
    "                     'i_b4_count_in_3',\n",
    "                      'i_b_count_in_3',\n",
    "                     'i_b1_count_in_1',\n",
    "                     'i_b2_count_in_1',\n",
    "                     'i_b3_count_in_1',\n",
    "                     'i_b4_count_in_1',\n",
    "                      'i_b_count_in_1']] = df_part_2_i_b_count[['i_b1_count_in_6',\n",
    "                                                                'i_b2_count_in_6',\n",
    "                                                                'i_b3_count_in_6',\n",
    "                                                                'i_b4_count_in_6',\n",
    "                                                                 'i_b_count_in_6',\n",
    "                                                                'i_b1_count_in_3',\n",
    "                                                                'i_b2_count_in_3',\n",
    "                                                                'i_b3_count_in_3',\n",
    "                                                                'i_b4_count_in_3',\n",
    "                                                                 'i_b_count_in_3',\n",
    "                                                                'i_b1_count_in_1',\n",
    "                                                                'i_b2_count_in_1',\n",
    "                                                                'i_b3_count_in_1',\n",
    "                                                                'i_b4_count_in_1',\n",
    "                                                                 'i_b_count_in_1']].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f21d489",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15406/2350423154.py:6: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_2_i_b4_time = df_part_2[df_part_2['behavior_type'] == 4].drop_duplicates(['item_id'], 'first')[['item_id','time']]\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15406/2350423154.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_2_i_b_time = df_part_2.drop_duplicates(['item_id'], 'first')[['item_id','time']]\n"
     ]
    }
   ],
   "source": [
    "# i_b4_rate\n",
    "df_part_2_i_b_count['i_b4_rate'] = df_part_2_i_b_count['i_b4_count_in_6'] / df_part_2_i_b_count['i_b_count_in_6']\n",
    "\n",
    "# i_b4_diff_time\n",
    "df_part_2 = df_part_2.sort_values(by=['item_id', 'time'])\n",
    "df_part_2_i_b4_time = df_part_2[df_part_2['behavior_type'] == 4].drop_duplicates(['item_id'], 'first')[['item_id','time']]\n",
    "df_part_2_i_b4_time.columns = ['item_id','b4_first_time']\n",
    "df_part_2_i_b_time = df_part_2.drop_duplicates(['item_id'], 'first')[['item_id','time']]\n",
    "df_part_2_i_b_time.columns = ['item_id','b_first_time']\n",
    "df_part_2_i_b_b4_time = pd.merge(df_part_2_i_b_time, df_part_2_i_b4_time, on = ['item_id'])\n",
    "df_part_2_i_b_b4_time['i_b4_diff_time']  = df_part_2_i_b_b4_time['b4_first_time'] - df_part_2_i_b_b4_time['b_first_time']\n",
    "df_part_2_i_b_b4_time['i_b4_diff_hours'] = df_part_2_i_b_b4_time['i_b4_diff_time'].apply(lambda x: x.days * 24 + x.seconds//3600)\n",
    "df_part_2_i_b_b4_time = df_part_2_i_b_b4_time[['item_id', 'i_b4_diff_hours']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94b86c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating feature set I\n",
    "f_I_part_2 = pd.merge(df_part_2_i_b_count, \n",
    "                      df_part_2_i_b_b4_time, \n",
    "                      on = ['item_id'], how = 'left')\n",
    "f_I_part_2 = pd.merge(f_I_part_2, \n",
    "                      df_part_2_i_u_count, \n",
    "                      on = ['item_id'], how = 'left')[['item_id', \n",
    "                                                       'i_u_count_in_6', \n",
    "                                                       'i_u_count_in_3', \n",
    "                                                       'i_u_count_in_1',\n",
    "                                                       'i_b1_count_in_6', \n",
    "                                                       'i_b2_count_in_6', \n",
    "                                                       'i_b3_count_in_6', \n",
    "                                                       'i_b4_count_in_6', \n",
    "                                                       'i_b_count_in_6', \n",
    "                                                       'i_b1_count_in_3',\n",
    "                                                       'i_b2_count_in_3',\n",
    "                                                       'i_b3_count_in_3',\n",
    "                                                       'i_b4_count_in_3',\n",
    "                                                       'i_b_count_in_3',\n",
    "                                                       'i_b1_count_in_1', \n",
    "                                                       'i_b2_count_in_1', \n",
    "                                                       'i_b3_count_in_1', \n",
    "                                                       'i_b4_count_in_1', \n",
    "                                                       'i_b_count_in_1',\n",
    "                                                       'i_b4_rate', \n",
    "                                                       'i_b4_diff_hours']]\n",
    "                      \n",
    "# write to csv file\n",
    "f_I_part_2 = f_I_part_2.round({'i_b4_rate': 3})\n",
    "f_I_part_2.to_csv(path_df_part_2_I, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aea5fb4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Step 1.3 feature data set C of df_part_2\\n    (1)\\n    c_u_count_in_6\\n    c_u_count_in_3\\n    c_u_count_in_1\\n    (2)\\n    c_b1_count_in_6\\n    c_b2_count_in_6\\n    c_b3_count_in_6\\n    c_b4_count_in_6\\n     c_b_count_in_6\\n    c_b1_count_in_3\\n    c_b2_count_in_3\\n    c_b3_count_in_3\\n    c_b4_count_in_3\\n     c_b_count_in_3\\n    c_b1_count_in_1\\n    c_b2_count_in_1\\n    c_b3_count_in_1\\n    c_b4_count_in_1\\n     c_b_count_in_1\\n    (3)\\n    c_b4_rate  (in_6)\\n    c_b4_diff_hours  (in_6)\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###########################################\n",
    "'''Step 1.3 feature data set C of df_part_2\n",
    "    (1)\n",
    "    c_u_count_in_6\n",
    "    c_u_count_in_3\n",
    "    c_u_count_in_1\n",
    "    (2)\n",
    "    c_b1_count_in_6\n",
    "    c_b2_count_in_6\n",
    "    c_b3_count_in_6\n",
    "    c_b4_count_in_6\n",
    "     c_b_count_in_6\n",
    "    c_b1_count_in_3\n",
    "    c_b2_count_in_3\n",
    "    c_b3_count_in_3\n",
    "    c_b4_count_in_3\n",
    "     c_b_count_in_3\n",
    "    c_b1_count_in_1\n",
    "    c_b2_count_in_1\n",
    "    c_b3_count_in_1\n",
    "    c_b4_count_in_1\n",
    "     c_b_count_in_1\n",
    "    (3)\n",
    "    c_b4_rate  (in_6)\n",
    "    c_b4_diff_hours  (in_6)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17574e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "path_df = open(path_df_part_2, 'r')\n",
    "try:\n",
    "    df_part_2 = pd.read_csv(path_df, index_col = False, parse_dates = [0])\n",
    "    df_part_2.columns = ['time','user_id','item_id','behavior_type','item_category']\n",
    "finally:\n",
    "    path_df.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e61c958",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15406/3539149622.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_part_2_in_6['c_u_count_in_6'] = df_part_2_in_6.groupby('item_category').cumcount() + 1\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15406/3539149622.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_2_c_u_count_in_6 = df_part_2_in_6.drop_duplicates(['item_category'], 'last')[['item_category', 'c_u_count_in_6']]\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15406/3539149622.py:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_2_c_u_count_in_3 = df_part_2_in_3.drop_duplicates(['item_category'], 'last')[['item_category', 'c_u_count_in_3']]\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15406/3539149622.py:14: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_2_c_u_count_in_1 = df_part_2_in_1.drop_duplicates(['item_category'], 'last')[['item_category', 'c_u_count_in_1']]\n"
     ]
    }
   ],
   "source": [
    "# c_u_count_in_6\n",
    "df_part_2_in_6 = df_part_2.drop_duplicates(['item_category', 'user_id'])\n",
    "df_part_2_in_6['c_u_count_in_6'] = df_part_2_in_6.groupby('item_category').cumcount() + 1\n",
    "df_part_2_c_u_count_in_6 = df_part_2_in_6.drop_duplicates(['item_category'], 'last')[['item_category', 'c_u_count_in_6']]\n",
    "\n",
    "# c_u_count_in_3\n",
    "df_part_2_in_3 = df_part_2[df_part_2['time'] >= np.datetime64('2014-12-02')].drop_duplicates(['item_category', 'user_id'])\n",
    "df_part_2_in_3['c_u_count_in_3'] = df_part_2_in_3.groupby('item_category').cumcount() + 1\n",
    "df_part_2_c_u_count_in_3 = df_part_2_in_3.drop_duplicates(['item_category'], 'last')[['item_category', 'c_u_count_in_3']]\n",
    "\n",
    "# c_u_count_in_1\n",
    "df_part_2_in_1 = df_part_2[df_part_2['time'] >= np.datetime64('2014-12-04')].drop_duplicates(['item_category', 'user_id'])\n",
    "df_part_2_in_1['c_u_count_in_1'] = df_part_2_in_1.groupby('item_category').cumcount() + 1\n",
    "df_part_2_c_u_count_in_1 = df_part_2_in_1.drop_duplicates(['item_category'], 'last')[['item_category', 'c_u_count_in_1']]\n",
    "\n",
    "df_part_2_c_u_count = pd.merge(df_part_2_c_u_count_in_6, df_part_2_c_u_count_in_3,on=['item_category'],how='left').fillna(0)\n",
    "df_part_2_c_u_count = pd.merge(df_part_2_c_u_count, df_part_2_c_u_count_in_1,on=['item_category'],how='left').fillna(0)\n",
    "df_part_2_c_u_count[['c_u_count_in_6',\n",
    "                     'c_u_count_in_3',\n",
    "                     'c_u_count_in_1']] = df_part_2_c_u_count[['c_u_count_in_6',\n",
    "                                                               'c_u_count_in_3',\n",
    "                                                               'c_u_count_in_1']].astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02ea3344",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15406/3010509315.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_2_c_b_count_in_6 = df_part_2.drop_duplicates(['item_category','behavior_type'], 'last')[['item_category','behavior_type','cumcount']]\n"
     ]
    }
   ],
   "source": [
    "# c_b_count_in_6\n",
    "df_part_2['cumcount'] = df_part_2.groupby(['item_category', 'behavior_type']).cumcount()\n",
    "df_part_2_c_b_count_in_6 = df_part_2.drop_duplicates(['item_category','behavior_type'], 'last')[['item_category','behavior_type','cumcount']]\n",
    "df_part_2_c_b_count_in_6 = pd.get_dummies(df_part_2_c_b_count_in_6['behavior_type']).join(df_part_2_c_b_count_in_6[['item_category','cumcount']])\n",
    "df_part_2_c_b_count_in_6.rename(columns = {1:'behavior_type_1',\n",
    "                                           2:'behavior_type_2',\n",
    "                                           3:'behavior_type_3',\n",
    "                                           4:'behavior_type_4'}, inplace=True)\n",
    "df_part_2_c_b_count_in_6['c_b1_count_in_6'] = df_part_2_c_b_count_in_6['behavior_type_1'] * (df_part_2_c_b_count_in_6['cumcount']+1)\n",
    "df_part_2_c_b_count_in_6['c_b2_count_in_6'] = df_part_2_c_b_count_in_6['behavior_type_2'] * (df_part_2_c_b_count_in_6['cumcount']+1)\n",
    "df_part_2_c_b_count_in_6['c_b3_count_in_6'] = df_part_2_c_b_count_in_6['behavior_type_3'] * (df_part_2_c_b_count_in_6['cumcount']+1)\n",
    "df_part_2_c_b_count_in_6['c_b4_count_in_6'] = df_part_2_c_b_count_in_6['behavior_type_4'] * (df_part_2_c_b_count_in_6['cumcount']+1)\n",
    "df_part_2_c_b_count_in_6 = df_part_2_c_b_count_in_6[['item_category', \n",
    "                                                     'c_b1_count_in_6', \n",
    "                                                     'c_b2_count_in_6', \n",
    "                                                     'c_b3_count_in_6',\n",
    "                                                     'c_b4_count_in_6']]\n",
    "df_part_2_c_b_count_in_6 = df_part_2_c_b_count_in_6.groupby('item_category').agg({'c_b1_count_in_6': np.sum,\n",
    "                                                                                  'c_b2_count_in_6': np.sum,\n",
    "                                                                                  'c_b3_count_in_6': np.sum,\n",
    "                                                                                  'c_b4_count_in_6': np.sum})\n",
    "df_part_2_c_b_count_in_6.reset_index(inplace = True)\n",
    "df_part_2_c_b_count_in_6['c_b_count_in_6'] = df_part_2_c_b_count_in_6['c_b1_count_in_6'] + \\\n",
    "                                             df_part_2_c_b_count_in_6['c_b2_count_in_6'] + \\\n",
    "                                             df_part_2_c_b_count_in_6['c_b3_count_in_6'] + \\\n",
    "                                             df_part_2_c_b_count_in_6['c_b4_count_in_6']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16377107",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15406/2772657636.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_part_2_in_3['cumcount'] = df_part_2_in_3.groupby(['item_category', 'behavior_type']).cumcount()\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15406/2772657636.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_2_c_b_count_in_3 = df_part_2_in_3.drop_duplicates(['item_category','behavior_type'], 'last')[['item_category','behavior_type','cumcount']]\n"
     ]
    }
   ],
   "source": [
    "# c_b_count_in_3\n",
    "df_part_2_in_3 = df_part_2[df_part_2['time'] >= np.datetime64('2014-12-02')]\n",
    "df_part_2_in_3['cumcount'] = df_part_2_in_3.groupby(['item_category', 'behavior_type']).cumcount()\n",
    "df_part_2_c_b_count_in_3 = df_part_2_in_3.drop_duplicates(['item_category','behavior_type'], 'last')[['item_category','behavior_type','cumcount']]\n",
    "df_part_2_c_b_count_in_3 = pd.get_dummies(df_part_2_c_b_count_in_3['behavior_type']).join(df_part_2_c_b_count_in_3[['item_category','cumcount']])\n",
    "df_part_2_c_b_count_in_3.rename(columns = {1:'behavior_type_1',\n",
    "                                           2:'behavior_type_2',\n",
    "                                           3:'behavior_type_3',\n",
    "                                           4:'behavior_type_4'}, inplace=True)\n",
    "df_part_2_c_b_count_in_3['c_b1_count_in_3'] = df_part_2_c_b_count_in_3['behavior_type_1'] * (df_part_2_c_b_count_in_3['cumcount']+1)\n",
    "df_part_2_c_b_count_in_3['c_b2_count_in_3'] = df_part_2_c_b_count_in_3['behavior_type_2'] * (df_part_2_c_b_count_in_3['cumcount']+1)\n",
    "df_part_2_c_b_count_in_3['c_b3_count_in_3'] = df_part_2_c_b_count_in_3['behavior_type_3'] * (df_part_2_c_b_count_in_3['cumcount']+1)\n",
    "df_part_2_c_b_count_in_3['c_b4_count_in_3'] = df_part_2_c_b_count_in_3['behavior_type_4'] * (df_part_2_c_b_count_in_3['cumcount']+1)\n",
    "df_part_2_c_b_count_in_3 = df_part_2_c_b_count_in_3[['item_category', \n",
    "                                                     'c_b1_count_in_3', \n",
    "                                                     'c_b2_count_in_3', \n",
    "                                                     'c_b3_count_in_3',\n",
    "                                                     'c_b4_count_in_3']]\n",
    "df_part_2_c_b_count_in_3 = df_part_2_c_b_count_in_3.groupby('item_category').agg({'c_b1_count_in_3': np.sum,\n",
    "                                                                                  'c_b2_count_in_3': np.sum,\n",
    "                                                                                  'c_b3_count_in_3': np.sum,\n",
    "                                                                                  'c_b4_count_in_3': np.sum})\n",
    "df_part_2_c_b_count_in_3.reset_index(inplace = True)\n",
    "df_part_2_c_b_count_in_3['c_b_count_in_3'] = df_part_2_c_b_count_in_3['c_b1_count_in_3'] + \\\n",
    "                                             df_part_2_c_b_count_in_3['c_b2_count_in_3'] + \\\n",
    "                                             df_part_2_c_b_count_in_3['c_b3_count_in_3'] + \\\n",
    "                                             df_part_2_c_b_count_in_3['c_b4_count_in_3']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80ec7eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15406/2040021634.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_part_2_in_1['cumcount'] = df_part_2_in_1.groupby(['item_category', 'behavior_type']).cumcount()\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15406/2040021634.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_2_c_b_count_in_1 = df_part_2_in_1.drop_duplicates(['item_category','behavior_type'], 'last')[['item_category','behavior_type','cumcount']]\n"
     ]
    }
   ],
   "source": [
    "# c_b_count_in_1\n",
    "df_part_2_in_1 = df_part_2[df_part_2['time'] >= np.datetime64('2014-12-04')]\n",
    "df_part_2_in_1['cumcount'] = df_part_2_in_1.groupby(['item_category', 'behavior_type']).cumcount()\n",
    "df_part_2_c_b_count_in_1 = df_part_2_in_1.drop_duplicates(['item_category','behavior_type'], 'last')[['item_category','behavior_type','cumcount']]\n",
    "df_part_2_c_b_count_in_1 = pd.get_dummies(df_part_2_c_b_count_in_1['behavior_type']).join(df_part_2_c_b_count_in_1[['item_category','cumcount']])\n",
    "df_part_2_c_b_count_in_1.rename(columns = {1:'behavior_type_1',\n",
    "                                           2:'behavior_type_2',\n",
    "                                           3:'behavior_type_3',\n",
    "                                           4:'behavior_type_4'}, inplace=True)\n",
    "df_part_2_c_b_count_in_1['c_b1_count_in_1'] = df_part_2_c_b_count_in_1['behavior_type_1'] * (df_part_2_c_b_count_in_1['cumcount']+1)\n",
    "df_part_2_c_b_count_in_1['c_b2_count_in_1'] = df_part_2_c_b_count_in_1['behavior_type_2'] * (df_part_2_c_b_count_in_1['cumcount']+1)\n",
    "df_part_2_c_b_count_in_1['c_b3_count_in_1'] = df_part_2_c_b_count_in_1['behavior_type_3'] * (df_part_2_c_b_count_in_1['cumcount']+1)\n",
    "df_part_2_c_b_count_in_1['c_b4_count_in_1'] = df_part_2_c_b_count_in_1['behavior_type_4'] * (df_part_2_c_b_count_in_1['cumcount']+1)\n",
    "df_part_2_c_b_count_in_1 = df_part_2_c_b_count_in_1[['item_category', \n",
    "                                                     'c_b1_count_in_1', \n",
    "                                                     'c_b2_count_in_1', \n",
    "                                                     'c_b3_count_in_1',\n",
    "                                                     'c_b4_count_in_1']]\n",
    "df_part_2_c_b_count_in_1 = df_part_2_c_b_count_in_1.groupby('item_category').agg({'c_b1_count_in_1': np.sum,\n",
    "                                                                                  'c_b2_count_in_1': np.sum,\n",
    "                                                                                  'c_b3_count_in_1': np.sum,\n",
    "                                                                                  'c_b4_count_in_1': np.sum})\n",
    "df_part_2_c_b_count_in_1.reset_index(inplace = True)\n",
    "df_part_2_c_b_count_in_1['c_b_count_in_1'] = df_part_2_c_b_count_in_1['c_b1_count_in_1'] + \\\n",
    "                                             df_part_2_c_b_count_in_1['c_b2_count_in_1'] + \\\n",
    "                                             df_part_2_c_b_count_in_1['c_b3_count_in_1'] + \\\n",
    "                                             df_part_2_c_b_count_in_1['c_b4_count_in_1']    \n",
    "                                             \n",
    "df_part_2_c_b_count = pd.merge(df_part_2_c_b_count_in_6, df_part_2_c_b_count_in_3, on = ['item_category'], how = 'left').fillna(0)                                      \n",
    "df_part_2_c_b_count = pd.merge(df_part_2_c_b_count, df_part_2_c_b_count_in_1, on = ['item_category'], how = 'left').fillna(0)\n",
    "df_part_2_c_b_count[['c_b1_count_in_6',\n",
    "                     'c_b2_count_in_6',\n",
    "                     'c_b3_count_in_6',\n",
    "                     'c_b4_count_in_6',\n",
    "                      'c_b_count_in_6',\n",
    "                     'c_b1_count_in_3',\n",
    "                     'c_b2_count_in_3',\n",
    "                     'c_b3_count_in_3',\n",
    "                     'c_b4_count_in_3',\n",
    "                      'c_b_count_in_3',\n",
    "                     'c_b1_count_in_1',\n",
    "                     'c_b2_count_in_1',\n",
    "                     'c_b3_count_in_1',\n",
    "                     'c_b4_count_in_1',\n",
    "                      'c_b_count_in_1']] = df_part_2_c_b_count[['c_b1_count_in_6',\n",
    "                                                                'c_b2_count_in_6',\n",
    "                                                                'c_b3_count_in_6',\n",
    "                                                                'c_b4_count_in_6',\n",
    "                                                                 'c_b_count_in_6',\n",
    "                                                                'c_b1_count_in_3',\n",
    "                                                                'c_b2_count_in_3',\n",
    "                                                                'c_b3_count_in_3',\n",
    "                                                                'c_b4_count_in_3',\n",
    "                                                                 'c_b_count_in_3',\n",
    "                                                                'c_b1_count_in_1',\n",
    "                                                                'c_b2_count_in_1',\n",
    "                                                                'c_b3_count_in_1',\n",
    "                                                                'c_b4_count_in_1',\n",
    "                                                                 'c_b_count_in_1']].astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e8967f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15406/387250695.py:6: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_2_c_b4_time = df_part_2[df_part_2['behavior_type'] == 4].drop_duplicates(['item_category'], 'first')[['item_category','time']]\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15406/387250695.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_2_c_b_time = df_part_2.drop_duplicates(['item_category'], 'first')[['item_category','time']]\n"
     ]
    }
   ],
   "source": [
    "# c_b4_rate\n",
    "df_part_2_c_b_count['c_b4_rate'] = df_part_2_c_b_count['c_b4_count_in_6'] / df_part_2_c_b_count['c_b_count_in_6']\n",
    "\n",
    "# c_b4_diff_time\n",
    "df_part_2 = df_part_2.sort_values(by=['item_category', 'time'])\n",
    "df_part_2_c_b4_time = df_part_2[df_part_2['behavior_type'] == 4].drop_duplicates(['item_category'], 'first')[['item_category','time']]\n",
    "df_part_2_c_b4_time.columns = ['item_category','b4_first_time']\n",
    "df_part_2_c_b_time = df_part_2.drop_duplicates(['item_category'], 'first')[['item_category','time']]\n",
    "df_part_2_c_b_time.columns = ['item_category','b_first_time']\n",
    "df_part_2_c_b_b4_time = pd.merge(df_part_2_c_b_time, df_part_2_c_b4_time, on = ['item_category'])\n",
    "df_part_2_c_b_b4_time['c_b4_diff_time']  = df_part_2_c_b_b4_time['b4_first_time'] - df_part_2_c_b_b4_time['b_first_time']\n",
    "df_part_2_c_b_b4_time['c_b4_diff_hours'] = df_part_2_c_b_b4_time['c_b4_diff_time'].apply(lambda x: x.days * 24 + x.seconds//3600)\n",
    "df_part_2_c_b_b4_time = df_part_2_c_b_b4_time[['item_category',\n",
    "                                               'c_b4_diff_hours']]\n",
    "\n",
    "# generating feature set C\n",
    "f_C_part_2 = pd.merge(df_part_2_c_u_count, df_part_2_c_b_count, on = ['item_category'], how = 'left')\n",
    "f_C_part_2 = pd.merge(f_C_part_2, df_part_2_c_b_b4_time, on = ['item_category'], how = 'left')\n",
    "f_C_part_2 = f_C_part_2.round({'c_b4_rate': 3})\n",
    "\n",
    "# write to csv file\n",
    "f_C_part_2.to_csv(path_df_part_2_C, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8df08836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Step 1.4 feature data set IC of df_part_2\\n    ic_u_rank_in_c  (in_6)\\n    ic_b_rank_in_c  (in_6)\\n    ic_b4_rank_in_c  (in_6)\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################################\n",
    "'''Step 1.4 feature data set IC of df_part_2\n",
    "    ic_u_rank_in_c  (in_6)\n",
    "    ic_b_rank_in_c  (in_6)\n",
    "    ic_b4_rank_in_c  (in_6)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7bdca4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get df_part_2_i_ub_count\n",
    "path_df = open(path_df_part_2_I, 'r')\n",
    "try:\n",
    "    df_part_2_I = pd.read_csv(path_df, index_col = False)\n",
    "finally:\n",
    "    path_df.close()\n",
    "df_part_2_i_ub_count = df_part_2_I[['item_id','i_u_count_in_6','i_b_count_in_6','i_b4_count_in_6']]\n",
    "del(df_part_2_I)\n",
    "\n",
    "# get df_part_2_uic for merge i & c\n",
    "path_df = open(path_df_part_2_uic_label, 'r')\n",
    "try:\n",
    "    df_part_2_uic = pd.read_csv(path_df, index_col = False)\n",
    "finally:\n",
    "    path_df.close()\n",
    "df_part_2_ic_u_b_count = pd.merge(df_part_2_uic, df_part_2_i_ub_count, on=['item_id'], how='left').fillna(0)\n",
    "df_part_2_ic_u_b_count = df_part_2_ic_u_b_count.drop_duplicates(['item_id','item_category'])\n",
    "\n",
    "# ic_u_rank_in_c\n",
    "df_part_2_ic_u_b_count['ic_u_rank_in_c'] = df_part_2_ic_u_b_count.groupby('item_category')['i_u_count_in_6'].rank(method='min',ascending=False).astype('int')\n",
    "# ic_b_rank_in_c\n",
    "df_part_2_ic_u_b_count['ic_b_rank_in_c'] = df_part_2_ic_u_b_count.groupby('item_category')['i_b_count_in_6'].rank(method='min',ascending=False).astype('int')\n",
    "# ic_b4_rank_in_c\n",
    "df_part_2_ic_u_b_count['ic_b4_rank_in_c'] = df_part_2_ic_u_b_count.groupby('item_category')['i_b4_count_in_6'].rank(method='min',ascending=False).astype('int')\n",
    "\n",
    "f_IC_part_2 = df_part_2_ic_u_b_count[['item_id', \n",
    "                                      'item_category', \n",
    "                                      'ic_u_rank_in_c', \n",
    "                                      'ic_b_rank_in_c', \n",
    "                                      'ic_b4_rank_in_c']]\n",
    "# write to csv file\n",
    "f_IC_part_2.to_csv(path_df_part_2_IC, index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bd35509d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Step 1.5 feature data set UI of df_part_2\\n    (1)\\n    ui_b1_count_in_6\\n    ui_b2_count_in_6\\n    ui_b3_count_in_6\\n    ui_b4_count_in_6\\n     ui_b_count_in_6\\n    ui_b1_count_in_3\\n    ui_b2_count_in_3\\n    ui_b3_count_in_3\\n    ui_b4_count_in_3\\n     ui_b_count_in_3\\n    ui_b1_count_in_1\\n    ui_b2_count_in_1\\n    ui_b3_count_in_1\\n    ui_b4_count_in_1\\n     ui_b_count_in_1\\n    (2)\\n    ui_b_count_rank_in_u  (in_6)\\n    ui_b_count_rank_in_uc (in_6)\\n    (3)\\n    ui_b1_last_hours  (in_6)\\n    ui_b2_last_hours  (in_6)\\n    ui_b3_last_hours  (in_6)\\n    ui_b4_last_hours  (in_6)\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################################\n",
    "'''Step 1.5 feature data set UI of df_part_2\n",
    "    (1)\n",
    "    ui_b1_count_in_6\n",
    "    ui_b2_count_in_6\n",
    "    ui_b3_count_in_6\n",
    "    ui_b4_count_in_6\n",
    "     ui_b_count_in_6\n",
    "    ui_b1_count_in_3\n",
    "    ui_b2_count_in_3\n",
    "    ui_b3_count_in_3\n",
    "    ui_b4_count_in_3\n",
    "     ui_b_count_in_3\n",
    "    ui_b1_count_in_1\n",
    "    ui_b2_count_in_1\n",
    "    ui_b3_count_in_1\n",
    "    ui_b4_count_in_1\n",
    "     ui_b_count_in_1\n",
    "    (2)\n",
    "    ui_b_count_rank_in_u  (in_6)\n",
    "    ui_b_count_rank_in_uc (in_6)\n",
    "    (3)\n",
    "    ui_b1_last_hours  (in_6)\n",
    "    ui_b2_last_hours  (in_6)\n",
    "    ui_b3_last_hours  (in_6)\n",
    "    ui_b4_last_hours  (in_6)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "04e3a2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_df = open(path_df_part_2, 'r')\n",
    "try:\n",
    "    df_part_2 = pd.read_csv(path_df, index_col = False, parse_dates = [0])\n",
    "    df_part_2.columns = ['time','user_id','item_id','behavior_type','item_category']\n",
    "finally:\n",
    "    path_df.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "056f277f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15406/1880042022.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_2_ui_b_count_in_6 = df_part_2.drop_duplicates(['user_id','item_id','behavior_type'],'last')[['user_id','item_id','behavior_type','cumcount']]\n"
     ]
    }
   ],
   "source": [
    "# ui_b_count_in_6\n",
    "df_part_2['cumcount'] = df_part_2.groupby(['user_id', 'item_id', 'behavior_type']).cumcount()\n",
    "df_part_2_ui_b_count_in_6 = df_part_2.drop_duplicates(['user_id','item_id','behavior_type'],'last')[['user_id','item_id','behavior_type','cumcount']]\n",
    "df_part_2_ui_b_count_in_6 = pd.get_dummies(df_part_2_ui_b_count_in_6['behavior_type']).join(df_part_2_ui_b_count_in_6[['user_id','item_id','cumcount']])\n",
    "df_part_2_ui_b_count_in_6.rename(columns = {1:'behavior_type_1',\n",
    "                                            2:'behavior_type_2',\n",
    "                                            3:'behavior_type_3',\n",
    "                                            4:'behavior_type_4'}, inplace=True)  \n",
    "df_part_2_ui_b_count_in_6['ui_b1_count_in_6'] = df_part_2_ui_b_count_in_6['behavior_type_1'] * (df_part_2_ui_b_count_in_6['cumcount']+1)\n",
    "df_part_2_ui_b_count_in_6['ui_b2_count_in_6'] = df_part_2_ui_b_count_in_6['behavior_type_2'] * (df_part_2_ui_b_count_in_6['cumcount']+1)\n",
    "df_part_2_ui_b_count_in_6['ui_b3_count_in_6'] = df_part_2_ui_b_count_in_6['behavior_type_3'] * (df_part_2_ui_b_count_in_6['cumcount']+1)\n",
    "df_part_2_ui_b_count_in_6['ui_b4_count_in_6'] = df_part_2_ui_b_count_in_6['behavior_type_4'] * (df_part_2_ui_b_count_in_6['cumcount']+1)\n",
    "df_part_2_ui_b_count_in_6 = df_part_2_ui_b_count_in_6[['user_id', \n",
    "                                                       'item_id', \n",
    "                                                       'ui_b1_count_in_6', \n",
    "                                                       'ui_b2_count_in_6', \n",
    "                                                       'ui_b3_count_in_6',\n",
    "                                                       'ui_b4_count_in_6']]\n",
    "df_part_2_ui_b_count_in_6 = df_part_2_ui_b_count_in_6.groupby(['user_id', 'item_id']).agg({'ui_b1_count_in_6': np.sum,\n",
    "                                                                                           'ui_b2_count_in_6': np.sum,\n",
    "                                                                                           'ui_b3_count_in_6': np.sum,\n",
    "                                                                                           'ui_b4_count_in_6': np.sum})\n",
    "df_part_2_ui_b_count_in_6.reset_index(inplace = True)\n",
    "df_part_2_ui_b_count_in_6['ui_b_count_in_6'] = df_part_2_ui_b_count_in_6['ui_b1_count_in_6'] + \\\n",
    "                                               df_part_2_ui_b_count_in_6['ui_b2_count_in_6'] + \\\n",
    "                                               df_part_2_ui_b_count_in_6['ui_b3_count_in_6'] + \\\n",
    "                                               df_part_2_ui_b_count_in_6['ui_b4_count_in_6']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e6fb4c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15406/3513265717.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_part_2_in_3['cumcount'] = df_part_2_in_3.groupby(['user_id', 'item_id', 'behavior_type']).cumcount()\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15406/3513265717.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_2_ui_b_count_in_3 = df_part_2.drop_duplicates(['user_id','item_id','behavior_type'],'last')[['user_id','item_id','behavior_type','cumcount']]\n"
     ]
    }
   ],
   "source": [
    "# ui_b_count_in_3\n",
    "df_part_2_in_3 = df_part_2[df_part_2['time'] >= np.datetime64('2014-12-02')]\n",
    "df_part_2_in_3['cumcount'] = df_part_2_in_3.groupby(['user_id', 'item_id', 'behavior_type']).cumcount()\n",
    "df_part_2_ui_b_count_in_3 = df_part_2.drop_duplicates(['user_id','item_id','behavior_type'],'last')[['user_id','item_id','behavior_type','cumcount']]\n",
    "df_part_2_ui_b_count_in_3 = pd.get_dummies(df_part_2_ui_b_count_in_3['behavior_type']).join(df_part_2_ui_b_count_in_3[['user_id','item_id','cumcount']])\n",
    "df_part_2_ui_b_count_in_3.rename(columns = {1:'behavior_type_1',\n",
    "                                            2:'behavior_type_2',\n",
    "                                            3:'behavior_type_3',\n",
    "                                            4:'behavior_type_4'}, inplace=True)  \n",
    "df_part_2_ui_b_count_in_3['ui_b1_count_in_3'] = df_part_2_ui_b_count_in_3['behavior_type_1'] * (df_part_2_ui_b_count_in_3['cumcount']+1)\n",
    "df_part_2_ui_b_count_in_3['ui_b2_count_in_3'] = df_part_2_ui_b_count_in_3['behavior_type_2'] * (df_part_2_ui_b_count_in_3['cumcount']+1)\n",
    "df_part_2_ui_b_count_in_3['ui_b3_count_in_3'] = df_part_2_ui_b_count_in_3['behavior_type_3'] * (df_part_2_ui_b_count_in_3['cumcount']+1)\n",
    "df_part_2_ui_b_count_in_3['ui_b4_count_in_3'] = df_part_2_ui_b_count_in_3['behavior_type_4'] * (df_part_2_ui_b_count_in_3['cumcount']+1)\n",
    "df_part_2_ui_b_count_in_3 = df_part_2_ui_b_count_in_3[['user_id', \n",
    "                                                       'item_id', \n",
    "                                                       'ui_b1_count_in_3', \n",
    "                                                       'ui_b2_count_in_3', \n",
    "                                                       'ui_b3_count_in_3',\n",
    "                                                       'ui_b4_count_in_3']]\n",
    "df_part_2_ui_b_count_in_3 = df_part_2_ui_b_count_in_3.groupby(['user_id', 'item_id']).agg({'ui_b1_count_in_3': np.sum,\n",
    "                                                                                           'ui_b2_count_in_3': np.sum,\n",
    "                                                                                           'ui_b3_count_in_3': np.sum,\n",
    "                                                                                           'ui_b4_count_in_3': np.sum})\n",
    "df_part_2_ui_b_count_in_3.reset_index(inplace = True)\n",
    "df_part_2_ui_b_count_in_3['ui_b_count_in_3'] = df_part_2_ui_b_count_in_3['ui_b1_count_in_3'] + \\\n",
    "                                               df_part_2_ui_b_count_in_3['ui_b2_count_in_3'] + \\\n",
    "                                               df_part_2_ui_b_count_in_3['ui_b3_count_in_3'] + \\\n",
    "                                               df_part_2_ui_b_count_in_3['ui_b4_count_in_3']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c53755c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15406/2094975292.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_part_2_in_1['cumcount'] = df_part_2_in_1.groupby(['user_id', 'item_id', 'behavior_type']).cumcount()\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15406/2094975292.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_2_ui_b_count_in_1 = df_part_2_in_1.drop_duplicates(['user_id','item_id','behavior_type'], 'last')[['user_id','item_id','behavior_type','cumcount']]\n"
     ]
    }
   ],
   "source": [
    "# ui_b_count_in_1\n",
    "df_part_2_in_1 = df_part_2[df_part_2['time'] >= np.datetime64('2014-12-04')]\n",
    "df_part_2_in_1['cumcount'] = df_part_2_in_1.groupby(['user_id', 'item_id', 'behavior_type']).cumcount()\n",
    "df_part_2_ui_b_count_in_1 = df_part_2_in_1.drop_duplicates(['user_id','item_id','behavior_type'], 'last')[['user_id','item_id','behavior_type','cumcount']]\n",
    "df_part_2_ui_b_count_in_1 = pd.get_dummies(df_part_2_ui_b_count_in_1['behavior_type']).join(df_part_2_ui_b_count_in_1[['user_id','item_id','cumcount']])\n",
    "df_part_2_ui_b_count_in_1.rename(columns = {1:'behavior_type_1',\n",
    "                                            2:'behavior_type_2',\n",
    "                                            3:'behavior_type_3',\n",
    "                                            4:'behavior_type_4'}, inplace=True)\n",
    "df_part_2_ui_b_count_in_1['ui_b1_count_in_1'] = df_part_2_ui_b_count_in_1['behavior_type_1'] * (df_part_2_ui_b_count_in_1['cumcount']+1)\n",
    "df_part_2_ui_b_count_in_1['ui_b2_count_in_1'] = df_part_2_ui_b_count_in_1['behavior_type_2'] * (df_part_2_ui_b_count_in_1['cumcount']+1)\n",
    "df_part_2_ui_b_count_in_1['ui_b3_count_in_1'] = df_part_2_ui_b_count_in_1['behavior_type_3'] * (df_part_2_ui_b_count_in_1['cumcount']+1)\n",
    "df_part_2_ui_b_count_in_1['ui_b4_count_in_1'] = df_part_2_ui_b_count_in_1['behavior_type_4'] * (df_part_2_ui_b_count_in_1['cumcount']+1)\n",
    "df_part_2_ui_b_count_in_1 = df_part_2_ui_b_count_in_1[['user_id',\n",
    "                                                       'item_id', \n",
    "                                                       'ui_b1_count_in_1', \n",
    "                                                       'ui_b2_count_in_1', \n",
    "                                                       'ui_b3_count_in_1',\n",
    "                                                       'ui_b4_count_in_1']]\n",
    "df_part_2_ui_b_count_in_1 = df_part_2_ui_b_count_in_1.groupby(['user_id', 'item_id']).agg({'ui_b1_count_in_1': np.sum,\n",
    "                                                                                           'ui_b2_count_in_1': np.sum,\n",
    "                                                                                           'ui_b3_count_in_1': np.sum,\n",
    "                                                                                           'ui_b4_count_in_1': np.sum})\n",
    "df_part_2_ui_b_count_in_1.reset_index(inplace = True)\n",
    "df_part_2_ui_b_count_in_1['ui_b_count_in_1'] = df_part_2_ui_b_count_in_1['ui_b1_count_in_1'] + \\\n",
    "                                               df_part_2_ui_b_count_in_1['ui_b2_count_in_1'] + \\\n",
    "                                               df_part_2_ui_b_count_in_1['ui_b3_count_in_1'] + \\\n",
    "                                               df_part_2_ui_b_count_in_1['ui_b4_count_in_1']\n",
    "                                             \n",
    "df_part_2_ui_b_count = pd.merge(df_part_2_ui_b_count_in_6, df_part_2_ui_b_count_in_3, on = ['user_id','item_id'], how = 'left').fillna(0)\n",
    "df_part_2_ui_b_count = pd.merge(df_part_2_ui_b_count, df_part_2_ui_b_count_in_1, on = ['user_id','item_id'], how = 'left').fillna(0)\n",
    "df_part_2_ui_b_count[['ui_b1_count_in_6',\n",
    "                      'ui_b2_count_in_6',\n",
    "                      'ui_b3_count_in_6',\n",
    "                      'ui_b4_count_in_6',\n",
    "                       'ui_b_count_in_6',\n",
    "                      'ui_b1_count_in_3',\n",
    "                      'ui_b2_count_in_3',\n",
    "                      'ui_b3_count_in_3',\n",
    "                      'ui_b4_count_in_3',\n",
    "                       'ui_b_count_in_3',\n",
    "                      'ui_b1_count_in_1',\n",
    "                      'ui_b2_count_in_1',\n",
    "                      'ui_b3_count_in_1',\n",
    "                      'ui_b4_count_in_1',\n",
    "                       'ui_b_count_in_1']] = df_part_2_ui_b_count[['ui_b1_count_in_6',\n",
    "                                                                   'ui_b2_count_in_6',\n",
    "                                                                   'ui_b3_count_in_6',\n",
    "                                                                   'ui_b4_count_in_6',\n",
    "                                                                    'ui_b_count_in_6',\n",
    "                                                                   'ui_b1_count_in_3',\n",
    "                                                                   'ui_b2_count_in_3',\n",
    "                                                                   'ui_b3_count_in_3',\n",
    "                                                                   'ui_b4_count_in_3',\n",
    "                                                                    'ui_b_count_in_3',\n",
    "                                                                   'ui_b1_count_in_1',\n",
    "                                                                   'ui_b2_count_in_1',\n",
    "                                                                   'ui_b3_count_in_1',\n",
    "                                                                   'ui_b4_count_in_1',\n",
    "                                                                    'ui_b_count_in_1']].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "db43a6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ui_b_count_rank_in_u\n",
    "df_part_2_ui_b_count['ui_b_count_rank_in_u'] = df_part_2_ui_b_count.groupby(['user_id'])['ui_b_count_in_6'].rank(method='min',ascending=False).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c77688aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ui_b_count_rank_in_uc\n",
    "path_df = open(path_df_part_2_uic_label, 'r')\n",
    "try:\n",
    "    df_part_2_uic = pd.read_csv(path_df, index_col = False)\n",
    "finally:\n",
    "    path_df.close()\n",
    "df_part_2_ui_b_count = pd.merge(df_part_2_uic, df_part_2_ui_b_count, on = ['user_id','item_id'], how = 'left')\n",
    "df_part_2_ui_b_count['ui_b_count_rank_in_uc'] = df_part_2_ui_b_count.groupby(['user_id','item_category'])['ui_b_count_rank_in_u'].rank(method='min',ascending=True).astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "18d76a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15406/546317807.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_2_ui_b_last_time = df_part_2.drop_duplicates(['user_id','item_id','behavior_type'],'last')[['user_id','item_id','behavior_type','time']]\n"
     ]
    }
   ],
   "source": [
    "# ui_b_last_time\n",
    "df_part_2.sort_values(by=['user_id','item_id','behavior_type','time'], inplace=True)\n",
    "df_part_2_ui_b_last_time = df_part_2.drop_duplicates(['user_id','item_id','behavior_type'],'last')[['user_id','item_id','behavior_type','time']]\n",
    "\n",
    "df_part_2_ui_b_last_time['ui_b1_last_time'] = df_part_2_ui_b_last_time[df_part_2_ui_b_last_time['behavior_type'] == 1]['time']\n",
    "df_part_2_ui_b_last_time['ui_b2_last_time'] = df_part_2_ui_b_last_time[df_part_2_ui_b_last_time['behavior_type'] == 2]['time']\n",
    "df_part_2_ui_b_last_time['ui_b3_last_time'] = df_part_2_ui_b_last_time[df_part_2_ui_b_last_time['behavior_type'] == 3]['time']\n",
    "df_part_2_ui_b_last_time['ui_b4_last_time'] = df_part_2_ui_b_last_time[df_part_2_ui_b_last_time['behavior_type'] == 4]['time']\n",
    "\n",
    "df_part_2_ui_b_last_time.loc[df_part_2_ui_b_last_time['ui_b1_last_time'].notnull(), 'ui_b1_last_hours'] = (pd.to_datetime('2014-12-05') - df_part_2_ui_b_last_time['ui_b1_last_time'])             \n",
    "df_part_2_ui_b_last_time['ui_b1_last_hours'] = df_part_2_ui_b_last_time[df_part_2_ui_b_last_time['ui_b1_last_hours'].notnull()]['ui_b1_last_hours'].apply(lambda x: x.days*24 + x.seconds//3600)\n",
    "\n",
    "df_part_2_ui_b_last_time.loc[df_part_2_ui_b_last_time['ui_b2_last_time'].notnull(), 'ui_b2_last_hours'] = (pd.to_datetime('2014-12-05') - df_part_2_ui_b_last_time['ui_b2_last_time'])             \n",
    "df_part_2_ui_b_last_time['ui_b2_last_hours'] = df_part_2_ui_b_last_time[df_part_2_ui_b_last_time['ui_b2_last_hours'].notnull()]['ui_b2_last_hours'].apply(lambda x: x.days*24 + x.seconds//3600)\n",
    "\n",
    "df_part_2_ui_b_last_time.loc[df_part_2_ui_b_last_time['ui_b3_last_time'].notnull(), 'ui_b3_last_hours'] = (pd.to_datetime('2014-12-05') - df_part_2_ui_b_last_time['ui_b3_last_time'])             \n",
    "df_part_2_ui_b_last_time['ui_b3_last_hours'] = df_part_2_ui_b_last_time[df_part_2_ui_b_last_time['ui_b3_last_hours'].notnull()]['ui_b3_last_hours'].apply(lambda x: x.days*24 + x.seconds//3600)\n",
    "\n",
    "df_part_2_ui_b_last_time.loc[df_part_2_ui_b_last_time['ui_b4_last_time'].notnull(), 'ui_b4_last_hours'] = (pd.to_datetime('2014-12-05') - df_part_2_ui_b_last_time['ui_b4_last_time'])             \n",
    "df_part_2_ui_b_last_time['ui_b4_last_hours'] = df_part_2_ui_b_last_time[df_part_2_ui_b_last_time['ui_b4_last_hours'].notnull()]['ui_b4_last_hours'].apply(lambda x: x.days*24 + x.seconds//3600)\n",
    "\n",
    "df_part_2_ui_b_last_time = df_part_2_ui_b_last_time[['user_id',\n",
    "                                                     'item_id',\n",
    "                                                     'ui_b1_last_hours',\n",
    "                                                     'ui_b2_last_hours',\n",
    "                                                     'ui_b3_last_hours',\n",
    "                                                     'ui_b4_last_hours']] \n",
    "\n",
    "df_part_2_ui_b_last_time = df_part_2_ui_b_last_time.groupby(['user_id', 'item_id']).agg({'ui_b1_last_hours': np.sum,\n",
    "                                                                                         'ui_b2_last_hours': np.sum,\n",
    "                                                                                         'ui_b3_last_hours': np.sum,\n",
    "                                                                                         'ui_b4_last_hours': np.sum})\n",
    "df_part_2_ui_b_last_time.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7e7606c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge for generation of f_UI_part_2\n",
    "f_UI_part_2 = pd.merge(df_part_2_ui_b_count, df_part_2_ui_b_last_time, how='left', on=['user_id', 'item_id'])\n",
    "\n",
    "# write to csv file\n",
    "f_UI_part_2.to_csv(path_df_part_2_UI, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "374e69d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Step 1.6 feature data set UC of df_part_2\\n    (1)\\n    uc_b1_count_in_6\\n    uc_b2_count_in_6\\n    uc_b3_count_in_6\\n    uc_b4_count_in_6\\n     uc_b_count_in_6\\n    uc_b1_count_in_3\\n    uc_b2_count_in_3\\n    uc_b3_count_in_3\\n    uc_b4_count_in_3\\n     uc_b_count_in_3\\n    uc_b1_count_in_1\\n    uc_b2_count_in_1\\n    uc_b3_count_in_1\\n    uc_b4_count_in_1\\n     uc_b_count_in_1\\n    (2)\\n    uc_b_count_rank_in_u  (in_6)\\n    (3)\\n    uc_b1_last_hours  (in_6)\\n    uc_b2_last_hours  (in_6)\\n    uc_b3_last_hours  (in_6)\\n    uc_b4_last_hours  (in_6)\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################################\n",
    "'''Step 1.6 feature data set UC of df_part_2\n",
    "    (1)\n",
    "    uc_b1_count_in_6\n",
    "    uc_b2_count_in_6\n",
    "    uc_b3_count_in_6\n",
    "    uc_b4_count_in_6\n",
    "     uc_b_count_in_6\n",
    "    uc_b1_count_in_3\n",
    "    uc_b2_count_in_3\n",
    "    uc_b3_count_in_3\n",
    "    uc_b4_count_in_3\n",
    "     uc_b_count_in_3\n",
    "    uc_b1_count_in_1\n",
    "    uc_b2_count_in_1\n",
    "    uc_b3_count_in_1\n",
    "    uc_b4_count_in_1\n",
    "     uc_b_count_in_1\n",
    "    (2)\n",
    "    uc_b_count_rank_in_u  (in_6)\n",
    "    (3)\n",
    "    uc_b1_last_hours  (in_6)\n",
    "    uc_b2_last_hours  (in_6)\n",
    "    uc_b3_last_hours  (in_6)\n",
    "    uc_b4_last_hours  (in_6)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0afddbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_df = open(path_df_part_2, 'r')\n",
    "try:\n",
    "    df_part_2 = pd.read_csv(path_df, index_col = False, parse_dates = [0])\n",
    "    df_part_2.columns = ['time','user_id','item_id','behavior_type','item_category']\n",
    "finally:\n",
    "    path_df.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "09eee457",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15406/1628107984.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_2_uc_b_count_in_6 = df_part_2.drop_duplicates(['user_id','item_category','behavior_type'],'last')[['user_id','item_category','behavior_type','cumcount']]\n"
     ]
    }
   ],
   "source": [
    "# uc_b_count_in_6\n",
    "df_part_2['cumcount'] = df_part_2.groupby(['user_id', 'item_category', 'behavior_type']).cumcount()\n",
    "df_part_2_uc_b_count_in_6 = df_part_2.drop_duplicates(['user_id','item_category','behavior_type'],'last')[['user_id','item_category','behavior_type','cumcount']]\n",
    "df_part_2_uc_b_count_in_6 = pd.get_dummies(df_part_2_uc_b_count_in_6['behavior_type']).join(df_part_2_uc_b_count_in_6[['user_id','item_category','cumcount']])\n",
    "df_part_2_uc_b_count_in_6.rename(columns = {1:'behavior_type_1',\n",
    "                                            2:'behavior_type_2',\n",
    "                                            3:'behavior_type_3',\n",
    "                                            4:'behavior_type_4'}, inplace=True)  \n",
    "df_part_2_uc_b_count_in_6['uc_b1_count_in_6'] = df_part_2_uc_b_count_in_6['behavior_type_1'] * (df_part_2_uc_b_count_in_6['cumcount']+1)\n",
    "df_part_2_uc_b_count_in_6['uc_b2_count_in_6'] = df_part_2_uc_b_count_in_6['behavior_type_2'] * (df_part_2_uc_b_count_in_6['cumcount']+1)\n",
    "df_part_2_uc_b_count_in_6['uc_b3_count_in_6'] = df_part_2_uc_b_count_in_6['behavior_type_3'] * (df_part_2_uc_b_count_in_6['cumcount']+1)\n",
    "df_part_2_uc_b_count_in_6['uc_b4_count_in_6'] = df_part_2_uc_b_count_in_6['behavior_type_4'] * (df_part_2_uc_b_count_in_6['cumcount']+1)\n",
    "df_part_2_uc_b_count_in_6 = df_part_2_uc_b_count_in_6[['user_id', \n",
    "                                                       'item_category', \n",
    "                                                       'uc_b1_count_in_6', \n",
    "                                                       'uc_b2_count_in_6', \n",
    "                                                       'uc_b3_count_in_6',\n",
    "                                                       'uc_b4_count_in_6']]\n",
    "df_part_2_uc_b_count_in_6 = df_part_2_uc_b_count_in_6.groupby(['user_id', 'item_category']).agg({'uc_b1_count_in_6': np.sum,\n",
    "                                                                                                 'uc_b2_count_in_6': np.sum,\n",
    "                                                                                                 'uc_b3_count_in_6': np.sum,\n",
    "                                                                                                 'uc_b4_count_in_6': np.sum})\n",
    "df_part_2_uc_b_count_in_6.reset_index(inplace = True)\n",
    "df_part_2_uc_b_count_in_6['uc_b_count_in_6'] = df_part_2_uc_b_count_in_6['uc_b1_count_in_6'] + \\\n",
    "                                               df_part_2_uc_b_count_in_6['uc_b2_count_in_6'] + \\\n",
    "                                               df_part_2_uc_b_count_in_6['uc_b3_count_in_6'] + \\\n",
    "                                               df_part_2_uc_b_count_in_6['uc_b4_count_in_6']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "698fe260",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15406/496279936.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_part_2_in_3['cumcount'] = df_part_2_in_3.groupby(['user_id', 'item_category', 'behavior_type']).cumcount()\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15406/496279936.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_2_uc_b_count_in_3 = df_part_2.drop_duplicates(['user_id','item_category','behavior_type'],'last')[['user_id','item_category','behavior_type','cumcount']]\n"
     ]
    }
   ],
   "source": [
    "# uc_b_count_in_3\n",
    "df_part_2_in_3 = df_part_2[df_part_2['time'] >= np.datetime64('2014-12-02')]\n",
    "df_part_2_in_3['cumcount'] = df_part_2_in_3.groupby(['user_id', 'item_category', 'behavior_type']).cumcount()\n",
    "df_part_2_uc_b_count_in_3 = df_part_2.drop_duplicates(['user_id','item_category','behavior_type'],'last')[['user_id','item_category','behavior_type','cumcount']]\n",
    "df_part_2_uc_b_count_in_3 = pd.get_dummies(df_part_2_uc_b_count_in_3['behavior_type']).join(df_part_2_uc_b_count_in_3[['user_id','item_category','cumcount']])\n",
    "df_part_2_uc_b_count_in_3.rename(columns = {1:'behavior_type_1',\n",
    "                                            2:'behavior_type_2',\n",
    "                                            3:'behavior_type_3',\n",
    "                                            4:'behavior_type_4'}, inplace=True)  \n",
    "df_part_2_uc_b_count_in_3['uc_b1_count_in_3'] = df_part_2_uc_b_count_in_3['behavior_type_1'] * (df_part_2_uc_b_count_in_3['cumcount']+1)\n",
    "df_part_2_uc_b_count_in_3['uc_b2_count_in_3'] = df_part_2_uc_b_count_in_3['behavior_type_2'] * (df_part_2_uc_b_count_in_3['cumcount']+1)\n",
    "df_part_2_uc_b_count_in_3['uc_b3_count_in_3'] = df_part_2_uc_b_count_in_3['behavior_type_3'] * (df_part_2_uc_b_count_in_3['cumcount']+1)\n",
    "df_part_2_uc_b_count_in_3['uc_b4_count_in_3'] = df_part_2_uc_b_count_in_3['behavior_type_4'] * (df_part_2_uc_b_count_in_3['cumcount']+1)\n",
    "df_part_2_uc_b_count_in_3 = df_part_2_uc_b_count_in_3[['user_id', \n",
    "                                                       'item_category', \n",
    "                                                       'uc_b1_count_in_3', \n",
    "                                                       'uc_b2_count_in_3', \n",
    "                                                       'uc_b3_count_in_3',\n",
    "                                                       'uc_b4_count_in_3']]\n",
    "df_part_2_uc_b_count_in_3 = df_part_2_uc_b_count_in_3.groupby(['user_id', 'item_category']).agg({'uc_b1_count_in_3': np.sum,\n",
    "                                                                                                 'uc_b2_count_in_3': np.sum,\n",
    "                                                                                                 'uc_b3_count_in_3': np.sum,\n",
    "                                                                                                 'uc_b4_count_in_3': np.sum})\n",
    "df_part_2_uc_b_count_in_3.reset_index(inplace = True)\n",
    "df_part_2_uc_b_count_in_3['uc_b_count_in_3'] = df_part_2_uc_b_count_in_3['uc_b1_count_in_3'] + \\\n",
    "                                               df_part_2_uc_b_count_in_3['uc_b2_count_in_3'] + \\\n",
    "                                               df_part_2_uc_b_count_in_3['uc_b3_count_in_3'] + \\\n",
    "                                               df_part_2_uc_b_count_in_3['uc_b4_count_in_3']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "559d4522",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15406/3043340709.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_part_2_in_1['cumcount'] = df_part_2_in_1.groupby(['user_id', 'item_category', 'behavior_type']).cumcount()\n",
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15406/3043340709.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_2_uc_b_count_in_1 = df_part_2_in_1.drop_duplicates(['user_id','item_category','behavior_type'], 'last')[['user_id','item_category','behavior_type','cumcount']]\n"
     ]
    }
   ],
   "source": [
    "# uc_b_count_in_1\n",
    "df_part_2_in_1 = df_part_2[df_part_2['time'] >= np.datetime64('2014-12-04')]\n",
    "df_part_2_in_1['cumcount'] = df_part_2_in_1.groupby(['user_id', 'item_category', 'behavior_type']).cumcount()\n",
    "df_part_2_uc_b_count_in_1 = df_part_2_in_1.drop_duplicates(['user_id','item_category','behavior_type'], 'last')[['user_id','item_category','behavior_type','cumcount']]\n",
    "df_part_2_uc_b_count_in_1 = pd.get_dummies(df_part_2_uc_b_count_in_1['behavior_type']).join(df_part_2_uc_b_count_in_1[['user_id','item_category','cumcount']])\n",
    "df_part_2_uc_b_count_in_1.rename(columns = {1:'behavior_type_1',\n",
    "                                            2:'behavior_type_2',\n",
    "                                            3:'behavior_type_3',\n",
    "                                            4:'behavior_type_4'}, inplace=True)\n",
    "df_part_2_uc_b_count_in_1['uc_b1_count_in_1'] = df_part_2_uc_b_count_in_1['behavior_type_1'] * (df_part_2_uc_b_count_in_1['cumcount']+1)\n",
    "df_part_2_uc_b_count_in_1['uc_b2_count_in_1'] = df_part_2_uc_b_count_in_1['behavior_type_2'] * (df_part_2_uc_b_count_in_1['cumcount']+1)\n",
    "df_part_2_uc_b_count_in_1['uc_b3_count_in_1'] = df_part_2_uc_b_count_in_1['behavior_type_3'] * (df_part_2_uc_b_count_in_1['cumcount']+1)\n",
    "df_part_2_uc_b_count_in_1['uc_b4_count_in_1'] = df_part_2_uc_b_count_in_1['behavior_type_4'] * (df_part_2_uc_b_count_in_1['cumcount']+1)\n",
    "df_part_2_uc_b_count_in_1 = df_part_2_uc_b_count_in_1[['user_id',\n",
    "                                                       'item_category', \n",
    "                                                       'uc_b1_count_in_1', \n",
    "                                                       'uc_b2_count_in_1', \n",
    "                                                       'uc_b3_count_in_1',\n",
    "                                                       'uc_b4_count_in_1']]\n",
    "df_part_2_uc_b_count_in_1 = df_part_2_uc_b_count_in_1.groupby(['user_id', 'item_category']).agg({'uc_b1_count_in_1': np.sum,\n",
    "                                                                                                 'uc_b2_count_in_1': np.sum,\n",
    "                                                                                                 'uc_b3_count_in_1': np.sum,\n",
    "                                                                                                 'uc_b4_count_in_1': np.sum})\n",
    "df_part_2_uc_b_count_in_1.reset_index(inplace = True)\n",
    "df_part_2_uc_b_count_in_1['uc_b_count_in_1'] = df_part_2_uc_b_count_in_1['uc_b1_count_in_1'] + \\\n",
    "                                               df_part_2_uc_b_count_in_1['uc_b2_count_in_1'] + \\\n",
    "                                               df_part_2_uc_b_count_in_1['uc_b3_count_in_1'] + \\\n",
    "                                               df_part_2_uc_b_count_in_1['uc_b4_count_in_1']\n",
    "                                             \n",
    "df_part_2_uc_b_count = pd.merge(df_part_2_uc_b_count_in_6, df_part_2_uc_b_count_in_3, on = ['user_id','item_category'], how = 'left').fillna(0)\n",
    "df_part_2_uc_b_count = pd.merge(df_part_2_uc_b_count, df_part_2_uc_b_count_in_1, on = ['user_id','item_category'], how = 'left').fillna(0)\n",
    "df_part_2_uc_b_count[['uc_b1_count_in_6',\n",
    "                      'uc_b2_count_in_6',\n",
    "                      'uc_b3_count_in_6',\n",
    "                      'uc_b4_count_in_6',\n",
    "                       'uc_b_count_in_6',\n",
    "                      'uc_b1_count_in_3',\n",
    "                      'uc_b2_count_in_3',\n",
    "                      'uc_b3_count_in_3',\n",
    "                      'uc_b4_count_in_3',\n",
    "                       'uc_b_count_in_3',\n",
    "                      'uc_b1_count_in_1',\n",
    "                      'uc_b2_count_in_1',\n",
    "                      'uc_b3_count_in_1',\n",
    "                      'uc_b4_count_in_1',\n",
    "                       'uc_b_count_in_1']] = df_part_2_uc_b_count[['uc_b1_count_in_6',\n",
    "                                                                   'uc_b2_count_in_6',\n",
    "                                                                   'uc_b3_count_in_6',\n",
    "                                                                   'uc_b4_count_in_6',\n",
    "                                                                    'uc_b_count_in_6',\n",
    "                                                                   'uc_b1_count_in_3',\n",
    "                                                                   'uc_b2_count_in_3',\n",
    "                                                                   'uc_b3_count_in_3',\n",
    "                                                                   'uc_b4_count_in_3',\n",
    "                                                                    'uc_b_count_in_3',\n",
    "                                                                   'uc_b1_count_in_1',\n",
    "                                                                   'uc_b2_count_in_1',\n",
    "                                                                   'uc_b3_count_in_1',\n",
    "                                                                   'uc_b4_count_in_1',\n",
    "                                                                    'uc_b_count_in_1']].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b0f12620",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/vmc0g_m96tvb6cdgrbz7478r0000gn/T/ipykernel_15406/3972051126.py:6: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  df_part_2_uc_b_last_time = df_part_2.drop_duplicates(['user_id','item_category','behavior_type'],'last')[['user_id','item_category','behavior_type','time']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " part2 done \n"
     ]
    }
   ],
   "source": [
    "# uc_b_count_rank_in_u\n",
    "df_part_2_uc_b_count['uc_b_count_rank_in_u'] = df_part_2_uc_b_count.groupby(['user_id'])['uc_b_count_in_6'].rank(method='min',ascending=False).astype('int')\n",
    "\n",
    "# uc_b_last_time\n",
    "df_part_2.sort_values(by=['user_id','item_category','behavior_type','time'], inplace=True)\n",
    "df_part_2_uc_b_last_time = df_part_2.drop_duplicates(['user_id','item_category','behavior_type'],'last')[['user_id','item_category','behavior_type','time']]\n",
    "\n",
    "df_part_2_uc_b_last_time['uc_b1_last_time'] = df_part_2_uc_b_last_time[df_part_2_uc_b_last_time['behavior_type'] == 1]['time']\n",
    "df_part_2_uc_b_last_time['uc_b2_last_time'] = df_part_2_uc_b_last_time[df_part_2_uc_b_last_time['behavior_type'] == 2]['time']\n",
    "df_part_2_uc_b_last_time['uc_b3_last_time'] = df_part_2_uc_b_last_time[df_part_2_uc_b_last_time['behavior_type'] == 3]['time']\n",
    "df_part_2_uc_b_last_time['uc_b4_last_time'] = df_part_2_uc_b_last_time[df_part_2_uc_b_last_time['behavior_type'] == 4]['time']\n",
    "\n",
    "df_part_2_uc_b_last_time.loc[df_part_2_uc_b_last_time['uc_b1_last_time'].notnull(), 'uc_b1_last_hours'] = (pd.to_datetime('2014-12-05') - df_part_2_uc_b_last_time['uc_b1_last_time'])             \n",
    "df_part_2_uc_b_last_time['uc_b1_last_hours'] = df_part_2_uc_b_last_time[df_part_2_uc_b_last_time['uc_b1_last_hours'].notnull()]['uc_b1_last_hours'].apply(lambda x: x.days*24 + x.seconds//3600)\n",
    "\n",
    "df_part_2_uc_b_last_time.loc[df_part_2_uc_b_last_time['uc_b2_last_time'].notnull(), 'uc_b2_last_hours'] = (pd.to_datetime('2014-12-05') - df_part_2_uc_b_last_time['uc_b2_last_time'])             \n",
    "df_part_2_uc_b_last_time['uc_b2_last_hours'] = df_part_2_uc_b_last_time[df_part_2_uc_b_last_time['uc_b2_last_hours'].notnull()]['uc_b2_last_hours'].apply(lambda x: x.days*24 + x.seconds//3600)\n",
    "\n",
    "df_part_2_uc_b_last_time.loc[df_part_2_uc_b_last_time['uc_b3_last_time'].notnull(), 'uc_b3_last_hours'] = (pd.to_datetime('2014-12-05') - df_part_2_uc_b_last_time['uc_b3_last_time'])             \n",
    "df_part_2_uc_b_last_time['uc_b3_last_hours'] = df_part_2_uc_b_last_time[df_part_2_uc_b_last_time['uc_b3_last_hours'].notnull()]['uc_b3_last_hours'].apply(lambda x: x.days*24 + x.seconds//3600)\n",
    "\n",
    "df_part_2_uc_b_last_time.loc[df_part_2_uc_b_last_time['uc_b4_last_time'].notnull(), 'uc_b4_last_hours'] = (pd.to_datetime('2014-12-05') - df_part_2_uc_b_last_time['uc_b4_last_time'])             \n",
    "df_part_2_uc_b_last_time['uc_b4_last_hours'] = df_part_2_uc_b_last_time[df_part_2_uc_b_last_time['uc_b4_last_hours'].notnull()]['uc_b4_last_hours'].apply(lambda x: x.days*24 + x.seconds//3600)\n",
    "\n",
    "df_part_2_uc_b_last_time = df_part_2_uc_b_last_time[['user_id',\n",
    "                                                     'item_category',\n",
    "                                                     'uc_b1_last_hours',\n",
    "                                                     'uc_b2_last_hours',\n",
    "                                                     'uc_b3_last_hours',\n",
    "                                                     'uc_b4_last_hours']] \n",
    "\n",
    "df_part_2_uc_b_last_time = df_part_2_uc_b_last_time.groupby(['user_id', 'item_category']).agg({'uc_b1_last_hours': np.sum,\n",
    "                                                                                               'uc_b2_last_hours': np.sum,\n",
    "                                                                                               'uc_b3_last_hours': np.sum,\n",
    "                                                                                               'uc_b4_last_hours': np.sum})\n",
    "df_part_2_uc_b_last_time.reset_index(inplace = True)\n",
    "\n",
    "# merge for generation of f_UC_part_2\n",
    "f_UC_part_2 = pd.merge(df_part_2_uc_b_count, df_part_2_uc_b_last_time, how='left', on=['user_id', 'item_category'])\n",
    "\n",
    "# write to csv file\n",
    "f_UC_part_2.to_csv(path_df_part_2_UC, index = False)\n",
    "\n",
    "\n",
    "print(' part2 done ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
